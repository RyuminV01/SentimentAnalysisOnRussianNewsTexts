{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd128c19-762d-49e7-959a-845e0599a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CyclicLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f20af-edf7-4cf5-84b3-bc8e437c24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaWithMultiSampleDropoutTarget(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3, num_dropouts=5, use_multi_sample_dropout=True):\n",
    "        super(RobertaWithMultiSampleDropoutTarget, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.use_multi_sample_dropout = use_multi_sample_dropout\n",
    "        self.hidden_size = self.roberta.config.hidden_size\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(dropout_rate) for _ in range(num_dropouts)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_labels)\n",
    "\n",
    "    def extract_entity_embeddings(self, input_ids, sequence_output, en_token_id, end_en_token_id):\n",
    "        batch_size = input_ids.size(0)\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            input_id = input_ids[i]\n",
    "            output = sequence_output[i]\n",
    "\n",
    "            try:\n",
    "                start = (input_id == en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "                end = (input_id == end_en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "            except IndexError:\n",
    "                # если вдруг токены не найдены — fallback на [CLS]\n",
    "                entity_representations.append(output[0])\n",
    "                continue\n",
    "\n",
    "            # вырезаем эмбеддинги между <en> и </en>\n",
    "            entity_tokens = output[start + 1:end]\n",
    "            if entity_tokens.shape[0] == 0:\n",
    "                entity_representations.append(output[0])  # fallback на [CLS]\n",
    "            else:\n",
    "                entity_representations.append(entity_tokens.mean(dim=0))  # mean pooling\n",
    "\n",
    "        return torch.stack(entity_representations)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # --- 1. Находим позиции <en> и </en> ---\n",
    "        start_token_id = tokenizer.convert_tokens_to_ids(\"<en>\")\n",
    "        end_token_id = tokenizer.convert_tokens_to_ids(\"</en>\")\n",
    "    \n",
    "        start_positions = (input_ids == start_token_id).nonzero(as_tuple=False)\n",
    "        end_positions = (input_ids == end_token_id).nonzero(as_tuple=False)\n",
    "\n",
    "        # --- 2. Для каждого примера агрегируем hidden states между <en> и </en> ---\n",
    "        pooled_output = []\n",
    "        for batch_idx in range(input_ids.size(0)):\n",
    "            start_pos = start_positions[start_positions[:, 0] == batch_idx][:, 1]\n",
    "            end_pos = end_positions[end_positions[:, 0] == batch_idx][:, 1]\n",
    "            if len(start_pos) > 0 and len(end_pos) > 0:\n",
    "                s, e = start_pos[0].item() + 1, end_pos[0].item()  # между тегами\n",
    "                if e > s:\n",
    "                    token_embeds = sequence_output[batch_idx, s:e, :]  # [num_entity_tokens, hidden]\n",
    "                    pooled = torch.mean(token_embeds, dim=0)  # Mean-pooling\n",
    "                else:\n",
    "                    pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "            else:\n",
    "                pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "\n",
    "            pooled_output.append(pooled)\n",
    "\n",
    "        pooled_output = torch.stack(pooled_output)  # [batch_size, hidden_size]\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            logits_list = [self.classifier(dropout(pooled_output)) for dropout in self.dropouts]\n",
    "            avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "        else:\n",
    "            avg_logits = self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "        return SequenceClassifierOutput(logits=avg_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1746-8eac-4865-8f99-828b9055d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_best(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metrics_file = os.path.join(result_path, \"metrics_best.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Создаем словарь с метриками\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop,\n",
    "        \"loss\": loss\n",
    "    }\n",
    "\n",
    "    # Добавляем метрики по каждому классу\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "\n",
    "    # Создаем DataFrame и сохраняем его в CSV (перезапись файла)\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2886be9d-a3f4-4164-8002-b4cc31a22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ens_weights(train_labels, beta: float = 0.999):\n",
    "    train_labels = np.array(train_labels)\n",
    "    classes, counts = np.unique(train_labels, return_counts=True)\n",
    "    effective_num = (1 - np.power(beta, counts)) / (1 - beta)\n",
    "    weights = 1.0 / effective_num\n",
    "    weights = weights / np.sum(weights) * len(classes)  # нормализация как в оригинальной статье\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d52154-884f-4289-8b00-b19358f419e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tags_from_files(*file_paths):\n",
    "    all_tags = set()\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "            if \"entity_tag\" in df.columns:\n",
    "                tags = df[\"entity_tag\"].dropna().unique().tolist()\n",
    "                all_tags.update(tags)\n",
    "        except Exception as e:\n",
    "            print(f\"[Ошибка] Не удалось загрузить {path}: {e}\")\n",
    "    return sorted(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be23ac59-6617-40d9-b01b-be5ff22e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, tokenizer, max_seq_len):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # Загружаем CSV (TSV)\n",
    "\n",
    "        # Проверка нужных колонок\n",
    "        required_columns = {\n",
    "            \"sentence\", \"entity\", \"label\", \"entity_tag\",\n",
    "            \"entity_pos_start_rel\", \"entity_pos_end_rel\"\n",
    "        }\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Ожидаемые колонки: {required_columns}, но в файле: {df.columns}\")\n",
    "\n",
    "        # Заменяем -1 на 2 (если есть)\n",
    "        df[\"label\"] = df[\"label\"].replace(-1, 2)\n",
    "\n",
    "        # Размечаем предложения с [ENTITY] токенами\n",
    "        def mark_entity_inline(row):\n",
    "            sent = row[\"sentence\"]\n",
    "            start = row[\"entity_pos_start_rel\"]\n",
    "            end = row[\"entity_pos_end_rel\"]\n",
    "            tag = row[\"entity_tag\"]\n",
    "            tag_token = f\"<en>\"\n",
    "            tag_token_close = f\"</en>\"\n",
    "            return (\n",
    "                sent[:start] +\n",
    "                f\"{tag_token} \" + sent[start:end] + f\" <|{tag}|>\"+ f\" {tag_token_close}\" +\n",
    "                sent[end:]\n",
    "            )\n",
    "\n",
    "        df[\"input_text\"] = df.apply(mark_entity_inline, axis=1)\n",
    "        texts = df[\"input_text\"].tolist()\n",
    "        labels = torch.tensor(df[\"label\"].astype(int).tolist(), dtype=torch.long)\n",
    "\n",
    "        # Токенизируем\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True,\n",
    "                              max_length=max_seq_len, return_tensors='pt')\n",
    "        dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "        return dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Файл {file_path} не найден!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbfe22-f0f3-4f70-b366-53259c79ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_metrics(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    metrics_file = os.path.join(result_path, \"metrics_class_weights.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    \n",
    "    # Создаем DataFrame для метрик\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop , # (Добавлено)\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    \n",
    "    # Добавляем метрики для каждого класса\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):  # Пропускаем 'accuracy', так как это float\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    # Создаем DataFrame и сохраняем в CSV\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='a', header=not os.path.exists(metrics_file), index=False)\n",
    "\n",
    "def save_confusion_matrix(epoch, y_true, y_pred, result_path,backprop):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"Pred_0\", \"Pred_1\", \"Pred_2\"], index=[\"True_0\", \"True_1\", \"True_2\"])\n",
    "    cm_file = os.path.join(result_path, f\"confusion_matrix_class_weights_epoch_{epoch}_backprop_{backprop}.csv\")\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd447891-39c3-42bc-981d-96b2800a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def castom_classification_report(all_labels, all_preds):\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    data = []\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):  # Для всех метрик, кроме accuracy\n",
    "            row = {'label': label}\n",
    "            for metric, value in metrics.items():\n",
    "                row[metric] = round(value * 100, 3) if metric != 'support' else value\n",
    "            data.append(row)\n",
    "        else:  # Для accuracy\n",
    "            data.append({'label': 'accuracy', 'precision': round(metrics * 100, 3), 'recall': None, 'f1-score': None, 'support': None})\n",
    "\n",
    "    # Добавляем macro F1 для классов 1 и 2\n",
    "    if '1' in report and '2' in report:\n",
    "        f1_1 = report['1']['f1-score']\n",
    "        f1_2 = report['2']['f1-score']\n",
    "        f1_macro_1_2 = (f1_1 + f1_2) / 2\n",
    "        data.append({\n",
    "            'label': 'avg f1 (class 1&2)',\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': round(f1_macro_1_2 * 100, 3),\n",
    "            'support': None\n",
    "        })\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = [''] * len(df)\n",
    "\n",
    "    # Выводим таблицу\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447e1ed-4fc6-43aa-a54c-d9023898afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(flag = False):\n",
    "    # Формируем список специальных токенов\n",
    "    if not flag: return None\n",
    "    special_tokens = {\n",
    "        \"additional_special_tokens\":\n",
    "            [f\"<|{tag}|>\" for tag in teg_class_entity] +\n",
    "            [\"<en>\", \"</en>\"]\n",
    "    }\n",
    "\n",
    "    print(\"Добавленные специальные токены:\")\n",
    "    for token in special_tokens[\"additional_special_tokens\"]:\n",
    "        print(token)\n",
    "    return special_tokens\n",
    "\n",
    "def save_contrel_date(tokenizer, train_dataset):\n",
    "    special_tokens = add_token(flag = True)\n",
    "    if special_tokens != None: \n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "    tokenizer.save_pretrained(os.path.join(args.result, \"tokenizer\"))\n",
    "    print(tokenizer.special_tokens_map)\n",
    "    print(tokenizer.additional_special_tokens)\n",
    "\n",
    "    \n",
    "    file_control_text = os.path.join(args.result, \"use_market_text.txt\")\n",
    "    input_ids, attention_mask, label = train_dataset[0]\n",
    "    decoded_text_token = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    with open(file_control_text, \"w\") as f:\n",
    "        f.write(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "        f.write(f\"Text:\\n{decoded_text}\\n\\n\")\n",
    "    print(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "    print(f\"Text:\\n{decoded_text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af33277-341d-43ba-8b31-c9bba05cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_name='./../ruRoberta-large/', max_seq_len=512, batch_size=16, epochs=10, lr=1e-06, init_checkpoint=None, train_data='./../data/train_data.csv', validation_data='./../data/validation.csv', eval_data='./../data/test.csv', result='./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./../ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавленные специальные токены:\n",
      "<|COUNTRY|>\n",
      "<|NATIONALITY|>\n",
      "<|ORGANIZATION|>\n",
      "<|PERSON|>\n",
      "<|PROFESSION|>\n",
      "<en>\n",
      "</en>\n",
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<|COUNTRY|>', '<|NATIONALITY|>', '<|ORGANIZATION|>', '<|PERSON|>', '<|PROFESSION|>', '<en>', '</en>']}\n",
      "['<|COUNTRY|>', '<|NATIONALITY|>', '<|ORGANIZATION|>', '<|PERSON|>', '<|PROFESSION|>', '<en>', '</en>']\n",
      "Text token:\n",
      "<s>Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена <|PROFESSION|> </en> остановить бой, но тот хотел продолжать.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "\n",
      "\n",
      "Text:\n",
      "Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена <|PROFESSION|> </en> остановить бой, но тот хотел продолжать.\n",
      "\n",
      "\n",
      "tensor([-0.0229, -0.0179,  0.0746,  ..., -0.1801, -0.0312,  0.0677],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "class_weights = tensor([0.7001, 1.2066, 1.0934])\n",
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  20%|██        | 85/415 [00:48<03:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8026\n",
      "F1-macro: 0.2841\n",
      "F1-pn: 0.0089\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.678  99.838    83.446    616.0\n",
      "                 1    100.000   0.901     1.786    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.628     NaN       NaN      NaN\n",
      "         macro avg     57.226  33.580    28.411    860.0\n",
      "      weighted avg     64.249  71.628    60.001    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.893      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  21%|██        | 86/415 [00:57<17:08,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1465\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.8026\n",
      "F1-macro: 0.2841\n",
      "F1-pn: 0.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 170/415 [01:43<02:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  41%|████      | 171/415 [01:51<10:31,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7519\n",
      "F1-macro: 0.2841\n",
      "F1-pn: 0.0088\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.678  99.838    83.446    616.0\n",
      "                 1     50.000   0.901     1.770    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.628     NaN       NaN      NaN\n",
      "         macro avg     40.559  33.580    28.405    860.0\n",
      "      weighted avg     57.795  71.628    59.999    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.885      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  50%|█████     | 209/415 [02:12<01:54,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  61%|██████▏   | 255/415 [03:29<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7966\n",
      "F1-macro: 0.3095\n",
      "F1-pn: 0.0461\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.118  99.513    83.629    616.0\n",
      "                 1     66.667   1.802     3.509    111.0\n",
      "                 2     57.143   3.008     5.714    133.0\n",
      "          accuracy     71.977     NaN       NaN      NaN\n",
      "         macro avg     65.309  34.774    30.951    860.0\n",
      "      weighted avg     69.098  71.977    61.238    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     4.612      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  62%|██████▏   | 256/415 [03:40<09:35,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1778\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7966\n",
      "F1-macro: 0.3095\n",
      "F1-pn: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 340/415 [04:26<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  82%|████████▏ | 341/415 [04:34<03:12,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7158\n",
      "F1-macro: 0.2881\n",
      "F1-pn: 0.0147\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.762  99.838    83.503    616.0\n",
      "                 1      0.000   0.000     0.000    111.0\n",
      "                 2     66.667   1.504     2.941    133.0\n",
      "          accuracy     71.744     NaN       NaN      NaN\n",
      "         macro avg     46.143  33.780    28.815    860.0\n",
      "      weighted avg     61.712  71.744    60.266    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     1.471      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches: 100%|██████████| 415/415 [05:15<00:00,  1.32it/s]\n",
      "INFO:root:Epoch 1, Loss: 0.9029651379728891, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.7919\n",
      "F1-macro: 0.3625\n",
      "F1-pn: 0.1236\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     73.412  98.261    84.038   4774.0\n",
      "                 1     70.270   3.037     5.823    856.0\n",
      "                 2     54.762  11.420    18.899   1007.0\n",
      "          accuracy     72.804     NaN       NaN      NaN\n",
      "         macro avg     66.148  37.573    36.253   6637.0\n",
      "      weighted avg     70.177  72.804    64.067   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    12.361      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6953\n",
      "F1-macro: 0.3542\n",
      "F1-pn: 0.1130\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.947  98.052    83.657    616.0\n",
      "                 1     75.000   2.703     5.217    111.0\n",
      "                 2     50.000  10.526    17.391    133.0\n",
      "          accuracy     72.209     NaN       NaN      NaN\n",
      "         macro avg     65.982  37.094    35.422    860.0\n",
      "      weighted avg     69.663  72.209    63.284    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    11.304      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2336\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6953\n",
      "F1-macro: 0.3542\n",
      "F1-pn: 0.1130\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.7215\n",
      "F1-macro: 0.3755\n",
      "F1-pn: 0.1391\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.523  98.460    84.836   1429.0\n",
      "                 1      0.000   0.000     0.000    251.0\n",
      "                 2     69.737  17.377    27.822    305.0\n",
      "          accuracy     73.552     NaN       NaN      NaN\n",
      "         macro avg     48.087  38.613    37.552   1985.0\n",
      "      weighted avg     64.365  73.552    65.348   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    13.911      NaN\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6660\n",
      "F1-macro: 0.4414\n",
      "F1-pn: 0.2407\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.032  96.104    84.270    616.0\n",
      "                 1     73.333   9.910    17.460    111.0\n",
      "                 2     51.786  21.805    30.688    133.0\n",
      "          accuracy     73.488     NaN       NaN      NaN\n",
      "         macro avg     66.717  42.606    44.140    860.0\n",
      "      weighted avg     71.217  73.488    67.361    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    24.074      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  21%|██        | 86/415 [00:58<19:45,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3411\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6660\n",
      "F1-macro: 0.4414\n",
      "F1-pn: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 170/415 [01:45<02:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6442\n",
      "F1-macro: 0.5446\n",
      "F1-pn: 0.3913\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.918  92.370    85.116    616.0\n",
      "                 1     57.778  23.423    33.333    111.0\n",
      "                 2     54.255  38.346    44.934    133.0\n",
      "          accuracy     75.116     NaN       NaN      NaN\n",
      "         macro avg     63.650  51.380    54.461    860.0\n",
      "      weighted avg     72.375  75.116    72.218    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    39.134      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 171/415 [01:55<14:42,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.4680\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6442\n",
      "F1-macro: 0.5446\n",
      "F1-pn: 0.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  50%|█████     | 209/415 [02:17<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  61%|██████▏   | 255/415 [03:34<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  62%|██████▏   | 256/415 [03:41<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6046\n",
      "F1-macro: 0.5376\n",
      "F1-pn: 0.3821\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     77.883  93.182    84.848    616.0\n",
      "                 1     79.167  17.117    28.148    111.0\n",
      "                 2     56.566  42.105    48.276    133.0\n",
      "          accuracy     75.465     NaN       NaN      NaN\n",
      "         macro avg     71.205  50.801    53.757    860.0\n",
      "      weighted avg     74.752  75.465    71.874    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    38.212      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 340/415 [04:28<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5732\n",
      "F1-macro: 0.5831\n",
      "F1-pn: 0.4461\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.198  92.045    85.714    616.0\n",
      "                 1     69.444  22.523    34.014    111.0\n",
      "                 2     58.974  51.880    55.200    133.0\n",
      "          accuracy     76.860     NaN       NaN      NaN\n",
      "         macro avg     69.539  55.483    58.309    860.0\n",
      "      weighted avg     75.528  76.860    74.322    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    44.607      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 341/415 [04:39<04:28,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5146\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5732\n",
      "F1-macro: 0.5831\n",
      "F1-pn: 0.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches: 100%|██████████| 415/415 [05:21<00:00,  1.29it/s]\n",
      "INFO:root:Epoch 2, Loss: 0.7541831297328673, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.6058\n",
      "F1-macro: 0.6537\n",
      "F1-pn: 0.5485\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.399  87.474    86.424   4774.0\n",
      "                 1     69.524  34.112    45.768    856.0\n",
      "                 2     56.217  74.081    63.925   1007.0\n",
      "          accuracy     78.560     NaN       NaN      NaN\n",
      "         macro avg     70.380  65.222    65.372   6637.0\n",
      "      weighted avg     78.924  78.560    77.767   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    54.846      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5741\n",
      "F1-macro: 0.6062\n",
      "F1-pn: 0.4858\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.677  85.714    84.683    616.0\n",
      "                 1     65.909  26.126    37.419    111.0\n",
      "                 2     51.351  71.429    59.748    133.0\n",
      "          accuracy     75.814     NaN       NaN      NaN\n",
      "         macro avg     66.979  61.090    60.617    860.0\n",
      "      weighted avg     76.384  75.814    74.727    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    48.584      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5460\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5741\n",
      "F1-macro: 0.6062\n",
      "F1-pn: 0.4858\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.5563\n",
      "F1-macro: 0.5174\n",
      "F1-pn: 0.3473\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.567  94.402    85.760   1429.0\n",
      "                 1     21.951   7.171    10.811    251.0\n",
      "                 2     77.419  47.213    58.656    305.0\n",
      "          accuracy     76.121     NaN       NaN      NaN\n",
      "         macro avg     59.313  49.595    51.742   1985.0\n",
      "      weighted avg     71.232  76.121    72.118   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    34.733      NaN\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5444\n",
      "F1-macro: 0.6186\n",
      "F1-pn: 0.4986\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.885  90.260    85.869    616.0\n",
      "                 1     69.565  28.829    40.764    111.0\n",
      "                 2     58.519  59.398    58.955    133.0\n",
      "          accuracy     77.558     NaN       NaN      NaN\n",
      "         macro avg     69.990  59.496    61.863    860.0\n",
      "      weighted avg     76.681  77.558    75.885    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    49.860      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  21%|██        | 86/415 [00:58<19:57,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5586\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5444\n",
      "F1-macro: 0.6186\n",
      "F1-pn: 0.4986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 170/415 [01:45<02:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5216\n",
      "F1-macro: 0.6501\n",
      "F1-pn: 0.5430\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     84.603  88.312    86.418    616.0\n",
      "                 1     61.039  42.342    50.000    111.0\n",
      "                 2     57.143  60.150    58.608    133.0\n",
      "          accuracy     78.023     NaN       NaN      NaN\n",
      "         macro avg     67.595  63.601    65.009    860.0\n",
      "      weighted avg     77.315  78.023    77.417    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    54.304      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 171/415 [01:55<14:45,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5966\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5216\n",
      "F1-macro: 0.6501\n",
      "F1-pn: 0.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  50%|█████     | 209/415 [02:17<01:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  61%|██████▏   | 255/415 [03:34<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  62%|██████▏   | 256/415 [03:41<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5176\n",
      "F1-macro: 0.6209\n",
      "F1-pn: 0.5017\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.606  90.747    85.934    616.0\n",
      "                 1     61.905  35.135    44.828    111.0\n",
      "                 2     60.714  51.128    55.510    133.0\n",
      "          accuracy     77.442     NaN       NaN      NaN\n",
      "         macro avg     68.075  59.003    62.091    860.0\n",
      "      weighted avg     75.832  77.442    75.923    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    50.169      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 340/415 [04:28<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4970\n",
      "F1-macro: 0.6632\n",
      "F1-pn: 0.5576\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     84.756  90.260    87.421    616.0\n",
      "                 1     70.909  35.135    46.988    111.0\n",
      "                 2     61.074  68.421    64.539    133.0\n",
      "          accuracy     79.767     NaN       NaN      NaN\n",
      "         macro avg     72.246  64.605    66.316    860.0\n",
      "      weighted avg     79.306  79.767    78.664    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    55.763      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 341/415 [04:39<04:26,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6104\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4970\n",
      "F1-macro: 0.6632\n",
      "F1-pn: 0.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches: 100%|██████████| 415/415 [05:20<00:00,  1.29it/s]\n",
      "INFO:root:Epoch 3, Loss: 0.6053051769912962, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4855\n",
      "F1-macro: 0.7425\n",
      "F1-pn: 0.6680\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.354  88.961    89.157   4774.0\n",
      "                 1     68.254  55.257    61.072    856.0\n",
      "                 2     66.919  79.146    72.520   1007.0\n",
      "          accuracy     83.125     NaN       NaN      NaN\n",
      "         macro avg     74.842  74.455    74.250   6637.0\n",
      "      weighted avg     83.229  83.125    83.011   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.796      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5014\n",
      "F1-macro: 0.6932\n",
      "F1-pn: 0.6053\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.147  85.714    86.914    616.0\n",
      "                 1     64.368  50.450    56.566    111.0\n",
      "                 2     56.897  74.436    64.495    133.0\n",
      "          accuracy     79.419     NaN       NaN      NaN\n",
      "         macro avg     69.804  70.200    69.325    860.0\n",
      "      weighted avg     80.245  79.419    79.530    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.530      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6493\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5014\n",
      "F1-macro: 0.6932\n",
      "F1-pn: 0.6053\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.4365\n",
      "F1-macro: 0.6708\n",
      "F1-pn: 0.5605\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.671  95.381    89.143   1429.0\n",
      "                 1     57.759  26.693    36.512    251.0\n",
      "                 2     85.833  67.541    75.596    305.0\n",
      "          accuracy     82.418     NaN       NaN      NaN\n",
      "         macro avg     75.754  63.205    67.084   1985.0\n",
      "      weighted avg     80.727  82.418    80.407   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    56.054      NaN\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  21%|██        | 86/415 [00:54<14:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5160\n",
      "F1-macro: 0.6896\n",
      "F1-pn: 0.6076\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.643  81.494    85.374    616.0\n",
      "                 1     56.637  57.658    57.143    111.0\n",
      "                 2     55.080  77.444    64.375    133.0\n",
      "          accuracy     77.791     NaN       NaN      NaN\n",
      "         macro avg     67.120  72.198    68.964    860.0\n",
      "      weighted avg     80.038  77.791    78.483    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.759      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 170/415 [01:42<02:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4820\n",
      "F1-macro: 0.7133\n",
      "F1-pn: 0.6305\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.091  87.662    87.876    616.0\n",
      "                 1     65.909  52.252    58.291    111.0\n",
      "                 2     62.264  74.436    67.808    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     72.088  71.450    71.325    860.0\n",
      "      weighted avg     81.234  81.047    80.954    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.050      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 171/415 [01:52<14:45,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6719\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4820\n",
      "F1-macro: 0.7133\n",
      "F1-pn: 0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  50%|█████     | 209/415 [02:14<01:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  61%|██████▏   | 255/415 [03:31<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  62%|██████▏   | 256/415 [03:38<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4777\n",
      "F1-macro: 0.6797\n",
      "F1-pn: 0.5842\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.580  88.636    87.081    616.0\n",
      "                 1     62.651  46.847    53.608    111.0\n",
      "                 2     61.871  64.662    63.235    133.0\n",
      "          accuracy     79.535     NaN       NaN      NaN\n",
      "         macro avg     70.034  66.715    67.975    860.0\n",
      "      weighted avg     78.954  79.535    79.073    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.422      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 340/415 [04:25<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 341/415 [04:32<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4745\n",
      "F1-macro: 0.7075\n",
      "F1-pn: 0.6238\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.667  86.364    87.500    616.0\n",
      "                 1     61.616  54.955    58.095    111.0\n",
      "                 2     60.870  73.684    66.667    133.0\n",
      "          accuracy     80.349     NaN       NaN      NaN\n",
      "         macro avg     70.384  71.668    70.754    860.0\n",
      "      weighted avg     80.876  80.349    80.483    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.381      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches: 100%|██████████| 415/415 [05:14<00:00,  1.32it/s]\n",
      "INFO:root:Epoch 4, Loss: 0.5019800503569913, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3958\n",
      "F1-macro: 0.7959\n",
      "F1-pn: 0.7380\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.750  90.616    91.179   4774.0\n",
      "                 1     73.494  64.136    68.497    856.0\n",
      "                 2     73.447  85.700    79.102   1007.0\n",
      "          accuracy     86.455     NaN       NaN      NaN\n",
      "         macro avg     79.564  80.150    79.593   6637.0\n",
      "      weighted avg     86.618  86.455    86.421   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    73.799      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4660\n",
      "F1-macro: 0.7208\n",
      "F1-pn: 0.6426\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.112  86.364    87.716    616.0\n",
      "                 1     63.918  55.856    59.615    111.0\n",
      "                 2     62.048  77.444    68.896    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     71.693  73.221    72.076    860.0\n",
      "      weighted avg     81.675  81.047    81.179    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.256      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6817\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4660\n",
      "F1-macro: 0.7208\n",
      "F1-pn: 0.6426\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.3406\n",
      "F1-macro: 0.7578\n",
      "F1-pn: 0.6777\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.162  96.921    91.783   1429.0\n",
      "                 1     75.000  40.637    52.713    251.0\n",
      "                 2     90.000  76.721    82.832    305.0\n",
      "          accuracy     86.700     NaN       NaN      NaN\n",
      "         macro avg     84.054  71.427    75.776   1985.0\n",
      "      weighted avg     86.060  86.700    85.467   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.773      NaN\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5019\n",
      "F1-macro: 0.7188\n",
      "F1-pn: 0.6465\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     92.251  81.169    86.356    616.0\n",
      "                 1     57.937  65.766    61.603    111.0\n",
      "                 2     57.292  82.707    67.692    133.0\n",
      "          accuracy     79.419     NaN       NaN      NaN\n",
      "         macro avg     69.160  76.547    71.884    860.0\n",
      "      weighted avg     82.415  79.419    80.275    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.648      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  21%|██        | 86/415 [00:58<19:59,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6827\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5019\n",
      "F1-macro: 0.7188\n",
      "F1-pn: 0.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 170/415 [01:45<02:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4631\n",
      "F1-macro: 0.7472\n",
      "F1-pn: 0.6770\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.111  86.526    88.759    616.0\n",
      "                 1     64.957  68.468    66.667    111.0\n",
      "                 2     63.291  75.188    68.729    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.120  76.727    74.718    860.0\n",
      "      weighted avg     83.433  82.442    82.810    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.698      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 171/415 [01:56<14:49,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7121\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4631\n",
      "F1-macro: 0.7472\n",
      "F1-pn: 0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  50%|█████     | 209/415 [02:17<01:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  61%|██████▏   | 255/415 [03:34<01:29,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  62%|██████▏   | 256/415 [03:41<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4491\n",
      "F1-macro: 0.7326\n",
      "F1-pn: 0.6564\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.350  88.636    88.493    616.0\n",
      "                 1     65.306  57.658    61.244    111.0\n",
      "                 2     67.361  72.932    70.036    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     73.672  73.075    73.258    860.0\n",
      "      weighted avg     82.129  82.209    82.121    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.640      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 340/415 [04:28<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 341/415 [04:36<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4502\n",
      "F1-macro: 0.7387\n",
      "F1-pn: 0.6646\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.388  87.013    88.668    616.0\n",
      "                 1     64.486  62.162    63.303    111.0\n",
      "                 2     63.750  76.692    69.625    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.875  75.289    73.865    860.0\n",
      "      weighted avg     82.925  82.209    82.449    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.464      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches: 100%|██████████| 415/415 [05:17<00:00,  1.31it/s]\n",
      "INFO:root:Epoch 5, Loss: 0.40930005724889684, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3045\n",
      "F1-macro: 0.8530\n",
      "F1-pn: 0.8132\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.475  92.061    93.253   4774.0\n",
      "                 1     74.973  79.790    77.306    856.0\n",
      "                 2     82.682  88.183    85.344   1007.0\n",
      "          accuracy     89.890     NaN       NaN      NaN\n",
      "         macro avg     84.043  86.678    85.301   6637.0\n",
      "      weighted avg     90.171  89.890    89.996   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    81.325      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4601\n",
      "F1-macro: 0.7461\n",
      "F1-pn: 0.6754\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.111  86.526    88.759    616.0\n",
      "                 1     62.500  67.568    64.935    111.0\n",
      "                 2     65.161  75.940    70.139    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     72.924  76.678    74.611    860.0\n",
      "      weighted avg     83.405  82.442    82.805    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.537      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.2348\n",
      "F1-macro: 0.8687\n",
      "F1-pn: 0.8272\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     92.358  98.111    95.148   1429.0\n",
      "                 1     88.202  62.550    73.193    251.0\n",
      "                 2     94.810  89.836    92.256    305.0\n",
      "          accuracy     92.343     NaN       NaN      NaN\n",
      "         macro avg     91.790  83.499    86.866   1985.0\n",
      "      weighted avg     92.209  92.343    91.927   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    82.725      NaN\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  21%|██        | 86/415 [00:55<14:22,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4779\n",
      "F1-macro: 0.7341\n",
      "F1-pn: 0.6628\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.373  84.253    87.669    616.0\n",
      "                 1     56.250  72.973    63.529    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     71.055  76.720    73.412    860.0\n",
      "      weighted avg     82.845  81.047    81.672    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.284      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 171/415 [01:49<10:35,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4618\n",
      "F1-macro: 0.7467\n",
      "F1-pn: 0.6762\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.111  86.526    88.759    616.0\n",
      "                 1     63.333  68.468    65.801    111.0\n",
      "                 2     64.516  75.188    69.444    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     72.987  76.727    74.668    860.0\n",
      "      weighted avg     83.413  82.442    82.809    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.623      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  50%|█████     | 209/415 [02:10<01:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  61%|██████▏   | 255/415 [03:28<01:29,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  62%|██████▏   | 256/415 [03:35<06:53,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4582\n",
      "F1-macro: 0.7427\n",
      "F1-pn: 0.6694\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.572  87.338    88.926    616.0\n",
      "                 1     66.364  65.766    66.063    111.0\n",
      "                 2     62.821  73.684    67.820    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.252  75.596    74.270    860.0\n",
      "      weighted avg     83.156  82.442    82.711    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.942      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 340/415 [04:22<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4555\n",
      "F1-macro: 0.7556\n",
      "F1-pn: 0.6867\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.638  87.175    89.351    616.0\n",
      "                 1     65.289  71.171    68.103    111.0\n",
      "                 2     64.706  74.436    69.231    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     73.878  77.594    75.562    860.0\n",
      "      weighted avg     84.072  83.140    83.497    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.667      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 341/415 [04:33<04:27,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7211\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4555\n",
      "F1-macro: 0.7556\n",
      "F1-pn: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches: 100%|██████████| 415/415 [05:14<00:00,  1.32it/s]\n",
      "INFO:root:Epoch 6, Loss: 0.3156509828495692, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.2278\n",
      "F1-macro: 0.9015\n",
      "F1-pn: 0.8738\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     95.569  95.790    95.679   4774.0\n",
      "                 1     86.286  83.061    84.643    856.0\n",
      "                 2     89.202  91.063    90.123   1007.0\n",
      "          accuracy     93.431     NaN       NaN      NaN\n",
      "         macro avg     90.353  89.971    90.148   6637.0\n",
      "      weighted avg     93.406  93.431    93.413   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    87.383      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4482\n",
      "F1-macro: 0.7534\n",
      "F1-pn: 0.6811\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.000  88.636    89.803    616.0\n",
      "                 1     67.273  66.667    66.968    111.0\n",
      "                 2     65.333  73.684    69.258    133.0\n",
      "          accuracy     83.488     NaN       NaN      NaN\n",
      "         macro avg     74.535  76.329    75.343    860.0\n",
      "      weighted avg     83.968  83.488    83.678    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.113      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1649\n",
      "F1-macro: 0.9167\n",
      "F1-pn: 0.8921\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.330  98.950    96.585   1429.0\n",
      "                 1     94.819  72.908    82.432    251.0\n",
      "                 2     97.952  94.098    95.987    305.0\n",
      "          accuracy     94.912     NaN       NaN      NaN\n",
      "         macro avg     95.700  88.652    91.668   1985.0\n",
      "      weighted avg     94.948  94.912    94.703   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    89.210      NaN\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  21%|██        | 86/415 [00:55<14:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4743\n",
      "F1-macro: 0.7441\n",
      "F1-pn: 0.6718\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.847  87.013    88.889    616.0\n",
      "                 1     63.333  68.468    65.801    111.0\n",
      "                 2     64.667  72.932    68.551    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     72.949  76.138    74.414    860.0\n",
      "      weighted avg     83.247  82.442    82.764    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.176      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 170/415 [01:41<02:16,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 171/415 [01:49<10:35,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4782\n",
      "F1-macro: 0.7510\n",
      "F1-pn: 0.6804\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.327  87.175    89.203    616.0\n",
      "                 1     65.789  67.568    66.667    111.0\n",
      "                 2     63.924  75.940    69.416    133.0\n",
      "          accuracy     82.907     NaN       NaN      NaN\n",
      "         macro avg     73.680  76.894    75.095    860.0\n",
      "      weighted avg     83.793  82.907    83.234    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.041      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  50%|█████     | 209/415 [02:10<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  61%|██████▏   | 255/415 [03:27<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  62%|██████▏   | 256/415 [03:35<06:55,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4761\n",
      "F1-macro: 0.7480\n",
      "F1-pn: 0.6756\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.772  87.825    89.274    616.0\n",
      "                 1     64.655  67.568    66.079    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     82.907     NaN       NaN      NaN\n",
      "         macro avg     73.656  76.108    74.797    860.0\n",
      "      weighted avg     83.499  82.907    83.151    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.559      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 340/415 [04:22<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 341/415 [04:29<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4789\n",
      "F1-macro: 0.7485\n",
      "F1-pn: 0.6787\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.552  86.201    88.796    616.0\n",
      "                 1     63.710  71.171    67.234    111.0\n",
      "                 2     63.462  74.436    68.512    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     72.908  77.270    74.847    860.0\n",
      "      weighted avg     83.614  82.442    82.876    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.873      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches: 100%|██████████| 415/415 [05:11<00:00,  1.33it/s]\n",
      "INFO:root:Epoch 7, Loss: 0.22806515252464507, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1464\n",
      "F1-macro: 0.9425\n",
      "F1-pn: 0.9264\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.009  96.942    97.473   4774.0\n",
      "                 1     89.527  92.874    91.170    856.0\n",
      "                 2     93.184  95.035    94.100   1007.0\n",
      "          accuracy     96.128     NaN       NaN      NaN\n",
      "         macro avg     93.573  94.950    94.248   6637.0\n",
      "      weighted avg     96.183  96.128    96.148   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    92.635      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4774\n",
      "F1-macro: 0.7543\n",
      "F1-pn: 0.6845\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.356  87.500    89.386    616.0\n",
      "                 1     65.289  71.171    68.103    111.0\n",
      "                 2     65.101  72.932    68.794    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     73.915  77.201    75.428    860.0\n",
      "      weighted avg     83.931  83.140    83.455    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.449      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0853\n",
      "F1-macro: 0.9734\n",
      "F1-pn: 0.9656\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.339  99.440    98.887   1429.0\n",
      "                 1     97.490  92.829    95.102    251.0\n",
      "                 2     98.671  97.377    98.020    305.0\n",
      "          accuracy     98.287     NaN       NaN      NaN\n",
      "         macro avg     98.167  96.549    97.336   1985.0\n",
      "      weighted avg     98.283  98.287    98.275   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    96.561      NaN\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  21%|██        | 86/415 [00:55<14:19,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5106\n",
      "F1-macro: 0.7530\n",
      "F1-pn: 0.6839\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.312  87.013    89.111    616.0\n",
      "                 1     64.228  71.171    67.521    111.0\n",
      "                 2     65.333  73.684    69.258    133.0\n",
      "          accuracy     82.907     NaN       NaN      NaN\n",
      "         macro avg     73.624  77.289    75.297    860.0\n",
      "      weighted avg     83.798  82.907    83.254    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.390      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5094\n",
      "F1-macro: 0.7646\n",
      "F1-pn: 0.6978\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.568  88.149    89.826    616.0\n",
      "                 1     69.565  72.072    70.796    111.0\n",
      "                 2     64.474  73.684    68.772    133.0\n",
      "          accuracy     83.837     NaN       NaN      NaN\n",
      "         macro avg     75.202  77.969    76.465    860.0\n",
      "      weighted avg     84.538  83.837    84.114    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    69.784      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 171/415 [01:52<14:44,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7312\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5094\n",
      "F1-macro: 0.7646\n",
      "F1-pn: 0.6978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  50%|█████     | 209/415 [02:14<01:55,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  61%|██████▏   | 255/415 [03:31<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  62%|██████▏   | 256/415 [03:38<06:53,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5206\n",
      "F1-macro: 0.7632\n",
      "F1-pn: 0.6951\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.304  88.636    89.951    616.0\n",
      "                 1     68.750  69.369    69.058    111.0\n",
      "                 2     66.000  74.436    69.965    133.0\n",
      "          accuracy     83.953     NaN       NaN      NaN\n",
      "         macro avg     75.351  77.481    76.325    860.0\n",
      "      weighted avg     84.480  83.953    84.163    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    69.511      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 340/415 [04:25<00:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 341/415 [04:33<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5310\n",
      "F1-macro: 0.7613\n",
      "F1-pn: 0.6949\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.938  87.013    89.408    616.0\n",
      "                 1     66.393  72.973    69.528    111.0\n",
      "                 2     64.516  75.188    69.444    133.0\n",
      "          accuracy     83.372     NaN       NaN      NaN\n",
      "         macro avg     74.283  78.391    76.127    860.0\n",
      "      weighted avg     84.400  83.372    83.755    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    69.486      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches: 100%|██████████| 415/415 [05:14<00:00,  1.32it/s]\n",
      "INFO:root:Epoch 8, Loss: 0.14016121192779168, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0813\n",
      "F1-macro: 0.9733\n",
      "F1-pn: 0.9658\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.095  98.576    98.834   4774.0\n",
      "                 1     95.402  96.963    96.176    856.0\n",
      "                 2     96.464  97.517    96.988   1007.0\n",
      "          accuracy     98.207     NaN       NaN      NaN\n",
      "         macro avg     96.987  97.685    97.333   6637.0\n",
      "      weighted avg     98.219  98.207    98.211   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    96.582      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5194\n",
      "F1-macro: 0.7571\n",
      "F1-pn: 0.6877\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.385  87.825    89.570    616.0\n",
      "                 1     66.949  71.171    68.996    111.0\n",
      "                 2     64.667  72.932    68.551    133.0\n",
      "          accuracy     83.372     NaN       NaN      NaN\n",
      "         macro avg     74.334  77.309    75.705    860.0\n",
      "      weighted avg     84.099  83.372    83.664    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.773      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0388\n",
      "F1-macro: 0.9923\n",
      "F1-pn: 0.9897\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.720  99.790    99.755   1429.0\n",
      "                 1     99.194  98.008    98.597    251.0\n",
      "                 2     99.023  99.672    99.346    305.0\n",
      "          accuracy     99.547     NaN       NaN      NaN\n",
      "         macro avg     99.312  99.157    99.233   1985.0\n",
      "      weighted avg     99.547  99.547    99.546   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    98.972      NaN\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  20%|██        | 85/415 [00:47<03:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  21%|██        | 86/415 [00:55<14:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5779\n",
      "F1-macro: 0.7468\n",
      "F1-pn: 0.6758\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.566  86.364    88.889    616.0\n",
      "                 1     61.069  72.072    66.116    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     72.725  77.123    74.681    860.0\n",
      "      weighted avg     83.605  82.442    82.880    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.577      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 171/415 [01:49<10:35,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5735\n",
      "F1-macro: 0.7567\n",
      "F1-pn: 0.6884\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.924  86.851    89.316    616.0\n",
      "                 1     63.492  72.072    67.511    111.0\n",
      "                 2     65.789  75.188    70.175    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     73.735  78.037    75.667    860.0\n",
      "      weighted avg     84.213  83.140    83.541    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.843      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  50%|█████     | 209/415 [02:10<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  61%|██████▏   | 255/415 [03:27<01:29,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  62%|██████▏   | 256/415 [03:35<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5842\n",
      "F1-macro: 0.7623\n",
      "F1-pn: 0.6942\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.290  88.474    89.860    616.0\n",
      "                 1     69.369  69.369    69.369    111.0\n",
      "                 2     65.132  74.436    69.474    133.0\n",
      "          accuracy     83.837     NaN       NaN      NaN\n",
      "         macro avg     75.264  77.426    76.234    860.0\n",
      "      weighted avg     84.415  83.837    84.062    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    69.422      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 340/415 [04:22<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 341/415 [04:29<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5896\n",
      "F1-macro: 0.7519\n",
      "F1-pn: 0.6824\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.595  86.688    89.074    616.0\n",
      "                 1     65.812  69.369    67.544    111.0\n",
      "                 2     63.125  75.940    68.942    133.0\n",
      "          accuracy     82.791     NaN       NaN      NaN\n",
      "         macro avg     73.511  77.333    75.187    860.0\n",
      "      weighted avg     83.864  82.791    83.182    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.243      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches: 100%|██████████| 415/415 [05:11<00:00,  1.33it/s]\n",
      "INFO:root:Epoch 9, Loss: 0.07719121122149279, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0409\n",
      "F1-macro: 0.9902\n",
      "F1-pn: 0.9872\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.811  99.393    99.601   4774.0\n",
      "                 1     98.266  99.299    98.780    856.0\n",
      "                 2     98.134  99.206    98.667   1007.0\n",
      "          accuracy     99.352     NaN       NaN      NaN\n",
      "         macro avg     98.737  99.299    99.016   6637.0\n",
      "      weighted avg     99.357  99.352    99.353   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    98.723      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5697\n",
      "F1-macro: 0.7513\n",
      "F1-pn: 0.6779\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.049  89.610    89.829    616.0\n",
      "                 1     69.307  63.063    66.038    111.0\n",
      "                 2     66.438  72.932    69.534    133.0\n",
      "          accuracy     83.605     NaN       NaN      NaN\n",
      "         macro avg     75.265  75.202    75.134    860.0\n",
      "      weighted avg     83.720  83.605    83.620    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.786      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0172\n",
      "F1-macro: 1.0000\n",
      "F1-pn: 1.0000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0      100.0   100.0     100.0   1429.0\n",
      "                 1      100.0   100.0     100.0    251.0\n",
      "                 2      100.0   100.0     100.0    305.0\n",
      "          accuracy      100.0     NaN       NaN      NaN\n",
      "         macro avg      100.0   100.0     100.0   1985.0\n",
      "      weighted avg      100.0   100.0     100.0   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN     100.0      NaN\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  20%|██        | 85/415 [00:47<03:04,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  21%|██        | 86/415 [00:55<14:17,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6271\n",
      "F1-macro: 0.7564\n",
      "F1-pn: 0.6881\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.924  86.851    89.316    616.0\n",
      "                 1     63.710  71.171    67.234    111.0\n",
      "                 2     65.584  75.940    70.383    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     73.739  77.987    75.644    860.0\n",
      "      weighted avg     84.209  83.140    83.538    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.809      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 171/415 [01:49<10:36,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6291\n",
      "F1-macro: 0.7543\n",
      "F1-pn: 0.6848\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.201  87.500    89.312    616.0\n",
      "                 1     65.254  69.369    67.249    111.0\n",
      "                 2     65.563  74.436    69.718    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     74.006  77.102    75.427    860.0\n",
      "      weighted avg     83.887  83.140    83.434    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.484      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  50%|█████     | 209/415 [02:10<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  61%|██████▏   | 255/415 [03:28<01:29,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  62%|██████▏   | 256/415 [03:35<06:54,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6287\n",
      "F1-macro: 0.7591\n",
      "F1-pn: 0.6888\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.344  89.610    89.976    616.0\n",
      "                 1     69.811  66.667    68.203    111.0\n",
      "                 2     67.133  72.180    69.565    133.0\n",
      "          accuracy     83.953     NaN       NaN      NaN\n",
      "         macro avg     75.763  76.153    75.915    860.0\n",
      "      weighted avg     84.104  83.953    84.009    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.884      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 340/415 [04:22<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 341/415 [04:30<03:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6378\n",
      "F1-macro: 0.7519\n",
      "F1-pn: 0.6810\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.787  87.987    89.365    616.0\n",
      "                 1     64.957  68.468    66.667    111.0\n",
      "                 2     66.438  72.932    69.534    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     74.061  76.463    75.189    860.0\n",
      "      weighted avg     83.688  83.140    83.369    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.100      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches: 100%|██████████| 415/415 [05:11<00:00,  1.33it/s]\n",
      "INFO:root:Epoch 10, Loss: 0.03793388788969851, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0182\n",
      "F1-macro: 0.9961\n",
      "F1-pn: 0.9950\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.958  99.686    99.822   4774.0\n",
      "                 1     99.303  99.883    99.592    856.0\n",
      "                 2     99.015  99.801    99.407   1007.0\n",
      "          accuracy     99.729     NaN       NaN      NaN\n",
      "         macro avg     99.425  99.790    99.607   6637.0\n",
      "      weighted avg     99.730  99.729    99.729   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.499      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6560\n",
      "F1-macro: 0.7552\n",
      "F1-pn: 0.6854\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.371  87.662    89.478    616.0\n",
      "                 1     65.546  70.270    67.826    111.0\n",
      "                 2     65.333  73.684    69.258    133.0\n",
      "          accuracy     83.256     NaN       NaN      NaN\n",
      "         macro avg     74.083  77.206    75.521    860.0\n",
      "      weighted avg     84.011  83.256    83.556    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.542      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0078\n",
      "F1-macro: 0.9993\n",
      "F1-pn: 0.9992\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0    100.000  99.930    99.965   1429.0\n",
      "                 1    100.000 100.000   100.000    251.0\n",
      "                 2     99.673 100.000    99.836    305.0\n",
      "          accuracy     99.950     NaN       NaN      NaN\n",
      "         macro avg     99.891  99.977    99.934   1985.0\n",
      "      weighted avg     99.950  99.950    99.950   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.918      NaN\n"
     ]
    }
   ],
   "source": [
    "teg_class_entity = [\"COUNTRY\", \"NATIONALITY\", \"ORGANIZATION\", \"PERSON\", \"PROFESSION\"]\n",
    "lr_m = 1e-6\n",
    "# lr = 1e-6 началось обучение, уменьшение TrainError\n",
    "# добавить волидацию по шагам в течение эпохи обучения, а не каджые N епох\n",
    "# Добавить сохранение ошибки в файлы для построения графиков\n",
    "# проверить методы передачи сущьности (параетром, +тип, или в тексте выделяя тегами).\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"./../ruRoberta-large/\")\n",
    "    #parser.add_argument(\"--model_name\", type=str, default=\"sberbank-ai/ruRoberta-large\", help=\"Имя модели\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=512) #128\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=lr_m)\n",
    "    parser.add_argument(\"--init_checkpoint\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_data\", type=str, required=False, default=\"./../data/train_data.csv\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, required=False, default=\"./../data/validation.csv\")\n",
    "    parser.add_argument(\"--eval_data\", type=str, required=False, default=\"./../data/test.csv\")\n",
    "    parser.add_argument(\"--result\", type=str, default=f\"./result_lr_{lr_m}_ENS_Teg_multi_dropout_V3_Token_Target/\")\n",
    "    # Игнорируем аргументы Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    os.makedirs(args.result, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    print(args)  # Проверяем аргументы\n",
    "\n",
    "    base_lr = args.lr\n",
    "    min_lr = base_lr * (1/4)\n",
    "    step_size_up = 400 #400\n",
    "    best_avg_f1 = 0.0\n",
    "    \n",
    "    best_model_path = os.path.join(args.result, \"best_model.pth\")\n",
    "\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.model_name)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained(args.model_name, num_labels=3)\n",
    "    model = RobertaWithMultiSampleDropoutTarget(model_name='./../ruRoberta-large', num_labels=3, use_multi_sample_dropout=True )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset = load_data(args.train_data, tokenizer, args.max_seq_len)\n",
    "    validation_data = load_data(args.validation_data, tokenizer, args.max_seq_len)\n",
    "    eval_dataset = load_data(args.eval_data, tokenizer, args.max_seq_len)\n",
    "\n",
    "    if train_dataset is None or eval_dataset is None or validation_data is None:\n",
    "        sys.exit(f\"Ошибка загрузки данных: убедитесь, что файлы {args.train_data}, {args.validation_data} и {args.eval_data} существуют и содержат нужные колонки.\")\n",
    "\n",
    "    #сохранение текста и токенов, с дабовлением собственных\n",
    "    save_contrel_date(tokenizer,train_dataset)\n",
    "    model.roberta.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    embedding_layer = model.roberta.embeddings.word_embeddings\n",
    "    print(embedding_layer.weight[tokenizer.convert_tokens_to_ids(\"<en>\")])\n",
    "    \n",
    "    # Получаем метки классов из тренировочного датасета\n",
    "    train_labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "    # Вычисляем веса классов\n",
    "    class_weights = compute_ens_weights(train_labels, beta=0.999)\n",
    "\n",
    "    # Вывод весов классов\n",
    "    print(f\"class_weights = {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=args.batch_size)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    #scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr = base_lr, step_size_up = step_size_up, mode=\"triangular2\",cycle_momentum=False )\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        batches_per_validation = (len(train_loader) // 2)+2\n",
    "        batches_per_test = (len(train_loader) // 5)+2\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"Epoch: {epoch}/{args.epochs}\")\n",
    "            total_loss = 0\n",
    "            for i,batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Batches\")):\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                if(i % batches_per_validation == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Validation\", vall_train = True)\n",
    "                if(i % batches_per_test == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Test\", flag_print = True)\n",
    "                \n",
    "            logging.info(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Step: {len(train_loader)}\")\n",
    "            # Валидация с обратным распространением ошибки каждые 2 эпохи\n",
    "            evaluate(epoch , backprop=\"Train\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Test\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Validation\", flag_print = True, vall_train = True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def evaluate(epoch = None, backprop = \"None\", flag_print = False, vall_train = False):\n",
    "        global best_avg_f1\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        total_loss = 0\n",
    "        print(f\"evaluate, backprop: {backprop}\")\n",
    "        loader = validation_loader\n",
    "        if backprop == \"Validation\":\n",
    "            loader = validation_loader\n",
    "        elif backprop == \"Test\":\n",
    "            loader = eval_loader\n",
    "        elif backprop == \"Train\":\n",
    "            loader = train_loader\n",
    "        \n",
    "        else: loader = eval_loader\n",
    "        with torch.no_grad() if not backprop == \"Validation\" else torch.enable_grad():  # Включаем градиенты для обучения на валидации\n",
    "            for batch in loader:\n",
    "            #for batch in loader:\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if backprop == \"Validation\" and vall_train:\n",
    "                    #уменьшая тк обучающие данные удвоились\n",
    "                    loss = loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #scheduler.step()\n",
    "                    loss = loss\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        f1_pn = f1_score(all_labels, all_preds, labels=[1, 2], average='macro')\n",
    "        avg_f1 = (f1 + f1_pn) / 2\n",
    "\n",
    "        if(flag_print):\n",
    "            print()\n",
    "            print(\"--\"*20)\n",
    "            print(f\"Result evaluate in {backprop}\")\n",
    "            #logging.info(f\"{backprop} Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "            #print(classification_report(all_labels, all_preds))\n",
    "            castom_classification_report(all_labels, all_preds)\n",
    "\n",
    "        # 💾 Сохраняем модель только при улучшении средней метрики\n",
    "        if (avg_f1 > best_avg_f1) and backprop == \"Test\":\n",
    "            best_avg_f1 = avg_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            \n",
    "            print(f\"[Checkpoint] 🎯 Новый лучший средний F1: {best_avg_f1:.4f}\")\n",
    "            print(f\"[Checkpoint] 💾 Модель сохранена: {best_model_path}\")\n",
    "            # 🔸 Сохраняем значение лучшего F1 в файл\n",
    "            best_score_path = os.path.join(args.result, \"best_score.txt\")\n",
    "            save_metrics_best(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "            save_confusion_matrix(epoch, all_labels, all_preds, args.result, backprop)\n",
    "            with open(best_score_path, \"w\") as f:\n",
    "                f.write(f\"Epoch: {epoch}\\n\")\n",
    "                f.write(f\"Loss: {avg_loss:.4f}\\n\")\n",
    "                f.write(f\"F1-pn0: {f1:.4f}\\n\")\n",
    "                f.write(f\"F1-pn: {f1_pn:.4f}\\n\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "\n",
    "\n",
    "        if epoch is not None:\n",
    "            save_metrics(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "        \n",
    "    if args.init_checkpoint:\n",
    "        model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n",
    "\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4520d-65bf-4708-99bc-4807f25ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805557fd-243e-47ff-b33c-4ce8c82c159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f9444b-5431-4eb6-8ff8-9074d559598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токены сущности: ['apple', ' <|company|>']\n",
      "Форма эмбеддингов: torch.Size([2, 768])\n",
      "Размерность итогового эмбеддинга сущности: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Загружаем токенизатор и модель\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Добавим специальные токены\n",
    "special_tokens = {\"additional_special_tokens\": [\"<en>\", \"</en>\", \" <|company|>\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Пример текста\n",
    "text = \"This is <en> Apple  <|company|> </en>.\"\n",
    "\n",
    "# Токенизация\n",
    "encoding = tokenizer(text, return_tensors='pt')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "# Пропускаем через модель\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = outputs.last_hidden_state\n",
    "\n",
    "# Получаем ID спецтокенов\n",
    "en_token_id = tokenizer.convert_tokens_to_ids(\"<en>\")\n",
    "end_en_token_id = tokenizer.convert_tokens_to_ids(\"</en>\")\n",
    "\n",
    "# Извлекаем эмбеддинги сущности\n",
    "input_id = input_ids[0]\n",
    "output = sequence_output[0]\n",
    "\n",
    "# Ищем индексы <en> и </en>\n",
    "start = (input_id == en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "end = (input_id == end_en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "# Эмбеддинги между <en> и </en>\n",
    "entity_tokens = output[start + 1:end]\n",
    "\n",
    "print(f\"Токены сущности: {tokenizer.convert_ids_to_tokens(input_id[start+1:end])}\")\n",
    "print(f\"Форма эмбеддингов: {entity_tokens.shape}\")\n",
    "\n",
    "\n",
    "# Среднее по токенам сущности\n",
    "entity_embedding = entity_tokens.mean(dim=0)\n",
    "print(f\"Размерность итогового эмбеддинга сущности: {entity_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6a1a8-a39a-4a83-a3a8-9ca221a05749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ryumin_env",
   "language": "python",
   "name": "ryumin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
