{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd128c19-762d-49e7-959a-845e0599a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CyclicLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f20af-edf7-4cf5-84b3-bc8e437c24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaWithMultiSampleDropout(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3, num_dropouts=5, use_multi_sample_dropout=True):\n",
    "        super(RobertaWithMultiSampleDropout, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.use_multi_sample_dropout = use_multi_sample_dropout\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(dropout_rate) for _ in range(num_dropouts)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[0]  # последний скрытый слой\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            logits_list = []\n",
    "            for dropout in self.dropouts:\n",
    "                dropped = dropout(sequence_output[:, 0, :])  # [CLS]-токен\n",
    "                logits_list.append(self.classifier(dropped))\n",
    "            avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "        else:\n",
    "            dropped = self.dropout(sequence_output[:, 0, :])  # [CLS]-токен\n",
    "            avg_logits = self.classifier(dropped)\n",
    "\n",
    "        return SequenceClassifierOutput(logits=avg_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1746-8eac-4865-8f99-828b9055d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_best(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metrics_file = os.path.join(result_path, \"metrics_best.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Создаем словарь с метриками\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop,\n",
    "        \"loss\": loss\n",
    "    }\n",
    "\n",
    "    # Добавляем метрики по каждому классу\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "\n",
    "    # Создаем DataFrame и сохраняем его в CSV (перезапись файла)\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2886be9d-a3f4-4164-8002-b4cc31a22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ens_weights(train_labels, beta: float = 0.999):\n",
    "    train_labels = np.array(train_labels)\n",
    "    classes, counts = np.unique(train_labels, return_counts=True)\n",
    "    effective_num = (1 - np.power(beta, counts)) / (1 - beta)\n",
    "    weights = 1.0 / effective_num\n",
    "    weights = weights / np.sum(weights) * len(classes)  # нормализация как в оригинальной статье\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d52154-884f-4289-8b00-b19358f419e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tags_from_files(*file_paths):\n",
    "    all_tags = set()\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "            if \"entity_tag\" in df.columns:\n",
    "                tags = df[\"entity_tag\"].dropna().unique().tolist()\n",
    "                all_tags.update(tags)\n",
    "        except Exception as e:\n",
    "            print(f\"[Ошибка] Не удалось загрузить {path}: {e}\")\n",
    "    return sorted(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be23ac59-6617-40d9-b01b-be5ff22e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, tokenizer, max_seq_len):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # Загружаем CSV (TSV)\n",
    "\n",
    "        # Проверка нужных колонок\n",
    "        required_columns = {\n",
    "            \"sentence\", \"entity\", \"label\", \"entity_tag\",\n",
    "            \"entity_pos_start_rel\", \"entity_pos_end_rel\"\n",
    "        }\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Ожидаемые колонки: {required_columns}, но в файле: {df.columns}\")\n",
    "\n",
    "        # Заменяем -1 на 2 (если есть)\n",
    "        df[\"label\"] = df[\"label\"].replace(-1, 2)\n",
    "\n",
    "        # Размечаем предложения с [ENTITY] токенами\n",
    "        def mark_entity_inline(row):\n",
    "            sent = row[\"sentence\"]\n",
    "            start = row[\"entity_pos_start_rel\"]\n",
    "            end = row[\"entity_pos_end_rel\"]\n",
    "            tag = row[\"entity_tag\"]\n",
    "            tag_token = f\"<en>\"\n",
    "            tag_token_close = f\"</en>\"\n",
    "            return (\n",
    "                sent[:start] +\n",
    "                f\"{tag_token}\" + sent[start:end] + f\"{tag_token_close}\" +\n",
    "                sent[end:]\n",
    "            )\n",
    "\n",
    "        df[\"input_text\"] = df.apply(mark_entity_inline, axis=1)\n",
    "        texts = df[\"input_text\"].tolist()\n",
    "        labels = torch.tensor(df[\"label\"].astype(int).tolist(), dtype=torch.long)\n",
    "\n",
    "        # Токенизируем\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True,\n",
    "                              max_length=max_seq_len, return_tensors='pt')\n",
    "        dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "        return dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Файл {file_path} не найден!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbfe22-f0f3-4f70-b366-53259c79ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_metrics(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    metrics_file = os.path.join(result_path, \"metrics_class_weights.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    \n",
    "    # Создаем DataFrame для метрик\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop , # (Добавлено)\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    \n",
    "    # Добавляем метрики для каждого класса\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):  # Пропускаем 'accuracy', так как это float\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    # Создаем DataFrame и сохраняем в CSV\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='a', header=not os.path.exists(metrics_file), index=False)\n",
    "\n",
    "def save_confusion_matrix(epoch, y_true, y_pred, result_path,backprop):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"Pred_0\", \"Pred_1\", \"Pred_2\"], index=[\"True_0\", \"True_1\", \"True_2\"])\n",
    "    cm_file = os.path.join(result_path, f\"confusion_matrix_class_weights_epoch_{epoch}_backprop_{backprop}.csv\")\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd447891-39c3-42bc-981d-96b2800a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def castom_classification_report(all_labels, all_preds):\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    data = []\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):  # Для всех метрик, кроме accuracy\n",
    "            row = {'label': label}\n",
    "            for metric, value in metrics.items():\n",
    "                row[metric] = round(value * 100, 3) if metric != 'support' else value\n",
    "            data.append(row)\n",
    "        else:  # Для accuracy\n",
    "            data.append({'label': 'accuracy', 'precision': round(metrics * 100, 3), 'recall': None, 'f1-score': None, 'support': None})\n",
    "\n",
    "    # Добавляем macro F1 для классов 1 и 2\n",
    "    if '1' in report and '2' in report:\n",
    "        f1_1 = report['1']['f1-score']\n",
    "        f1_2 = report['2']['f1-score']\n",
    "        f1_macro_1_2 = (f1_1 + f1_2) / 2\n",
    "        data.append({\n",
    "            'label': 'avg f1 (class 1&2)',\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': round(f1_macro_1_2 * 100, 3),\n",
    "            'support': None\n",
    "        })\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = [''] * len(df)\n",
    "\n",
    "    # Выводим таблицу\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447e1ed-4fc6-43aa-a54c-d9023898afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(flag = False):\n",
    "    # Формируем список специальных токенов\n",
    "    if not flag: return None\n",
    "    special_tokens = {\n",
    "        \"additional_special_tokens\": \n",
    "            [\"<en>\", \"</en>\"]\n",
    "    }\n",
    "\n",
    "    print(\"Добавленные специальные токены:\")\n",
    "    for token in special_tokens[\"additional_special_tokens\"]:\n",
    "        print(token)\n",
    "    return special_tokens\n",
    "\n",
    "def save_contrel_date(tokenizer, train_dataset):\n",
    "    special_tokens = add_token(flag = True)\n",
    "    if special_tokens != None: \n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "    tokenizer.save_pretrained(os.path.join(args.result, \"tokenizer\"))\n",
    "    print(tokenizer.special_tokens_map)\n",
    "    print(tokenizer.additional_special_tokens)\n",
    "\n",
    "    \n",
    "    file_control_text = os.path.join(args.result, \"use_market_text.txt\")\n",
    "    input_ids, attention_mask, label = train_dataset[0]\n",
    "    decoded_text_token = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    with open(file_control_text, \"w\") as f:\n",
    "        f.write(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "        f.write(f\"Text:\\n{decoded_text}\\n\\n\")\n",
    "    print(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "    print(f\"Text:\\n{decoded_text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af33277-341d-43ba-8b31-c9bba05cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_name='./ruRoberta-large/', max_seq_len=512, batch_size=16, epochs=10, lr=1e-06, init_checkpoint=None, train_data='./data/train_data.csv', validation_data='./data/validation.csv', eval_data='./data/test.csv', result='./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавленные специальные токены:\n",
      "<en>\n",
      "</en>\n",
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<en>', '</en>']}\n",
      "['<en>', '</en>']\n",
      "Text token:\n",
      "<s>Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена </en> остановить бой, но тот хотел продолжать.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "\n",
      "\n",
      "Text:\n",
      "Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена </en> остановить бой, но тот хотел продолжать.\n",
      "\n",
      "\n",
      "class_weights = tensor([0.7001, 1.2066, 1.0934])\n",
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  20%|██        | 85/415 [00:44<02:52,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8095\n",
      "F1-macro: 0.2911\n",
      "F1-pn: 0.0210\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.731  98.864    83.140    616.0\n",
      "                 1      0.000   0.000     0.000    111.0\n",
      "                 2     30.000   2.256     4.196    133.0\n",
      "          accuracy     71.163     NaN       NaN      NaN\n",
      "         macro avg     33.910  33.706    29.112    860.0\n",
      "      weighted avg     56.019  71.163    60.200    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     2.098      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  21%|██        | 86/415 [00:53<16:19,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1560\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.8095\n",
      "F1-macro: 0.2911\n",
      "F1-pn: 0.0210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 170/415 [01:36<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  41%|████      | 171/415 [01:43<09:58,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7588\n",
      "F1-macro: 0.2837\n",
      "F1-pn: 0.0088\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.645  99.675    83.367    616.0\n",
      "                 1     33.333   0.901     1.754    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.512     NaN       NaN      NaN\n",
      "         macro avg     34.993  33.525    28.374    860.0\n",
      "      weighted avg     55.620  71.512    59.941    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.877      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  50%|█████     | 209/415 [02:03<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  61%|██████▏   | 255/415 [03:13<01:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7456\n",
      "F1-macro: 0.3163\n",
      "F1-pn: 0.0555\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.373  99.513    83.800    616.0\n",
      "                 1     57.143   3.604     6.780    111.0\n",
      "                 2     50.000   2.256     4.317    133.0\n",
      "          accuracy     72.093     NaN       NaN      NaN\n",
      "         macro avg     59.839  35.124    31.632    860.0\n",
      "      weighted avg     66.947  72.093    61.567    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     5.548      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  62%|██████▏   | 256/415 [03:23<09:16,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1859\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.7456\n",
      "F1-macro: 0.3163\n",
      "F1-pn: 0.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 340/415 [04:07<00:38,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7031\n",
      "F1-macro: 0.3661\n",
      "F1-pn: 0.1315\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     73.026  97.565    83.530    616.0\n",
      "                 1     80.000   3.604     6.897    111.0\n",
      "                 2     50.000  12.030    19.394    133.0\n",
      "          accuracy     72.209     NaN       NaN      NaN\n",
      "         macro avg     67.675  37.733    36.607    860.0\n",
      "      weighted avg     70.365  72.209    63.720    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    13.145      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 341/415 [04:19<04:45,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2488\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.7031\n",
      "F1-macro: 0.3661\n",
      "F1-pn: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches: 100%|██████████| 415/415 [04:57<00:00,  1.39it/s]\n",
      "INFO:root:Epoch 1, Loss: 0.8879664482840572, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.7598\n",
      "F1-macro: 0.4211\n",
      "F1-pn: 0.2098\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.729  96.816    84.351   4774.0\n",
      "                 1     68.750   5.140     9.565    856.0\n",
      "                 2     58.247  22.443    32.401   1007.0\n",
      "          accuracy     73.708     NaN       NaN      NaN\n",
      "         macro avg     67.242  41.466    42.106   6637.0\n",
      "      weighted avg     71.457  73.708    66.823   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    20.983      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6799\n",
      "F1-macro: 0.4016\n",
      "F1-pn: 0.1848\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     73.756  96.266    83.521    616.0\n",
      "                 1     83.333   4.505     8.547    111.0\n",
      "                 2     52.000  19.549    28.415    133.0\n",
      "          accuracy     72.558     NaN       NaN      NaN\n",
      "         macro avg     69.697  40.107    40.161    860.0\n",
      "      weighted avg     71.628  72.558    65.322    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    18.481      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2932\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.6799\n",
      "F1-macro: 0.4016\n",
      "F1-pn: 0.1848\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.6965\n",
      "F1-macro: 0.4366\n",
      "F1-pn: 0.2232\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     76.401  99.230    86.332   1429.0\n",
      "                 1     38.462   1.992     3.788    251.0\n",
      "                 2     74.138  28.197    40.855    305.0\n",
      "          accuracy     76.020     NaN       NaN      NaN\n",
      "         macro avg     63.000  43.140    43.658   1985.0\n",
      "      weighted avg     71.256  76.020    68.907   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    22.321      NaN\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  20%|██        | 85/415 [00:44<02:51,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6488\n",
      "F1-macro: 0.4850\n",
      "F1-pn: 0.3067\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.880  94.481    84.165    616.0\n",
      "                 1     64.000  14.414    23.529    111.0\n",
      "                 2     55.882  28.571    37.811    133.0\n",
      "          accuracy     73.953     NaN       NaN      NaN\n",
      "         macro avg     65.254  45.822    48.502    860.0\n",
      "      weighted avg     71.254  73.953    69.170    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    30.670      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  21%|██        | 86/415 [00:54<19:05,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3959\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.6488\n",
      "F1-macro: 0.4850\n",
      "F1-pn: 0.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 170/415 [01:38<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6379\n",
      "F1-macro: 0.5887\n",
      "F1-pn: 0.4585\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.406  89.935    84.904    616.0\n",
      "                 1     56.452  31.532    40.462    111.0\n",
      "                 2     56.881  46.617    51.240    133.0\n",
      "          accuracy     75.698     NaN       NaN      NaN\n",
      "         macro avg     64.580  56.028    58.869    860.0\n",
      "      weighted avg     73.676  75.698    73.962    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    45.851      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 171/415 [01:48<14:11,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5236\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.6379\n",
      "F1-macro: 0.5887\n",
      "F1-pn: 0.4585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  50%|█████     | 209/415 [02:08<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  61%|██████▏   | 255/415 [03:18<01:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  62%|██████▏   | 256/415 [03:25<06:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5966\n",
      "F1-macro: 0.5381\n",
      "F1-pn: 0.3846\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.099  92.045    84.501    616.0\n",
      "                 1     66.667  16.216    26.087    111.0\n",
      "                 2     57.009  45.865    50.833    133.0\n",
      "          accuracy     75.116     NaN       NaN      NaN\n",
      "         macro avg     67.258  51.375    53.807    860.0\n",
      "      weighted avg     73.362  75.116    71.755    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    38.460      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 340/415 [04:09<00:38,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 341/415 [04:16<03:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5712\n",
      "F1-macro: 0.5801\n",
      "F1-pn: 0.4442\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     79.745  91.396    85.174    616.0\n",
      "                 1     66.667  25.225    36.601    111.0\n",
      "                 2     57.143  48.120    52.245    133.0\n",
      "          accuracy     76.163     NaN       NaN      NaN\n",
      "         macro avg     67.852  54.914    58.007    860.0\n",
      "      weighted avg     74.562  76.163    73.812    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    44.423      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches: 100%|██████████| 415/415 [04:54<00:00,  1.41it/s]\n",
      "INFO:root:Epoch 2, Loss: 0.7206249496304845, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.5738\n",
      "F1-macro: 0.6740\n",
      "F1-pn: 0.5728\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.425  89.987    87.647   4774.0\n",
      "                 1     70.507  35.748    47.442    856.0\n",
      "                 2     62.351  72.691    67.125   1007.0\n",
      "          accuracy     80.368     NaN       NaN      NaN\n",
      "         macro avg     72.761  66.142    67.405   6637.0\n",
      "      weighted avg     80.000  80.368    79.348   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    57.284      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5647\n",
      "F1-macro: 0.6073\n",
      "F1-pn: 0.4838\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.002  87.987    85.422    616.0\n",
      "                 1     66.667  27.027    38.462    111.0\n",
      "                 2     53.086  64.662    58.305    133.0\n",
      "          accuracy     76.512     NaN       NaN      NaN\n",
      "         macro avg     67.585  59.892    60.729    860.0\n",
      "      weighted avg     76.267  76.512    75.167    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    48.383      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5456\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5647\n",
      "F1-macro: 0.6073\n",
      "F1-pn: 0.4838\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.5160\n",
      "F1-macro: 0.5833\n",
      "F1-pn: 0.4382\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.907  94.892    87.343   1429.0\n",
      "                 1     36.957  13.546    19.825    251.0\n",
      "                 2     81.567  58.033    67.816    305.0\n",
      "          accuracy     78.942     NaN       NaN      NaN\n",
      "         macro avg     66.477  55.490    58.328   1985.0\n",
      "      weighted avg     75.451  78.942    75.805   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    43.821      NaN\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  20%|██        | 85/415 [00:44<02:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  21%|██        | 86/415 [00:51<13:29,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5433\n",
      "F1-macro: 0.6034\n",
      "F1-pn: 0.4743\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.871  90.909    86.154    616.0\n",
      "                 1     60.784  27.928    38.272    111.0\n",
      "                 2     58.400  54.887    56.589    133.0\n",
      "          accuracy     77.209     NaN       NaN      NaN\n",
      "         macro avg     67.019  57.908    60.338    860.0\n",
      "      weighted avg     75.520  77.209    75.401    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    47.430      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 170/415 [01:34<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5271\n",
      "F1-macro: 0.6311\n",
      "F1-pn: 0.5135\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.661  89.773    86.609    616.0\n",
      "                 1     53.165  37.838    44.211    111.0\n",
      "                 2     61.667  55.639    58.498    133.0\n",
      "          accuracy     77.791     NaN       NaN      NaN\n",
      "         macro avg     66.164  61.083    63.106    860.0\n",
      "      weighted avg     76.323  77.791    76.789    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    51.354      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 171/415 [01:45<14:07,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5723\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5271\n",
      "F1-macro: 0.6311\n",
      "F1-pn: 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  50%|█████     | 209/415 [02:05<01:46,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  61%|██████▏   | 255/415 [03:15<01:23,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  62%|██████▏   | 256/415 [03:22<06:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5265\n",
      "F1-macro: 0.6158\n",
      "F1-pn: 0.4919\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.349  92.045    86.367    616.0\n",
      "                 1     56.944  36.937    44.809    111.0\n",
      "                 2     65.934  45.113    53.571    133.0\n",
      "          accuracy     77.674     NaN       NaN      NaN\n",
      "         macro avg     68.076  58.032    61.582    860.0\n",
      "      weighted avg     75.815  77.674    75.931    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    49.190      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 340/415 [04:05<00:38,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5018\n",
      "F1-macro: 0.6476\n",
      "F1-pn: 0.5373\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.939  89.935    86.834    616.0\n",
      "                 1     63.492  36.036    45.977    111.0\n",
      "                 2     60.584  62.406    61.481    133.0\n",
      "          accuracy     78.721     NaN       NaN      NaN\n",
      "         macro avg     69.338  62.792    64.764    860.0\n",
      "      weighted avg     77.688  78.721    77.640    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    53.729      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 341/415 [04:16<04:16,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5925\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5018\n",
      "F1-macro: 0.6476\n",
      "F1-pn: 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches: 100%|██████████| 415/415 [04:54<00:00,  1.41it/s]\n",
      "INFO:root:Epoch 3, Loss: 0.5672602651169502, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4338\n",
      "F1-macro: 0.7751\n",
      "F1-pn: 0.7102\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.731  90.218    90.474   4774.0\n",
      "                 1     70.121  60.864    65.166    856.0\n",
      "                 2     72.188  82.224    76.880   1007.0\n",
      "          accuracy     85.219     NaN       NaN      NaN\n",
      "         macro avg     77.680  77.769    77.507   6637.0\n",
      "      weighted avg     85.259  85.219    85.147   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    71.023      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5006\n",
      "F1-macro: 0.6796\n",
      "F1-pn: 0.5841\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.914  86.201    87.049    616.0\n",
      "                 1     56.989  47.748    51.961    111.0\n",
      "                 2     58.896  72.180    64.865    133.0\n",
      "          accuracy     79.070     NaN       NaN      NaN\n",
      "         macro avg     67.933  68.710    67.958    860.0\n",
      "      weighted avg     79.435  79.070    79.089    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.413      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6319\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5006\n",
      "F1-macro: 0.6796\n",
      "F1-pn: 0.5841\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.3790\n",
      "F1-macro: 0.7179\n",
      "F1-pn: 0.6231\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.974  96.081    90.747   1429.0\n",
      "                 1     63.492  31.873    42.440    251.0\n",
      "                 2     88.931  76.393    82.187    305.0\n",
      "          accuracy     84.937     NaN       NaN      NaN\n",
      "         macro avg     79.466  68.116    71.791   1985.0\n",
      "      weighted avg     83.585  84.937    83.323   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.314      NaN\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  20%|██        | 85/415 [00:44<02:51,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5258\n",
      "F1-macro: 0.6825\n",
      "F1-pn: 0.5952\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.000  81.818    85.714    616.0\n",
      "                 1     52.756  60.360    56.303    111.0\n",
      "                 2     55.491  72.180    62.745    133.0\n",
      "          accuracy     77.558     NaN       NaN      NaN\n",
      "         macro avg     66.082  71.453    68.254    860.0\n",
      "      weighted avg     79.856  77.558    78.366    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    59.524      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  21%|██        | 86/415 [00:54<18:58,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6389\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5258\n",
      "F1-macro: 0.6825\n",
      "F1-pn: 0.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 170/415 [01:38<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4922\n",
      "F1-macro: 0.7050\n",
      "F1-pn: 0.6170\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.884  88.312    88.097    616.0\n",
      "                 1     61.856  54.054    57.692    111.0\n",
      "                 2     63.194  68.421    65.704    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.978  70.262    70.498    860.0\n",
      "      weighted avg     80.706  80.814    80.710    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.698      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 171/415 [01:48<14:14,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6610\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.4922\n",
      "F1-macro: 0.7050\n",
      "F1-pn: 0.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  50%|█████     | 209/415 [02:08<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  61%|██████▏   | 255/415 [03:18<01:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  62%|██████▏   | 256/415 [03:25<06:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4886\n",
      "F1-macro: 0.6658\n",
      "F1-pn: 0.5619\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.647  89.123    87.351    616.0\n",
      "                 1     54.023  42.342    47.475    111.0\n",
      "                 2     65.152  64.662    64.906    133.0\n",
      "          accuracy     79.302     NaN       NaN      NaN\n",
      "         macro avg     68.274  65.376    66.577    860.0\n",
      "      weighted avg     78.396  79.302    78.733    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    56.190      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 340/415 [04:09<00:38,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4829\n",
      "F1-macro: 0.7059\n",
      "F1-pn: 0.6176\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.351  87.175    88.250    616.0\n",
      "                 1     57.407  55.856    56.621    111.0\n",
      "                 2     62.914  71.429    66.901    133.0\n",
      "          accuracy     80.698     NaN       NaN      NaN\n",
      "         macro avg     69.891  71.487    70.591    860.0\n",
      "      weighted avg     81.140  80.698    80.866    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.761      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 341/415 [04:19<04:17,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6618\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.4829\n",
      "F1-macro: 0.7059\n",
      "F1-pn: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches: 100%|██████████| 415/415 [04:58<00:00,  1.39it/s]\n",
      "INFO:root:Epoch 4, Loss: 0.44242986939757706, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3272\n",
      "F1-macro: 0.8377\n",
      "F1-pn: 0.7921\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     93.844  91.956    92.890   4774.0\n",
      "                 1     77.160  73.014    75.030    856.0\n",
      "                 2     78.242  89.275    83.395   1007.0\n",
      "          accuracy     89.107     NaN       NaN      NaN\n",
      "         macro avg     83.082  84.749    83.772   6637.0\n",
      "      weighted avg     89.325  89.107    89.146   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    79.213      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4858\n",
      "F1-macro: 0.6965\n",
      "F1-pn: 0.6076\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.189  85.714    87.417    616.0\n",
      "                 1     56.190  53.153    54.630    111.0\n",
      "                 2     60.736  74.436    66.892    133.0\n",
      "          accuracy     79.767     NaN       NaN      NaN\n",
      "         macro avg     68.705  71.101    69.646    860.0\n",
      "      weighted avg     80.530  79.767    80.011    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.761      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.2694\n",
      "F1-macro: 0.8284\n",
      "F1-pn: 0.7720\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.094  97.341    94.114   1429.0\n",
      "                 1     81.707  53.386    64.578    251.0\n",
      "                 2     91.497  88.197    89.816    305.0\n",
      "          accuracy     90.378     NaN       NaN      NaN\n",
      "         macro avg     88.099  79.641    82.836   1985.0\n",
      "      weighted avg     89.969  90.378    89.719   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    77.197      NaN\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  20%|██        | 85/415 [00:44<02:51,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5211\n",
      "F1-macro: 0.7073\n",
      "F1-pn: 0.6258\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.727  82.792    87.031    616.0\n",
      "                 1     57.143  61.261    59.130    111.0\n",
      "                 2     56.757  78.947    66.038    133.0\n",
      "          accuracy     79.419     NaN       NaN      NaN\n",
      "         macro avg     68.542  74.334    70.733    860.0\n",
      "      weighted avg     81.855  79.419    80.183    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.584      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  21%|██        | 86/415 [00:54<19:01,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6666\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5211\n",
      "F1-macro: 0.7073\n",
      "F1-pn: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 170/415 [01:38<02:07,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4918\n",
      "F1-macro: 0.7279\n",
      "F1-pn: 0.6484\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.252  87.175    88.687    616.0\n",
      "                 1     61.062  62.162    61.607    111.0\n",
      "                 2     63.816  72.932    68.070    133.0\n",
      "          accuracy     81.744     NaN       NaN      NaN\n",
      "         macro avg     71.710  74.090    72.788    860.0\n",
      "      weighted avg     82.396  81.744    82.003    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.839      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 171/415 [01:48<13:57,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6881\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.4918\n",
      "F1-macro: 0.7279\n",
      "F1-pn: 0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  50%|█████     | 209/415 [02:08<01:46,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  61%|██████▏   | 255/415 [03:18<01:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  62%|██████▏   | 256/415 [03:25<06:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5023\n",
      "F1-macro: 0.7071\n",
      "F1-pn: 0.6163\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.595  91.234    88.854    616.0\n",
      "                 1     60.606  54.054    57.143    111.0\n",
      "                 2     72.321  60.902    66.122    133.0\n",
      "          accuracy     81.744     NaN       NaN      NaN\n",
      "         macro avg     73.174  68.730    70.706    860.0\n",
      "      weighted avg     81.033  81.744    81.245    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.633      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 340/415 [04:08<00:39,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 341/415 [04:15<03:01,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4900\n",
      "F1-macro: 0.7090\n",
      "F1-pn: 0.6236\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.987  87.987    87.987    616.0\n",
      "                 1     58.559  58.559    58.559    111.0\n",
      "                 2     66.165  66.165    66.165    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.904  70.904    70.904    860.0\n",
      "      weighted avg     80.814  80.814    80.814    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.362      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches: 100%|██████████| 415/415 [04:54<00:00,  1.41it/s]\n",
      "INFO:root:Epoch 5, Loss: 0.3257912185626576, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.2213\n",
      "F1-macro: 0.9023\n",
      "F1-pn: 0.8748\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     96.869  94.617    95.730   4774.0\n",
      "                 1     81.216  87.383    84.187    856.0\n",
      "                 2     88.794  92.850    90.777   1007.0\n",
      "          accuracy     93.416     NaN       NaN      NaN\n",
      "         macro avg     88.960  91.617    90.231   6637.0\n",
      "      weighted avg     93.625  93.416    93.489   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    87.482      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4907\n",
      "F1-macro: 0.7241\n",
      "F1-pn: 0.6439\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.933  87.013    88.449    616.0\n",
      "                 1     58.400  65.766    61.864    111.0\n",
      "                 2     65.468  68.421    66.912    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.267  73.733    72.408    860.0\n",
      "      weighted avg     82.079  81.395    81.687    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.388      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1506\n",
      "F1-macro: 0.9246\n",
      "F1-pn: 0.9010\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     95.415  99.020    97.184   1429.0\n",
      "                 1     93.204  76.494    84.026    251.0\n",
      "                 2     97.635  94.754    96.173    305.0\n",
      "          accuracy     95.516     NaN       NaN      NaN\n",
      "         macro avg     95.418  90.089    92.461   1985.0\n",
      "      weighted avg     95.476  95.516    95.365   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    90.100      NaN\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  20%|██        | 85/415 [00:44<02:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  21%|██        | 86/415 [00:51<13:31,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5237\n",
      "F1-macro: 0.7216\n",
      "F1-pn: 0.6410\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.460  86.201    88.279    616.0\n",
      "                 1     55.072  68.468    61.044    111.0\n",
      "                 2     66.667  67.669    67.164    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     70.733  74.113    72.163    860.0\n",
      "      weighted avg     82.213  81.047    81.499    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.104      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 170/415 [01:35<02:07,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5075\n",
      "F1-macro: 0.7346\n",
      "F1-pn: 0.6600\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.782  87.013    88.376    616.0\n",
      "                 1     62.069  64.865    63.436    111.0\n",
      "                 2     65.306  72.180    68.571    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.386  74.686    73.461    860.0\n",
      "      weighted avg     82.420  81.860    82.094    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.004      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 171/415 [01:45<14:08,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6973\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_32_multi_dropout_V3_Token/best_model.pth\n",
      "Loss: 0.5075\n",
      "F1-macro: 0.7346\n",
      "F1-pn: 0.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  50%|█████     | 209/415 [02:05<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  61%|██████▏   | 255/415 [03:15<01:22,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  62%|██████▏   | 256/415 [03:22<06:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5165\n",
      "F1-macro: 0.7261\n",
      "F1-pn: 0.6458\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.387  88.961    88.673    616.0\n",
      "                 1     63.208  60.360    61.751    111.0\n",
      "                 2     67.164  67.669    67.416    133.0\n",
      "          accuracy     81.977     NaN       NaN      NaN\n",
      "         macro avg     72.920  72.330    72.613    860.0\n",
      "      weighted avg     81.855  81.977    81.911    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.583      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 340/415 [04:06<00:38,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 341/415 [04:13<03:02,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5087\n",
      "F1-macro: 0.7291\n",
      "F1-pn: 0.6495\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.735  87.987    88.852    616.0\n",
      "                 1     61.947  63.063    62.500    111.0\n",
      "                 2     65.035  69.925    67.391    133.0\n",
      "          accuracy     81.977     NaN       NaN      NaN\n",
      "         macro avg     72.239  73.658    72.915    860.0\n",
      "      weighted avg     82.329  81.977    82.132    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.946      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches: 100%|██████████| 415/415 [04:51<00:00,  1.42it/s]\n",
      "INFO:root:Epoch 6, Loss: 0.2172641000429909, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1291\n",
      "F1-macro: 0.9541\n",
      "F1-pn: 0.9411\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     97.950  98.094    98.022   4774.0\n",
      "                 1     92.781  91.589    92.181    856.0\n",
      "                 2     95.846  96.226    96.036   1007.0\n",
      "          accuracy     96.972     NaN       NaN      NaN\n",
      "         macro avg     95.526  95.303    95.413   6637.0\n",
      "      weighted avg     96.964  96.972    96.967   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    94.108      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5056\n",
      "F1-macro: 0.7241\n",
      "F1-pn: 0.6435\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.480  89.610    88.532    616.0\n",
      "                 1     63.107  58.559    60.748    111.0\n",
      "                 2     69.841  66.165    67.954    133.0\n",
      "          accuracy     81.977     NaN       NaN      NaN\n",
      "         macro avg     73.476  71.445    72.411    860.0\n",
      "      weighted avg     81.606  81.977    81.764    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.351      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0749\n",
      "F1-macro: 0.9750\n",
      "F1-pn: 0.9665\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.752  99.650    99.199   1429.0\n",
      "                 1     97.490  92.829    95.102    251.0\n",
      "                 2     98.355  98.033    98.194    305.0\n",
      "          accuracy     98.539     NaN       NaN      NaN\n",
      "         macro avg     98.199  96.837    97.498   1985.0\n",
      "      weighted avg     98.531  98.539    98.526   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    96.648      NaN\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  20%|██        | 85/415 [00:44<02:51,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  21%|██        | 86/415 [00:51<13:31,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5684\n",
      "F1-macro: 0.7205\n",
      "F1-pn: 0.6387\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.821  88.961    88.387    616.0\n",
      "                 1     62.264  59.459    60.829    111.0\n",
      "                 2     67.692  66.165    66.920    133.0\n",
      "          accuracy     81.628     NaN       NaN      NaN\n",
      "         macro avg     72.592  71.529    72.046    860.0\n",
      "      weighted avg     81.409  81.628    81.510    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.875      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 170/415 [01:35<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 171/415 [01:42<10:01,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5603\n",
      "F1-macro: 0.7250\n",
      "F1-pn: 0.6426\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.710  89.286    88.997    616.0\n",
      "                 1     62.963  61.261    62.100    111.0\n",
      "                 2     66.667  66.165    66.415    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.780  72.237    72.504    860.0\n",
      "      weighted avg     81.978  82.093    82.033    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.258      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  50%|█████     | 209/415 [02:01<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  61%|██████▏   | 255/415 [03:12<01:23,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  62%|██████▏   | 256/415 [03:19<06:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5802\n",
      "F1-macro: 0.7265\n",
      "F1-pn: 0.6443\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.728  89.448    89.086    616.0\n",
      "                 1     60.345  63.063    61.674    111.0\n",
      "                 2     69.919  64.662    67.188    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.997  72.391    72.649    860.0\n",
      "      weighted avg     82.156  82.209    82.162    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.431      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 340/415 [04:02<00:39,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 341/415 [04:09<03:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5677\n",
      "F1-macro: 0.7296\n",
      "F1-pn: 0.6518\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.535  87.500    88.506    616.0\n",
      "                 1     57.812  66.667    61.925    111.0\n",
      "                 2     69.231  67.669    68.441    133.0\n",
      "          accuracy     81.744     NaN       NaN      NaN\n",
      "         macro avg     72.193  73.945    72.957    860.0\n",
      "      weighted avg     82.300  81.744    81.972    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.183      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches: 100%|██████████| 415/415 [04:48<00:00,  1.44it/s]\n",
      "INFO:root:Epoch 7, Loss: 0.11927447977464602, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0586\n",
      "F1-macro: 0.9825\n",
      "F1-pn: 0.9772\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.683  98.932    99.306   4774.0\n",
      "                 1     95.588  98.715    97.126    856.0\n",
      "                 2     97.931  98.709    98.318   1007.0\n",
      "          accuracy     98.870     NaN       NaN      NaN\n",
      "         macro avg     97.734  98.785    98.250   6637.0\n",
      "      weighted avg     98.889  98.870    98.875   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    97.722      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5758\n",
      "F1-macro: 0.7286\n",
      "F1-pn: 0.6485\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.943  88.799    88.871    616.0\n",
      "                 1     60.169  63.964    62.009    111.0\n",
      "                 2     69.291  66.165    67.692    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.801  72.976    72.857    860.0\n",
      "      weighted avg     82.190  82.093    82.128    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.851      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0316\n",
      "F1-macro: 0.9948\n",
      "F1-pn: 0.9934\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.651  99.860    99.755   1429.0\n",
      "                 1     99.200  98.805    99.002    251.0\n",
      "                 2    100.000  99.344    99.671    305.0\n",
      "          accuracy     99.647     NaN       NaN      NaN\n",
      "         macro avg     99.617  99.336    99.476   1985.0\n",
      "      weighted avg     99.647  99.647    99.647   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.337      NaN\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  20%|██        | 85/415 [00:44<02:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  21%|██        | 86/415 [00:51<13:32,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6321\n",
      "F1-macro: 0.7135\n",
      "F1-pn: 0.6291\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.482  87.013    88.230    616.0\n",
      "                 1     54.412  66.667    59.919    111.0\n",
      "                 2     68.000  63.910    65.891    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.631  72.530    71.347    860.0\n",
      "      weighted avg     81.634  80.814    81.122    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.905      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 170/415 [01:35<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 171/415 [01:42<10:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6314\n",
      "F1-macro: 0.7212\n",
      "F1-pn: 0.6377\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.548  89.123    88.835    616.0\n",
      "                 1     60.360  60.360    60.360    111.0\n",
      "                 2     68.217  66.165    67.176    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.375  71.883    72.124    860.0\n",
      "      weighted avg     81.766  81.860    81.810    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.768      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  50%|█████     | 209/415 [02:01<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  61%|██████▏   | 255/415 [03:11<01:23,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  62%|██████▏   | 256/415 [03:18<06:32,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6687\n",
      "F1-macro: 0.7191\n",
      "F1-pn: 0.6343\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.179  89.610    88.889    616.0\n",
      "                 1     60.177  61.261    60.714    111.0\n",
      "                 2     69.421  63.158    66.142    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.592  71.343    71.915    860.0\n",
      "      weighted avg     81.664  81.860    81.735    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.428      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 340/415 [04:02<00:39,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 341/415 [04:09<03:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6595\n",
      "F1-macro: 0.7149\n",
      "F1-pn: 0.6324\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.167  86.851    87.993    616.0\n",
      "                 1     56.452  63.063    59.574    111.0\n",
      "                 2     66.176  67.669    66.914    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.598  72.528    71.494    860.0\n",
      "      weighted avg     81.389  80.814    81.066    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.244      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches: 100%|██████████| 415/415 [04:48<00:00,  1.44it/s]\n",
      "INFO:root:Epoch 8, Loss: 0.05299506319956068, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0244\n",
      "F1-macro: 0.9947\n",
      "F1-pn: 0.9928\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.874  99.811    99.843   4774.0\n",
      "                 1     99.415  99.182    99.298    856.0\n",
      "                 2     99.012  99.503    99.257   1007.0\n",
      "          accuracy     99.684     NaN       NaN      NaN\n",
      "         macro avg     99.434  99.499    99.466   6637.0\n",
      "      weighted avg     99.684  99.684    99.684   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.278      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6724\n",
      "F1-macro: 0.7168\n",
      "F1-pn: 0.6308\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.957  90.909    88.889    616.0\n",
      "                 1     64.211  54.955    59.223    111.0\n",
      "                 2     70.248  63.910    66.929    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     73.805  69.925    71.680    860.0\n",
      "      weighted avg     81.437  82.093    81.664    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.076      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0113\n",
      "F1-macro: 0.9980\n",
      "F1-pn: 0.9972\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.930 100.000    99.965   1429.0\n",
      "                 1     99.602  99.602    99.602    251.0\n",
      "                 2    100.000  99.672    99.836    305.0\n",
      "          accuracy     99.899     NaN       NaN      NaN\n",
      "         macro avg     99.844  99.758    99.801   1985.0\n",
      "      weighted avg     99.899  99.899    99.899   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.719      NaN\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  20%|██        | 85/415 [00:44<02:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  21%|██        | 86/415 [00:51<13:31,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7239\n",
      "F1-macro: 0.7116\n",
      "F1-pn: 0.6273\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.380  87.662    88.020    616.0\n",
      "                 1     56.911  63.063    59.829    111.0\n",
      "                 2     67.460  63.910    65.637    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.917  71.545    71.162    860.0\n",
      "      weighted avg     81.083  80.814    80.920    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.733      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 170/415 [01:35<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 171/415 [01:42<10:03,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7243\n",
      "F1-macro: 0.7146\n",
      "F1-pn: 0.6294\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.350  88.636    88.493    616.0\n",
      "                 1     59.813  57.658    58.716    111.0\n",
      "                 2     66.667  67.669    67.164    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.610  71.321    71.457    860.0\n",
      "      weighted avg     81.313  81.395    81.351    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.940      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  50%|█████     | 209/415 [02:01<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  61%|██████▏   | 255/415 [03:12<01:23,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  62%|██████▏   | 256/415 [03:19<06:33,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7450\n",
      "F1-macro: 0.7171\n",
      "F1-pn: 0.6326\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.889  88.312    88.599    616.0\n",
      "                 1     58.824  63.063    60.870    111.0\n",
      "                 2     66.667  64.662    65.649    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.460  72.012    71.706    860.0\n",
      "      weighted avg     81.572  81.395    81.471    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.259      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 340/415 [04:02<00:39,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 341/415 [04:09<03:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7166\n",
      "F1-macro: 0.7266\n",
      "F1-pn: 0.6448\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.585  89.448    89.015    616.0\n",
      "                 1     63.810  60.360    62.037    111.0\n",
      "                 2     66.917  66.917    66.917    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     73.104  72.242    72.656    860.0\n",
      "      weighted avg     82.036  82.209    82.115    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.477      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches: 100%|██████████| 415/415 [04:48<00:00,  1.44it/s]\n",
      "INFO:root:Epoch 9, Loss: 0.02304945271209735, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0120\n",
      "F1-macro: 0.9983\n",
      "F1-pn: 0.9978\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.979  99.895    99.937   4774.0\n",
      "                 1     99.534  99.883    99.708    856.0\n",
      "                 2     99.802  99.901    99.851   1007.0\n",
      "          accuracy     99.895     NaN       NaN      NaN\n",
      "         macro avg     99.772  99.893    99.832   6637.0\n",
      "      weighted avg     99.895  99.895    99.895   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.780      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7454\n",
      "F1-macro: 0.7227\n",
      "F1-pn: 0.6393\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.088  88.799    88.943    616.0\n",
      "                 1     60.870  63.063    61.947    111.0\n",
      "                 2     66.412  65.414    65.909    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.123  72.425    72.266    860.0\n",
      "      weighted avg     81.939  81.860    81.896    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.928      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0059\n",
      "F1-macro: 0.9992\n",
      "F1-pn: 0.9990\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.930 100.000    99.965   1429.0\n",
      "                 1    100.000  99.602    99.800    251.0\n",
      "                 2    100.000 100.000   100.000    305.0\n",
      "          accuracy     99.950     NaN       NaN      NaN\n",
      "         macro avg     99.977  99.867    99.922   1985.0\n",
      "      weighted avg     99.950  99.950    99.950   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.900      NaN\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  20%|██        | 85/415 [00:44<02:51,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  21%|██        | 86/415 [00:51<13:33,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7893\n",
      "F1-macro: 0.7266\n",
      "F1-pn: 0.6441\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.997  89.286    89.141    616.0\n",
      "                 1     62.162  62.162    62.162    111.0\n",
      "                 2     67.176  66.165    66.667    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.778  72.538    72.657    860.0\n",
      "      weighted avg     82.159  82.209    82.183    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.414      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 170/415 [01:35<02:07,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 171/415 [01:42<10:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8172\n",
      "F1-macro: 0.7216\n",
      "F1-pn: 0.6371\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.217  89.935    89.068    616.0\n",
      "                 1     61.818  61.261    61.538    111.0\n",
      "                 2     68.852  63.158    65.882    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.962  71.451    72.163    860.0\n",
      "      weighted avg     81.815  82.093    81.929    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.710      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  50%|█████     | 209/415 [02:01<01:47,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  61%|██████▏   | 255/415 [03:12<01:23,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  62%|██████▏   | 256/415 [03:19<06:34,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8424\n",
      "F1-macro: 0.7113\n",
      "F1-pn: 0.6264\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.525  87.662    88.091    616.0\n",
      "                 1     56.800  63.964    60.169    111.0\n",
      "                 2     67.200  63.158    65.116    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.842  71.595    71.126    860.0\n",
      "      weighted avg     81.132  80.814    80.934    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.643      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 340/415 [04:03<00:39,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 341/415 [04:10<03:03,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8347\n",
      "F1-macro: 0.7263\n",
      "F1-pn: 0.6425\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.658  90.097    89.372    616.0\n",
      "                 1     62.963  61.261    62.100    111.0\n",
      "                 2     68.254  64.662    66.409    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.292  72.007    72.627    860.0\n",
      "      weighted avg     82.186  82.442    82.301    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.255      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches: 100%|██████████| 415/415 [04:48<00:00,  1.44it/s]\n",
      "INFO:root:Epoch 10, Loss: 0.010223582985738, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0049\n",
      "F1-macro: 0.9995\n",
      "F1-pn: 0.9994\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0    100.000  99.958    99.979   4774.0\n",
      "                 1     99.767 100.000    99.883    856.0\n",
      "                 2    100.000 100.000   100.000   1007.0\n",
      "          accuracy     99.970     NaN       NaN      NaN\n",
      "         macro avg     99.922  99.986    99.954   6637.0\n",
      "      weighted avg     99.970  99.970    99.970   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.942      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8500\n",
      "F1-macro: 0.7165\n",
      "F1-pn: 0.6303\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.301  89.448    88.871    616.0\n",
      "                 1     61.321  58.559    59.908    111.0\n",
      "                 2     66.923  65.414    66.160    133.0\n",
      "          accuracy     81.744     NaN       NaN      NaN\n",
      "         macro avg     72.182  71.140    71.646    860.0\n",
      "      weighted avg     81.513  81.744    81.620    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.034      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0030\n",
      "F1-macro: 1.0000\n",
      "F1-pn: 1.0000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0      100.0   100.0     100.0   1429.0\n",
      "                 1      100.0   100.0     100.0    251.0\n",
      "                 2      100.0   100.0     100.0    305.0\n",
      "          accuracy      100.0     NaN       NaN      NaN\n",
      "         macro avg      100.0   100.0     100.0   1985.0\n",
      "      weighted avg      100.0   100.0     100.0   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN     100.0      NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_m = 1e-6\n",
    "# lr = 1e-6 началось обучение, уменьшение TrainError\n",
    "# добавить волидацию по шагам в течение эпохи обучения, а не каджые N епох\n",
    "# Добавить сохранение ошибки в файлы для построения графиков\n",
    "# проверить методы передачи сущьности (параетром, +тип, или в тексте выделяя тегами).\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"./ruRoberta-large/\")\n",
    "    #parser.add_argument(\"--model_name\", type=str, default=\"sberbank-ai/ruRoberta-large\", help=\"Имя модели\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=512) #128\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=lr_m)\n",
    "    parser.add_argument(\"--init_checkpoint\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_data\", type=str, required=False, default=\"./data/train_data.csv\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, required=False, default=\"./data/validation.csv\")\n",
    "    parser.add_argument(\"--eval_data\", type=str, required=False, default=\"./data/test.csv\")\n",
    "    parser.add_argument(\"--result\", type=str, default=f\"./result_lr_{lr_m}_ENS_Teg_32_multi_dropout_V3_Token/\")\n",
    "    # Игнорируем аргументы Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    os.makedirs(args.result, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    print(args)  # Проверяем аргументы\n",
    "\n",
    "    base_lr = args.lr\n",
    "    min_lr = base_lr * (1/4)\n",
    "    step_size_up = 400 #400\n",
    "\n",
    "    best_avg_f1 = 0.0\n",
    "    \n",
    "    best_model_path = os.path.join(args.result, \"best_model.pth\")\n",
    "\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.model_name)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained(args.model_name, num_labels=3)\n",
    "    model = RobertaWithMultiSampleDropout(model_name='./ruRoberta-large', num_labels=3, use_multi_sample_dropout=True )\n",
    "\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    train_dataset = load_data(args.train_data, tokenizer, args.max_seq_len)\n",
    "    validation_data = load_data(args.validation_data, tokenizer, args.max_seq_len)\n",
    "    eval_dataset = load_data(args.eval_data, tokenizer, args.max_seq_len)\n",
    "\n",
    "    \n",
    "    if train_dataset is None or eval_dataset is None or validation_data is None:\n",
    "        sys.exit(f\"Ошибка загрузки данных: убедитесь, что файлы {args.train_data}, {args.validation_data} и {args.eval_data} существуют и содержат нужные колонки.\")\n",
    "\n",
    "    #сохранение текста и токенов, с дабовлением собственных\n",
    "    save_contrel_date(tokenizer,train_dataset)\n",
    "    model.roberta.resize_token_embeddings(len(tokenizer))\n",
    "    # Получаем метки классов из тренировочного датасета\n",
    "    train_labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "    # Вычисляем веса классов\n",
    "    class_weights = compute_ens_weights(train_labels, beta=0.999)\n",
    "\n",
    "    # Вывод весов классов\n",
    "    print(f\"class_weights = {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=args.batch_size)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    #scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr = base_lr, step_size_up = step_size_up, mode=\"triangular2\",cycle_momentum=False )\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        batches_per_validation = (len(train_loader) // 2)+2\n",
    "        batches_per_test = (len(train_loader) // 5)+2\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"Epoch: {epoch}/{args.epochs}\")\n",
    "            total_loss = 0\n",
    "            for i,batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Batches\")):\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                if(i % batches_per_validation == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Validation\", vall_train = True)\n",
    "                if(i % batches_per_test == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Test\", flag_print = True)\n",
    "                \n",
    "            logging.info(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Step: {len(train_loader)}\")\n",
    "            # Валидация с обратным распространением ошибки каждые 2 эпохи\n",
    "            evaluate(epoch , backprop=\"Train\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Test\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Validation\", flag_print = True, vall_train = True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def evaluate(epoch = None, backprop = \"None\", flag_print = False, vall_train = False):\n",
    "        global best_avg_f1\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        total_loss = 0\n",
    "        print(f\"evaluate, backprop: {backprop}\")\n",
    "        loader = validation_loader\n",
    "        if backprop == \"Validation\":\n",
    "            loader = validation_loader\n",
    "        elif backprop == \"Test\":\n",
    "            loader = eval_loader\n",
    "        elif backprop == \"Train\":\n",
    "            loader = train_loader\n",
    "        \n",
    "        else: loader = eval_loader\n",
    "        with torch.no_grad() if not backprop == \"Validation\" else torch.enable_grad():  # Включаем градиенты для обучения на валидации\n",
    "            for batch in loader:\n",
    "            #for batch in loader:\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if backprop == \"Validation\" and vall_train:\n",
    "                    #уменьшая тк обучающие данные удвоились\n",
    "                    loss = loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #scheduler.step()\n",
    "                    loss = loss\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        f1_pn = f1_score(all_labels, all_preds, labels=[1, 2], average='macro')\n",
    "        avg_f1 = (f1 + f1_pn) / 2\n",
    "\n",
    "        if(flag_print):\n",
    "            print()\n",
    "            print(\"--\"*20)\n",
    "            print(f\"Result evaluate in {backprop}\")\n",
    "            #logging.info(f\"{backprop} Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "            #print(classification_report(all_labels, all_preds))\n",
    "            castom_classification_report(all_labels, all_preds)\n",
    "\n",
    "        # 💾 Сохраняем модель только при улучшении средней метрики\n",
    "        if (avg_f1 > best_avg_f1) and backprop == \"Test\":\n",
    "            best_avg_f1 = avg_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            \n",
    "            print(f\"[Checkpoint] 🎯 Новый лучший средний F1: {best_avg_f1:.4f}\")\n",
    "            print(f\"[Checkpoint] 💾 Модель сохранена: {best_model_path}\")\n",
    "            # 🔸 Сохраняем значение лучшего F1 в файл\n",
    "            best_score_path = os.path.join(args.result, \"best_score.txt\")\n",
    "            save_metrics_best(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "            save_confusion_matrix(epoch, all_labels, all_preds, args.result, backprop)\n",
    "            with open(best_score_path, \"w\") as f:\n",
    "                f.write(f\"Epoch: {epoch}\\n\")\n",
    "                f.write(f\"Loss: {avg_loss:.4f}\\n\")\n",
    "                f.write(f\"F1-pn0: {f1:.4f}\\n\")\n",
    "                f.write(f\"F1-pn: {f1_pn:.4f}\\n\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "\n",
    "\n",
    "        if epoch is not None:\n",
    "            save_metrics(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "        \n",
    "    if args.init_checkpoint:\n",
    "        model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n",
    "\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4520d-65bf-4708-99bc-4807f25ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "805557fd-243e-47ff-b33c-4ce8c82c159f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './result_lr_1e-06_test/metrics_class_weights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Пример использования\u001b[39;00m\n\u001b[32m     54\u001b[39m metrics_file = \u001b[33m\"\u001b[39m\u001b[33m./result_lr_1e-06_test/metrics_class_weights.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mload_and_display_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_and_display_metrics\u001b[39m\u001b[34m(metrics_file)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_and_display_metrics\u001b[39m(metrics_file):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Загружаем CSV-файл\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     df = df[df[\u001b[33m\"\u001b[39m\u001b[33mbackprop\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mTest\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Определяем количество эпох\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './result_lr_1e-06_test/metrics_class_weights.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_display_metrics(metrics_file):\n",
    "    # Загружаем CSV-файл\n",
    "    df = pd.read_csv(metrics_file)\n",
    "    df = df[df[\"backprop\"] == \"Test\"]\n",
    "    # Определяем количество эпох\n",
    "    epochs = df[\"epoch\"].unique()\n",
    "    print(epochs)\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # Фильтруем данные по эпохе\n",
    "        epoch_df = df[df[\"epoch\"] == epoch]\n",
    "        \n",
    "        for idx, row in epoch_df.iterrows():\n",
    "            loss = row[\"loss\"]\n",
    "            backprop_value = row[\"backprop\"]\n",
    "            print(f\"\\nEpoch {epoch} (Backprop: {backprop_value}) (Loss: {loss})\\n\" + \"-\"*30)\n",
    "            # Формируем таблицу в стиле classification_report\n",
    "            table_data = {}\n",
    "            class_labels = sorted(\n",
    "                set(col.split(\"_\")[1] for col in df.columns \n",
    "                    if col.startswith(\"class_\") and \"precision\" in col)\n",
    "            )\n",
    "            \n",
    "            # Фильтруем только числовые метки классов\n",
    "            class_labels = [label for label in class_labels if label.isdigit()]\n",
    "            \n",
    "            for label in class_labels:\n",
    "                table_data[int(label)] = {\n",
    "                    \"precision\": row[f\"class_{label}_precision\"],\n",
    "                    \"recall\": row[f\"class_{label}_recall\"],\n",
    "                    \"f1-score\": row[f\"class_{label}_f1\"],\n",
    "                }\n",
    "            \n",
    "            # Добавляем средние значения\n",
    "            table_data[\"accuracy\"] = {\"precision\": \"\", \"recall\": \"\", \"f1-score\": row[\"accuracy\"] }\n",
    "            table_data[\"macro avg\"] = {\n",
    "                \"precision\": row[\"macro_precision\"],\n",
    "                \"recall\": row[\"macro_recall\"],\n",
    "                \"f1-score\": row[\"macro_f1\"],\n",
    "            }\n",
    "            table_data[\"weighted avg\"] = {\n",
    "                \"precision\": row[\"weighted_precision\"],\n",
    "                \"recall\": row[\"weighted_recall\"],\n",
    "                \"f1-score\": row[\"weighted_f1\"],\n",
    "            }\n",
    "            \n",
    "            # Выводим таблицу\n",
    "            df_table = pd.DataFrame.from_dict(table_data, orient=\"index\")\n",
    "            print(df_table.to_string())\n",
    "\n",
    "# Пример использования\n",
    "metrics_file = \"./result_lr_1e-06_test/metrics_class_weights.csv\"\n",
    "load_and_display_metrics(metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9444b-5431-4eb6-8ff8-9074d559598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка CSV-файла\n",
    "df = pd.read_csv(\"metrics_class_weights.csv\")  # укажи путь к файлу, если он отличается\n",
    "\n",
    "# Построение графика loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for stage in ['Train', 'Validation', 'Test']:\n",
    "    stage_data = df[df['backprop'] == stage]\n",
    "    plt.plot(stage_data['epoch'], stage_data['loss'], label=stage)\n",
    "\n",
    "plt.title('Значение Loss по эпохам')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ryumin_env",
   "language": "python",
   "name": "ryumin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
