{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd128c19-762d-49e7-959a-845e0599a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CyclicLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f20af-edf7-4cf5-84b3-bc8e437c24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaWithMultiSampleDropoutTarget(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3, num_dropouts=5, use_multi_sample_dropout=True):\n",
    "        super(RobertaWithMultiSampleDropoutTarget, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.use_multi_sample_dropout = use_multi_sample_dropout\n",
    "        self.hidden_size = self.roberta.config.hidden_size\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(dropout_rate) for _ in range(num_dropouts)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_labels)\n",
    "\n",
    "    def extract_entity_embeddings(self, input_ids, sequence_output, en_token_id, end_en_token_id):\n",
    "        batch_size = input_ids.size(0)\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            input_id = input_ids[i]\n",
    "            output = sequence_output[i]\n",
    "\n",
    "            try:\n",
    "                start = (input_id == en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "                end = (input_id == end_en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "            except IndexError:\n",
    "                # если вдруг токены не найдены — fallback на [CLS]\n",
    "                entity_representations.append(output[0])\n",
    "                continue\n",
    "\n",
    "            # вырезаем эмбеддинги между <en> и </en>\n",
    "            entity_tokens = output[start + 1:end]\n",
    "            if entity_tokens.shape[0] == 0:\n",
    "                entity_representations.append(output[0])  # fallback на [CLS]\n",
    "            else:\n",
    "                entity_representations.append(entity_tokens.mean(dim=0))  # mean pooling\n",
    "\n",
    "        return torch.stack(entity_representations)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # --- 1. Находим позиции <en> и </en> ---\n",
    "        start_token_id = start_token_ids = [tokenizer.convert_tokens_to_ids(f\"<en:{tag}>\") for tag in teg_class_entity]\n",
    "        end_token_id = tokenizer.convert_tokens_to_ids(\"</en>\")\n",
    "    \n",
    "        start_positions = torch.zeros_like(input_ids).bool()\n",
    "        for token_id in start_token_ids:\n",
    "            start_positions |= (input_ids == token_id)\n",
    "\n",
    "        start_positions = start_positions.nonzero(as_tuple=False)\n",
    "        end_positions = (input_ids == end_token_id).nonzero(as_tuple=False)\n",
    "\n",
    "        # --- 2. Для каждого примера агрегируем hidden states между <en> и </en> ---\n",
    "        pooled_output = []\n",
    "        for batch_idx in range(input_ids.size(0)):\n",
    "            start_pos = start_positions[start_positions[:, 0] == batch_idx][:, 1]\n",
    "            end_pos = end_positions[end_positions[:, 0] == batch_idx][:, 1]\n",
    "            if len(start_pos) > 0 and len(end_pos) > 0:\n",
    "                s, e = start_pos[0].item() + 1, end_pos[0].item()  # между тегами\n",
    "                if e > s:\n",
    "                    token_embeds = sequence_output[batch_idx, s:e, :]  # [num_entity_tokens, hidden]\n",
    "                    pooled = torch.mean(token_embeds, dim=0)  # Mean-pooling\n",
    "                else:\n",
    "                    pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "            else:\n",
    "                pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "\n",
    "            pooled_output.append(pooled)\n",
    "\n",
    "        pooled_output = torch.stack(pooled_output)  # [batch_size, hidden_size]\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            logits_list = [self.classifier(dropout(pooled_output)) for dropout in self.dropouts]\n",
    "            avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "        else:\n",
    "            avg_logits = self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "        return SequenceClassifierOutput(logits=avg_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1746-8eac-4865-8f99-828b9055d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_best(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metrics_file = os.path.join(result_path, \"metrics_best.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Создаем словарь с метриками\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop,\n",
    "        \"loss\": loss\n",
    "    }\n",
    "\n",
    "    # Добавляем метрики по каждому классу\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "\n",
    "    # Создаем DataFrame и сохраняем его в CSV (перезапись файла)\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2886be9d-a3f4-4164-8002-b4cc31a22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ens_weights(train_labels, beta: float = 0.999):\n",
    "    train_labels = np.array(train_labels)\n",
    "    classes, counts = np.unique(train_labels, return_counts=True)\n",
    "    effective_num = (1 - np.power(beta, counts)) / (1 - beta)\n",
    "    weights = 1.0 / effective_num\n",
    "    weights = weights / np.sum(weights) * len(classes)  # нормализация как в оригинальной статье\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d52154-884f-4289-8b00-b19358f419e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tags_from_files(*file_paths):\n",
    "    all_tags = set()\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "            if \"entity_tag\" in df.columns:\n",
    "                tags = df[\"entity_tag\"].dropna().unique().tolist()\n",
    "                all_tags.update(tags)\n",
    "        except Exception as e:\n",
    "            print(f\"[Ошибка] Не удалось загрузить {path}: {e}\")\n",
    "    return sorted(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be23ac59-6617-40d9-b01b-be5ff22e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, tokenizer, max_seq_len):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # Загружаем CSV (TSV)\n",
    "\n",
    "        # Проверка нужных колонок\n",
    "        required_columns = {\n",
    "            \"sentence\", \"entity\", \"label\", \"entity_tag\",\n",
    "            \"entity_pos_start_rel\", \"entity_pos_end_rel\"\n",
    "        }\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Ожидаемые колонки: {required_columns}, но в файле: {df.columns}\")\n",
    "\n",
    "        # Заменяем -1 на 2 (если есть)\n",
    "        df[\"label\"] = df[\"label\"].replace(-1, 2)\n",
    "\n",
    "        # Размечаем предложения с [ENTITY] токенами\n",
    "        def mark_entity_inline(row):\n",
    "            sent = row[\"sentence\"]\n",
    "            start = row[\"entity_pos_start_rel\"]\n",
    "            end = row[\"entity_pos_end_rel\"]\n",
    "            tag = row[\"entity_tag\"]\n",
    "            tag_token = f\"<en:{tag}>\"\n",
    "            tag_token_close = f\"</en>\"\n",
    "            return (\n",
    "                sent[:start] +\n",
    "                f\"{tag_token} \" + sent[start:end] + f\" {tag_token_close}\" +\n",
    "                sent[end:]\n",
    "            )\n",
    "\n",
    "        df[\"input_text\"] = df.apply(mark_entity_inline, axis=1)\n",
    "        texts = df[\"input_text\"].tolist()\n",
    "        labels = torch.tensor(df[\"label\"].astype(int).tolist(), dtype=torch.long)\n",
    "\n",
    "        # Токенизируем\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True,\n",
    "                              max_length=max_seq_len, return_tensors='pt')\n",
    "        dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "        return dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Файл {file_path} не найден!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbfe22-f0f3-4f70-b366-53259c79ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_metrics(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    metrics_file = os.path.join(result_path, \"metrics_class_weights.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    \n",
    "    # Создаем DataFrame для метрик\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop , # (Добавлено)\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    \n",
    "    # Добавляем метрики для каждого класса\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):  # Пропускаем 'accuracy', так как это float\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    # Создаем DataFrame и сохраняем в CSV\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='a', header=not os.path.exists(metrics_file), index=False)\n",
    "\n",
    "def save_confusion_matrix(epoch, y_true, y_pred, result_path,backprop):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"Pred_0\", \"Pred_1\", \"Pred_2\"], index=[\"True_0\", \"True_1\", \"True_2\"])\n",
    "    cm_file = os.path.join(result_path, f\"confusion_matrix_class_weights_epoch_{epoch}_backprop_{backprop}.csv\")\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd447891-39c3-42bc-981d-96b2800a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def castom_classification_report(all_labels, all_preds):\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    data = []\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):  # Для всех метрик, кроме accuracy\n",
    "            row = {'label': label}\n",
    "            for metric, value in metrics.items():\n",
    "                row[metric] = round(value * 100, 3) if metric != 'support' else value\n",
    "            data.append(row)\n",
    "        else:  # Для accuracy\n",
    "            data.append({'label': 'accuracy', 'precision': round(metrics * 100, 3), 'recall': None, 'f1-score': None, 'support': None})\n",
    "\n",
    "    # Добавляем macro F1 для классов 1 и 2\n",
    "    if '1' in report and '2' in report:\n",
    "        f1_1 = report['1']['f1-score']\n",
    "        f1_2 = report['2']['f1-score']\n",
    "        f1_macro_1_2 = (f1_1 + f1_2) / 2\n",
    "        data.append({\n",
    "            'label': 'avg f1 (class 1&2)',\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': round(f1_macro_1_2 * 100, 3),\n",
    "            'support': None\n",
    "        })\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = [''] * len(df)\n",
    "\n",
    "    # Выводим таблицу\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447e1ed-4fc6-43aa-a54c-d9023898afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(flag = False):\n",
    "    # Формируем список специальных токенов\n",
    "    if not flag: return None\n",
    "    #entity_tags = get_entity_tags_from_files(args.train_data, args.validation_data, args.eval_data)\n",
    "    special_tokens = {\n",
    "        \"additional_special_tokens\":\n",
    "            [f\"<en:{tag}>\" for tag in teg_class_entity] +\n",
    "            [\"<en>\", \"</en>\"]\n",
    "    }\n",
    "\n",
    "    print(\"Добавленные специальные токены:\")\n",
    "    for token in special_tokens[\"additional_special_tokens\"]:\n",
    "        print(token)\n",
    "    return special_tokens\n",
    "\n",
    "def save_contrel_date(tokenizer, train_dataset):\n",
    "    special_tokens = add_token(flag = True)\n",
    "    if special_tokens != None: \n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "    tokenizer.save_pretrained(os.path.join(args.result, \"tokenizer\"))\n",
    "    print(tokenizer.special_tokens_map)\n",
    "    print(tokenizer.additional_special_tokens)\n",
    "\n",
    "    \n",
    "    file_control_text = os.path.join(args.result, \"use_market_text.txt\")\n",
    "    input_ids, attention_mask, label = train_dataset[0]\n",
    "    decoded_text_token = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    with open(file_control_text, \"w\") as f:\n",
    "        f.write(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "        f.write(f\"Text:\\n{decoded_text}\\n\\n\")\n",
    "    print(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "    print(f\"Text:\\n{decoded_text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af33277-341d-43ba-8b31-c9bba05cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_name='./../ruRoberta-large/', max_seq_len=512, batch_size=16, epochs=10, lr=1e-06, init_checkpoint=None, train_data='./../data/train_data.csv', validation_data='./../data/validation.csv', eval_data='./../data/test.csv', result='./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./../ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавленные специальные токены:\n",
      "<en:COUNTRY>\n",
      "<en:NATIONALITY>\n",
      "<en:ORGANIZATION>\n",
      "<en:PERSON>\n",
      "<en:PROFESSION>\n",
      "<en>\n",
      "</en>\n",
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<en:COUNTRY>', '<en:NATIONALITY>', '<en:ORGANIZATION>', '<en:PERSON>', '<en:PROFESSION>', '<en>', '</en>']}\n",
      "['<en:COUNTRY>', '<en:NATIONALITY>', '<en:ORGANIZATION>', '<en:PERSON>', '<en:PROFESSION>', '<en>', '</en>']\n",
      "Text token:\n",
      "<s>Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en:PROFESSION> спортсмена </en> остановить бой, но тот хотел продолжать.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "\n",
      "\n",
      "Text:\n",
      "Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en:PROFESSION> спортсмена </en> остановить бой, но тот хотел продолжать.\n",
      "\n",
      "\n",
      "tensor([-0.0229, -0.0179,  0.0746,  ..., -0.1801, -0.0312,  0.0677],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "class_weights = tensor([0.7001, 1.2066, 1.0934])\n",
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  20%|██        | 85/415 [00:48<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7943\n",
      "F1-macro: 0.2838\n",
      "F1-pn: 0.0088\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.645  99.675    83.367    616.0\n",
      "                 1     50.000   0.901     1.770    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.512     NaN       NaN      NaN\n",
      "         macro avg     40.548  33.525    28.379    860.0\n",
      "      weighted avg     57.771  71.512    59.943    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.885      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  21%|██        | 86/415 [00:57<17:01,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1463\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7943\n",
      "F1-macro: 0.2838\n",
      "F1-pn: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 170/415 [01:44<02:18,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 171/415 [01:51<10:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7433\n",
      "F1-macro: 0.2835\n",
      "F1-pn: 0.0088\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.612  99.513    83.288    616.0\n",
      "                 1     33.333   0.901     1.754    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.395     NaN       NaN      NaN\n",
      "         macro avg     34.982  33.471    28.347    860.0\n",
      "      weighted avg     55.597  71.395    59.884    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.877      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  50%|█████     | 209/415 [02:12<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  61%|██████▏   | 255/415 [03:28<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7470\n",
      "F1-macro: 0.3008\n",
      "F1-pn: 0.0339\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.864  99.513    83.458    616.0\n",
      "                 1     57.143   3.604     6.780    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.744     NaN       NaN      NaN\n",
      "         macro avg     43.002  34.372    30.079    860.0\n",
      "      weighted avg     58.850  71.744    60.654    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     3.390      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  62%|██████▏   | 256/415 [03:39<09:31,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1673\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7470\n",
      "F1-macro: 0.3008\n",
      "F1-pn: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 340/415 [04:26<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7007\n",
      "F1-macro: 0.3568\n",
      "F1-pn: 0.1168\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.892  98.214    83.679    616.0\n",
      "                 1     80.000   3.604     6.897    111.0\n",
      "                 2     52.000   9.774    16.456    133.0\n",
      "          accuracy     72.326     NaN       NaN      NaN\n",
      "         macro avg     68.297  37.197    35.677    860.0\n",
      "      weighted avg     70.578  72.326    63.373    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    11.676      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 341/415 [04:36<04:25,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2368\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7007\n",
      "F1-macro: 0.3568\n",
      "F1-pn: 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches: 100%|██████████| 415/415 [05:18<00:00,  1.30it/s]\n",
      "INFO:root:Epoch 1, Loss: 0.88680782820805, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.7630\n",
      "F1-macro: 0.4198\n",
      "F1-pn: 0.2076\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.774  96.921    84.419   4774.0\n",
      "                 1     71.429   5.257     9.793    856.0\n",
      "                 2     57.254  21.946    31.730   1007.0\n",
      "          accuracy     73.723     NaN       NaN      NaN\n",
      "         macro avg     67.819  41.375    41.981   6637.0\n",
      "      weighted avg     71.684  73.723    66.800   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    20.762      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6767\n",
      "F1-macro: 0.4041\n",
      "F1-pn: 0.1863\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.282  96.591    83.980    616.0\n",
      "                 1     75.000   5.405    10.084    111.0\n",
      "                 2     49.020  18.797    27.174    133.0\n",
      "          accuracy     72.791     NaN       NaN      NaN\n",
      "         macro avg     66.101  40.264    40.413    860.0\n",
      "      weighted avg     70.468  72.791    65.657    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    18.629      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2952\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6767\n",
      "F1-macro: 0.4041\n",
      "F1-pn: 0.1863\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.6987\n",
      "F1-macro: 0.3811\n",
      "F1-pn: 0.1476\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.839  97.831    84.804   1429.0\n",
      "                 1      0.000   0.000     0.000    251.0\n",
      "                 2     65.909  19.016    29.517    305.0\n",
      "          accuracy     73.350     NaN       NaN      NaN\n",
      "         macro avg     46.916  38.949    38.107   1985.0\n",
      "      weighted avg     64.004  73.350    65.586   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    14.758      NaN\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  20%|██        | 85/415 [00:47<03:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6533\n",
      "F1-macro: 0.4743\n",
      "F1-pn: 0.2878\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     76.098  95.617    84.748    616.0\n",
      "                 1     69.565  14.414    23.881    111.0\n",
      "                 2     52.381  24.812    33.673    133.0\n",
      "          accuracy     74.186     NaN       NaN      NaN\n",
      "         macro avg     66.015  44.948    47.434    860.0\n",
      "      weighted avg     71.587  74.186    68.993    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    28.777      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  21%|██        | 86/415 [00:58<19:40,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3811\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6533\n",
      "F1-macro: 0.4743\n",
      "F1-pn: 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 170/415 [01:45<02:17,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6373\n",
      "F1-macro: 0.5604\n",
      "F1-pn: 0.4186\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     79.484  89.935    84.387    616.0\n",
      "                 1     52.542  27.928    36.471    111.0\n",
      "                 2     53.846  42.105    47.257    133.0\n",
      "          accuracy     74.535     NaN       NaN      NaN\n",
      "         macro avg     61.957  53.323    56.038    860.0\n",
      "      weighted avg     72.041  74.535    72.460    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    41.864      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 171/415 [01:56<14:41,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.4895\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6373\n",
      "F1-macro: 0.5604\n",
      "F1-pn: 0.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  50%|█████     | 209/415 [02:17<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  61%|██████▏   | 255/415 [03:33<01:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  62%|██████▏   | 256/415 [03:40<06:52,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6015\n",
      "F1-macro: 0.5600\n",
      "F1-pn: 0.4155\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     79.021  91.721    84.899    616.0\n",
      "                 1     70.588  21.622    33.103    111.0\n",
      "                 2     54.955  45.865    50.000    133.0\n",
      "          accuracy     75.581     NaN       NaN      NaN\n",
      "         macro avg     68.188  53.069    56.001    860.0\n",
      "      weighted avg     74.211  75.581    72.816    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    41.552      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 340/415 [04:28<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5780\n",
      "F1-macro: 0.5902\n",
      "F1-pn: 0.4589\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.432  90.747    85.278    616.0\n",
      "                 1     67.442  26.126    37.662    111.0\n",
      "                 2     56.557  51.880    54.118    133.0\n",
      "          accuracy     76.395     NaN       NaN      NaN\n",
      "         macro avg     68.144  56.251    59.019    860.0\n",
      "      weighted avg     75.063  76.395    74.314    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    45.890      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 341/415 [04:38<04:27,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5245\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5780\n",
      "F1-macro: 0.5902\n",
      "F1-pn: 0.4589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches: 100%|██████████| 415/415 [05:20<00:00,  1.29it/s]\n",
      "INFO:root:Epoch 2, Loss: 0.738673224075731, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.5891\n",
      "F1-macro: 0.6670\n",
      "F1-pn: 0.5658\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.320  88.626    86.941   4774.0\n",
      "                 1     69.912  36.916    48.318    856.0\n",
      "                 2     59.054  71.897    64.845   1007.0\n",
      "          accuracy     79.418     NaN       NaN      NaN\n",
      "         macro avg     71.428  65.813    66.702   6637.0\n",
      "      weighted avg     79.347  79.418    78.607   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    56.582      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5745\n",
      "F1-macro: 0.6121\n",
      "F1-pn: 0.4952\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.203  86.039    84.597    616.0\n",
      "                 1     63.462  29.730    40.491    111.0\n",
      "                 2     52.047  66.917    58.553    133.0\n",
      "          accuracy     75.814     NaN       NaN      NaN\n",
      "         macro avg     66.237  60.895    61.213    860.0\n",
      "      weighted avg     75.836  75.814    74.876    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    49.522      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5537\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5745\n",
      "F1-macro: 0.6121\n",
      "F1-pn: 0.4952\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.5500\n",
      "F1-macro: 0.5379\n",
      "F1-pn: 0.3745\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.847  95.731    86.473   1429.0\n",
      "                 1     36.000  10.757    16.564    251.0\n",
      "                 2     80.000  45.902    58.333    305.0\n",
      "          accuracy     77.330     NaN       NaN      NaN\n",
      "         macro avg     64.949  50.797    53.790   1985.0\n",
      "      weighted avg     73.606  77.330    73.309   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    37.449      NaN\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  21%|██        | 86/415 [00:55<14:12,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5499\n",
      "F1-macro: 0.6119\n",
      "F1-pn: 0.4903\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.872  89.448    85.493    616.0\n",
      "                 1     64.815  31.532    42.424    111.0\n",
      "                 2     55.639  55.639    55.639    133.0\n",
      "          accuracy     76.744     NaN       NaN      NaN\n",
      "         macro avg     67.442  58.873    61.185    860.0\n",
      "      weighted avg     75.614  76.744    75.317    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    49.032      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5332\n",
      "F1-macro: 0.6322\n",
      "F1-pn: 0.5192\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.436  88.312    85.804    616.0\n",
      "                 1     61.111  39.640    48.087    111.0\n",
      "                 2     55.147  56.391    55.762    133.0\n",
      "          accuracy     77.093     NaN       NaN      NaN\n",
      "         macro avg     66.565  61.447    63.218    860.0\n",
      "      weighted avg     76.179  77.093    76.290    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    51.925      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 171/415 [01:53<14:40,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5757\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5332\n",
      "F1-macro: 0.6322\n",
      "F1-pn: 0.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  50%|█████     | 209/415 [02:14<01:56,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  61%|██████▏   | 255/415 [03:30<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  62%|██████▏   | 256/415 [03:37<06:52,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5269\n",
      "F1-macro: 0.6248\n",
      "F1-pn: 0.5066\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.567  91.234    86.130    616.0\n",
      "                 1     63.934  35.135    45.349    111.0\n",
      "                 2     61.818  51.128    55.967    133.0\n",
      "          accuracy     77.791     NaN       NaN      NaN\n",
      "         macro avg     69.107  59.166    62.482    860.0\n",
      "      weighted avg     76.237  77.791    76.202    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    50.658      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 340/415 [04:24<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5094\n",
      "F1-macro: 0.6442\n",
      "F1-pn: 0.5355\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.537  88.961    86.164    616.0\n",
      "                 1     69.811  33.333    45.122    111.0\n",
      "                 2     58.278  66.165    61.972    133.0\n",
      "          accuracy     78.256     NaN       NaN      NaN\n",
      "         macro avg     70.542  62.820    64.419    860.0\n",
      "      weighted avg     77.859  78.256    77.125    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    53.547      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 341/415 [04:35<04:25,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5898\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5094\n",
      "F1-macro: 0.6442\n",
      "F1-pn: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches: 100%|██████████| 415/415 [05:17<00:00,  1.31it/s]\n",
      "INFO:root:Epoch 3, Loss: 0.5864631323211165, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4610\n",
      "F1-macro: 0.7562\n",
      "F1-pn: 0.6857\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.956  89.485    89.720   4774.0\n",
      "                 1     68.793  57.944    62.904    856.0\n",
      "                 2     69.152  80.139    74.241   1007.0\n",
      "          accuracy     83.999     NaN       NaN      NaN\n",
      "         macro avg     75.967  75.856    75.622   6637.0\n",
      "      weighted avg     84.070  83.999    83.913   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.573      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5110\n",
      "F1-macro: 0.6898\n",
      "F1-pn: 0.6022\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.273  85.714    86.486    616.0\n",
      "                 1     63.529  48.649    55.102    111.0\n",
      "                 2     58.235  74.436    65.347    133.0\n",
      "          accuracy     79.186     NaN       NaN      NaN\n",
      "         macro avg     69.679  69.600    68.978    860.0\n",
      "      weighted avg     79.718  79.186    79.166    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.224      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6460\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5110\n",
      "F1-macro: 0.6898\n",
      "F1-pn: 0.6022\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.4142\n",
      "F1-macro: 0.6915\n",
      "F1-pn: 0.5878\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     84.620  95.871    89.895   1429.0\n",
      "                 1     61.667  29.482    39.892    251.0\n",
      "                 2     86.992  70.164    77.677    305.0\n",
      "          accuracy     83.526     NaN       NaN      NaN\n",
      "         macro avg     77.760  65.172    69.155   1985.0\n",
      "      weighted avg     82.082  83.526    81.695   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.785      NaN\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  20%|██        | 85/415 [00:47<03:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5236\n",
      "F1-macro: 0.6991\n",
      "F1-pn: 0.6169\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.255  83.604    86.337    616.0\n",
      "                 1     59.259  57.658    58.447    111.0\n",
      "                 2     57.143  75.188    64.935    133.0\n",
      "          accuracy     78.953     NaN       NaN      NaN\n",
      "         macro avg     68.552  72.150    69.907    860.0\n",
      "      weighted avg     80.417  78.953    79.427    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.691      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  21%|██        | 86/415 [00:58<20:21,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6580\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5236\n",
      "F1-macro: 0.6991\n",
      "F1-pn: 0.6169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 170/415 [01:46<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4904\n",
      "F1-macro: 0.7035\n",
      "F1-pn: 0.6171\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.783  88.474    87.621    616.0\n",
      "                 1     67.073  49.550    56.995    111.0\n",
      "                 2     62.667  70.677    66.431    133.0\n",
      "          accuracy     80.698     NaN       NaN      NaN\n",
      "         macro avg     72.174  69.567    70.349    860.0\n",
      "      weighted avg     80.510  80.698    80.391    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.713      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 171/415 [01:56<14:32,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6603\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4904\n",
      "F1-macro: 0.7035\n",
      "F1-pn: 0.6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  50%|█████     | 209/415 [02:18<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  61%|██████▏   | 255/415 [03:33<01:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  62%|██████▏   | 256/415 [03:41<06:50,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4926\n",
      "F1-macro: 0.6789\n",
      "F1-pn: 0.5835\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.093  88.961    86.984    616.0\n",
      "                 1     65.385  45.946    53.968    111.0\n",
      "                 2     61.594  63.910    62.731    133.0\n",
      "          accuracy     79.535     NaN       NaN      NaN\n",
      "         macro avg     70.691  66.272    67.894    860.0\n",
      "      weighted avg     78.915  79.535    78.972    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.349      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 340/415 [04:28<00:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4811\n",
      "F1-macro: 0.7163\n",
      "F1-pn: 0.6352\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.216  87.500    87.857    616.0\n",
      "                 1     64.583  55.856    59.903    111.0\n",
      "                 2     62.745  72.180    67.133    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     71.848  71.845    71.631    860.0\n",
      "      weighted avg     81.227  81.047    81.044    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.518      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 341/415 [04:39<04:26,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6757\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4811\n",
      "F1-macro: 0.7163\n",
      "F1-pn: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches: 100%|██████████| 415/415 [05:20<00:00,  1.29it/s]\n",
      "INFO:root:Epoch 4, Loss: 0.4680818463843989, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3603\n",
      "F1-macro: 0.8164\n",
      "F1-pn: 0.7649\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     92.640  91.223    91.926   4774.0\n",
      "                 1     75.840  68.575    72.025    856.0\n",
      "                 2     75.559  87.190    80.959   1007.0\n",
      "          accuracy     87.690     NaN       NaN      NaN\n",
      "         macro avg     81.346  82.329    81.637   6637.0\n",
      "      weighted avg     87.882  87.690    87.695   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    76.492      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4811\n",
      "F1-macro: 0.7247\n",
      "F1-pn: 0.6461\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.748  86.688    88.192    616.0\n",
      "                 1     67.021  56.757    61.463    111.0\n",
      "                 2     60.234  77.444    67.763    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     72.334  73.630    72.473    860.0\n",
      "      weighted avg     82.250  81.395    81.583    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.613      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6854\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4811\n",
      "F1-macro: 0.7247\n",
      "F1-pn: 0.6461\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.3018\n",
      "F1-macro: 0.7916\n",
      "F1-pn: 0.7231\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.768  97.341    92.857   1429.0\n",
      "                 1     77.931  45.020    57.071    251.0\n",
      "                 2     92.674  82.951    87.543    305.0\n",
      "          accuracy     88.514     NaN       NaN      NaN\n",
      "         macro avg     86.458  75.104    79.157   1985.0\n",
      "      weighted avg     87.998  88.514    87.516   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    72.307      NaN\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  21%|██        | 86/415 [00:55<14:12,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5244\n",
      "F1-macro: 0.7151\n",
      "F1-pn: 0.6404\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.486  81.981    86.473    616.0\n",
      "                 1     61.062  62.162    61.607    111.0\n",
      "                 2     55.897  81.955    66.463    133.0\n",
      "          accuracy     79.419     NaN       NaN      NaN\n",
      "         macro avg     69.482  75.366    71.514    860.0\n",
      "      weighted avg     82.055  79.419    80.169    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.035      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 170/415 [01:42<02:18,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4730\n",
      "F1-macro: 0.7394\n",
      "F1-pn: 0.6649\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.867  87.825    88.834    616.0\n",
      "                 1     63.889  62.162    63.014    111.0\n",
      "                 2     66.000  74.436    69.965    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.252  74.808    73.938    860.0\n",
      "      weighted avg     82.823  82.442    82.583    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.489      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 171/415 [01:53<14:46,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7021\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4730\n",
      "F1-macro: 0.7394\n",
      "F1-pn: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  50%|█████     | 209/415 [02:14<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  61%|██████▏   | 255/415 [03:30<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  62%|██████▏   | 256/415 [03:37<06:50,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4714\n",
      "F1-macro: 0.7067\n",
      "F1-pn: 0.6191\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.202  90.260    88.184    616.0\n",
      "                 1     65.556  53.153    58.706    111.0\n",
      "                 2     67.200  63.158    65.116    133.0\n",
      "          accuracy     81.279     NaN       NaN      NaN\n",
      "         macro avg     72.986  68.857    70.669    860.0\n",
      "      weighted avg     80.598  81.279    80.812    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.911      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 340/415 [04:25<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 341/415 [04:32<03:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4693\n",
      "F1-macro: 0.7347\n",
      "F1-pn: 0.6580\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.799  88.799    88.799    616.0\n",
      "                 1     69.231  56.757    62.376    111.0\n",
      "                 2     64.706  74.436    69.231    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     74.245  73.331    73.469    860.0\n",
      "      weighted avg     82.547  82.442    82.362    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.804      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches: 100%|██████████| 415/415 [05:14<00:00,  1.32it/s]\n",
      "INFO:root:Epoch 5, Loss: 0.3639307471732777, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.2599\n",
      "F1-macro: 0.8769\n",
      "F1-pn: 0.8437\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     96.190  92.543    94.331   4774.0\n",
      "                 1     76.754  85.631    80.950    856.0\n",
      "                 2     84.481  91.360    87.786   1007.0\n",
      "          accuracy     91.472     NaN       NaN      NaN\n",
      "         macro avg     85.808  89.845    87.689   6637.0\n",
      "      weighted avg     91.907  91.472    91.612   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    84.368      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4856\n",
      "F1-macro: 0.7426\n",
      "F1-pn: 0.6708\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.379  86.039    88.629    616.0\n",
      "                 1     62.400  70.270    66.102    111.0\n",
      "                 2     63.226  73.684    68.056    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.335  76.664    74.262    860.0\n",
      "      weighted avg     83.285  82.093    82.540    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.079      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7067\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4856\n",
      "F1-macro: 0.7426\n",
      "F1-pn: 0.6708\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1848\n",
      "F1-macro: 0.9030\n",
      "F1-pn: 0.8742\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     93.800  98.460    96.074   1429.0\n",
      "                 1     92.308  71.713    80.717    251.0\n",
      "                 2     96.552  91.803    94.118    305.0\n",
      "          accuracy     94.055     NaN       NaN      NaN\n",
      "         macro avg     94.220  87.326    90.303   1985.0\n",
      "      weighted avg     94.034  94.055    93.831   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    87.418      NaN\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4871\n",
      "F1-macro: 0.7443\n",
      "F1-pn: 0.6726\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.840  85.877    88.758    616.0\n",
      "                 1     58.824  72.072    64.777    111.0\n",
      "                 2     66.216  73.684    69.751    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.293  77.211    74.429    860.0\n",
      "      weighted avg     83.616  82.209    82.724    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.264      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  21%|██        | 86/415 [00:58<19:52,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7085\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4871\n",
      "F1-macro: 0.7443\n",
      "F1-pn: 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 170/415 [01:46<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4748\n",
      "F1-macro: 0.7489\n",
      "F1-pn: 0.6759\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.371  87.662    89.478    616.0\n",
      "                 1     65.766  65.766    65.766    111.0\n",
      "                 2     63.924  75.940    69.416    133.0\n",
      "          accuracy     83.023     NaN       NaN      NaN\n",
      "         macro avg     73.687  76.456    74.887    860.0\n",
      "      weighted avg     83.821  83.023    83.315    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.591      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 171/415 [01:57<15:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7124\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4748\n",
      "F1-macro: 0.7489\n",
      "F1-pn: 0.6759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  50%|█████     | 209/415 [02:18<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  61%|██████▏   | 255/415 [03:34<01:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  62%|██████▏   | 256/415 [03:41<06:52,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4861\n",
      "F1-macro: 0.7323\n",
      "F1-pn: 0.6541\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.943  88.799    88.871    616.0\n",
      "                 1     67.010  58.559    62.500    111.0\n",
      "                 2     64.865  72.180    68.327    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     73.606  73.179    73.233    860.0\n",
      "      weighted avg     82.389  82.326    82.290    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.414      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 340/415 [04:28<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4790\n",
      "F1-macro: 0.7513\n",
      "F1-pn: 0.6814\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.741  87.500    89.091    616.0\n",
      "                 1     65.254  69.369    67.249    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     82.907     NaN       NaN      NaN\n",
      "         macro avg     73.845  76.601    75.126    860.0\n",
      "      weighted avg     83.554  82.907    83.171    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.144      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 341/415 [04:39<04:26,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7164\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_34_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4790\n",
      "F1-macro: 0.7513\n",
      "F1-pn: 0.6814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches: 100%|██████████| 415/415 [05:21<00:00,  1.29it/s]\n",
      "INFO:root:Epoch 6, Loss: 0.25587002664624925, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1608\n",
      "F1-macro: 0.9356\n",
      "F1-pn: 0.9174\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     96.859  97.528    97.192   4774.0\n",
      "                 1     92.054  87.967    89.964    856.0\n",
      "                 2     93.281  93.744    93.512   1007.0\n",
      "          accuracy     95.721     NaN       NaN      NaN\n",
      "         macro avg     94.064  93.080    93.556   6637.0\n",
      "      weighted avg     95.696  95.721    95.702   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    91.738      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4765\n",
      "F1-macro: 0.7344\n",
      "F1-pn: 0.6575\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.673  88.961    88.817    616.0\n",
      "                 1     65.741  63.964    64.840    111.0\n",
      "                 2     66.418  66.917    66.667    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     73.611  73.281    73.441    860.0\n",
      "      weighted avg     82.271  82.326    82.297    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.753      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0967\n",
      "F1-macro: 0.9632\n",
      "F1-pn: 0.9521\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     97.467  99.650    98.547   1429.0\n",
      "                 1     97.345  87.649    92.243    251.0\n",
      "                 2     99.329  97.049    98.176    305.0\n",
      "          accuracy     97.733     NaN       NaN      NaN\n",
      "         macro avg     98.047  94.783    96.322   1985.0\n",
      "      weighted avg     97.738  97.733    97.693   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    95.209      NaN\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  21%|██        | 86/415 [00:55<14:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5093\n",
      "F1-macro: 0.7301\n",
      "F1-pn: 0.6500\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.638  88.474    89.052    616.0\n",
      "                 1     65.049  60.360    62.617    111.0\n",
      "                 2     63.758  71.429    67.376    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.815  73.421    73.015    860.0\n",
      "      weighted avg     82.462  82.209    82.288    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.996      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 170/415 [01:42<02:18,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 171/415 [01:49<10:33,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5157\n",
      "F1-macro: 0.7346\n",
      "F1-pn: 0.6560\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.066  88.312    89.180    616.0\n",
      "                 1     65.686  60.360    62.911    111.0\n",
      "                 2     63.636  73.684    68.293    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.130  74.119    73.461    860.0\n",
      "      weighted avg     82.832  82.442    82.559    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.602      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  50%|█████     | 209/415 [02:11<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  61%|██████▏   | 255/415 [03:27<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  62%|██████▏   | 256/415 [03:34<06:52,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5263\n",
      "F1-macro: 0.7266\n",
      "F1-pn: 0.6481\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.238  87.500    88.361    616.0\n",
      "                 1     63.248  66.667    64.912    111.0\n",
      "                 2     63.309  66.165    64.706    133.0\n",
      "          accuracy     81.512     NaN       NaN      NaN\n",
      "         macro avg     71.932  73.444    72.660    860.0\n",
      "      weighted avg     81.874  81.512    81.676    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.809      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 340/415 [04:22<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 341/415 [04:29<03:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5225\n",
      "F1-macro: 0.7501\n",
      "F1-pn: 0.6780\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.077  87.825    89.421    616.0\n",
      "                 1     63.710  71.171    67.234    111.0\n",
      "                 2     66.197  70.677    68.364    133.0\n",
      "          accuracy     83.023     NaN       NaN      NaN\n",
      "         macro avg     73.661  76.558    75.006    860.0\n",
      "      weighted avg     83.697  83.023    83.301    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.799      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches: 100%|██████████| 415/415 [05:11<00:00,  1.33it/s]\n",
      "INFO:root:Epoch 7, Loss: 0.1567243077130203, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0857\n",
      "F1-macro: 0.9715\n",
      "F1-pn: 0.9633\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.011  98.555    98.782   4774.0\n",
      "                 1     95.481  96.262    95.870    856.0\n",
      "                 2     96.086  97.517    96.796   1007.0\n",
      "          accuracy     98.102     NaN       NaN      NaN\n",
      "         macro avg     96.859  97.445    97.149   6637.0\n",
      "      weighted avg     98.112  98.102    98.105   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    96.333      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5228\n",
      "F1-macro: 0.7469\n",
      "F1-pn: 0.6728\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.593  89.448    89.521    616.0\n",
      "                 1     66.981  63.964    65.438    111.0\n",
      "                 2     67.626  70.677    69.118    133.0\n",
      "          accuracy     83.256     NaN       NaN      NaN\n",
      "         macro avg     74.734  74.696    74.692    860.0\n",
      "      weighted avg     83.278  83.256    83.257    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.278      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0417\n",
      "F1-macro: 0.9930\n",
      "F1-pn: 0.9905\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.651  99.930    99.790   1429.0\n",
      "                 1     99.593  97.610    98.592    251.0\n",
      "                 2     99.346  99.672    99.509    305.0\n",
      "          accuracy     99.597     NaN       NaN      NaN\n",
      "         macro avg     99.530  99.071    99.297   1985.0\n",
      "      weighted avg     99.597  99.597    99.596   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.050      NaN\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  21%|██        | 86/415 [00:55<14:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5782\n",
      "F1-macro: 0.7385\n",
      "F1-pn: 0.6646\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.522  85.877    88.610    616.0\n",
      "                 1     60.769  71.171    65.560    111.0\n",
      "                 2     63.158  72.180    67.368    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     71.817  76.409    73.846    860.0\n",
      "      weighted avg     83.167  81.860    82.350    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.464      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 170/415 [01:42<02:18,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 171/415 [01:49<10:31,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5757\n",
      "F1-macro: 0.7373\n",
      "F1-pn: 0.6590\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.967  88.799    89.379    616.0\n",
      "                 1     63.393  63.964    63.677    111.0\n",
      "                 2     66.429  69.925    68.132    133.0\n",
      "          accuracy     82.674     NaN       NaN      NaN\n",
      "         macro avg     73.263  74.229    73.729    860.0\n",
      "      weighted avg     82.897  82.674    82.776    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.904      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  50%|█████     | 209/415 [02:11<01:56,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  61%|██████▏   | 255/415 [03:27<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  62%|██████▏   | 256/415 [03:34<06:51,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6007\n",
      "F1-macro: 0.7243\n",
      "F1-pn: 0.6436\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.368  88.799    88.583    616.0\n",
      "                 1     64.356  58.559    61.321    111.0\n",
      "                 2     65.714  69.173    67.399    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.813  72.177    72.434    860.0\n",
      "      weighted avg     81.766  81.860    81.788    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.360      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 340/415 [04:21<00:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 341/415 [04:29<03:11,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6090\n",
      "F1-macro: 0.7377\n",
      "F1-pn: 0.6609\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.604  87.662    89.109    616.0\n",
      "                 1     60.938  70.270    65.272    111.0\n",
      "                 2     66.176  67.669    66.914    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     72.573  75.201    73.765    860.0\n",
      "      weighted avg     82.997  82.326    82.600    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.093      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches: 100%|██████████| 415/415 [05:10<00:00,  1.34it/s]\n",
      "INFO:root:Epoch 8, Loss: 0.07788176874304752, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0389\n",
      "F1-macro: 0.9911\n",
      "F1-pn: 0.9883\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.769  99.560    99.664   4774.0\n",
      "                 1     98.949  98.949    98.949    856.0\n",
      "                 2     98.230  99.206    98.715   1007.0\n",
      "          accuracy     99.427     NaN       NaN      NaN\n",
      "         macro avg     98.983  99.238    99.110   6637.0\n",
      "      weighted avg     99.430  99.427    99.428   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    98.832      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5983\n",
      "F1-macro: 0.7326\n",
      "F1-pn: 0.6530\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.622  89.773    89.194    616.0\n",
      "                 1     66.346  62.162    64.186    111.0\n",
      "                 2     66.667  66.165    66.415    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.878  72.700    73.265    860.0\n",
      "      weighted avg     82.351  82.558    82.443    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.301      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0183\n",
      "F1-macro: 0.9972\n",
      "F1-pn: 0.9962\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.860 100.000    99.930   1429.0\n",
      "                 1    100.000  98.805    99.399    251.0\n",
      "                 2     99.673 100.000    99.836    305.0\n",
      "          accuracy     99.849     NaN       NaN      NaN\n",
      "         macro avg     99.844  99.602    99.722   1985.0\n",
      "      weighted avg     99.849  99.849    99.848   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.618      NaN\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  20%|██        | 85/415 [00:47<03:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  21%|██        | 86/415 [00:55<14:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6646\n",
      "F1-macro: 0.7378\n",
      "F1-pn: 0.6615\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.638  88.474    89.052    616.0\n",
      "                 1     64.407  68.468    66.376    111.0\n",
      "                 2     65.672  66.165    65.918    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.239  74.369    73.782    860.0\n",
      "      weighted avg     82.675  82.442    82.548    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.147      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 170/415 [01:42<02:17,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 171/415 [01:49<10:32,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6442\n",
      "F1-macro: 0.7382\n",
      "F1-pn: 0.6613\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.934  88.474    89.198    616.0\n",
      "                 1     64.865  64.865    64.865    111.0\n",
      "                 2     65.035  69.925    67.391    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.278  74.421    73.818    860.0\n",
      "      weighted avg     82.848  82.558    82.685    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.128      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  50%|█████     | 209/415 [02:11<01:55,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  61%|██████▏   | 255/415 [03:27<01:30,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  62%|██████▏   | 256/415 [03:34<06:52,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6763\n",
      "F1-macro: 0.7240\n",
      "F1-pn: 0.6428\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.511  88.799    88.655    616.0\n",
      "                 1     63.462  59.459    61.395    111.0\n",
      "                 2     65.942  68.421    67.159    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.638  72.226    72.403    860.0\n",
      "      weighted avg     81.788  81.860    81.812    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.277      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 340/415 [04:21<00:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 341/415 [04:29<03:11,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6714\n",
      "F1-macro: 0.7402\n",
      "F1-pn: 0.6645\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.333  87.987    89.145    616.0\n",
      "                 1     64.286  64.865    64.574    111.0\n",
      "                 2     64.865  72.180    68.327    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.161  75.011    74.015    860.0\n",
      "      weighted avg     83.033  82.558    82.754    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.451      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches: 100%|██████████| 415/415 [05:10<00:00,  1.33it/s]\n",
      "INFO:root:Epoch 9, Loss: 0.03388175776239529, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 199\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.init_checkpoint:\n\u001b[32m    197\u001b[39m     model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    108\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss/\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Валидация с обратным распространением ошибки каждые 2 эпохи\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackprop\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag_print\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m evaluate(epoch , backprop=\u001b[33m\"\u001b[39m\u001b[33mTest\u001b[39m\u001b[33m\"\u001b[39m, flag_print = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    112\u001b[39m evaluate(epoch , backprop=\u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m, flag_print = \u001b[38;5;28;01mTrue\u001b[39;00m, vall_train = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(epoch, backprop, flag_print, vall_train)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m#for batch in loader:\u001b[39;00m\n\u001b[32m    134\u001b[39m     input_ids, attention_mask, labels = [x.to(device) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     loss = loss_fct(outputs.logits, labels)\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backprop == \u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m vall_train:\n\u001b[32m    141\u001b[39m         \u001b[38;5;66;03m#уменьшая тк обучающие данные удвоились\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mRobertaWithMultiSampleDropoutTarget.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token_id \u001b[38;5;129;01min\u001b[39;00m start_token_ids:\n\u001b[32m     60\u001b[39m     start_positions |= (input_ids == token_id)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m start_positions = \u001b[43mstart_positions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m end_positions = (input_ids == end_token_id).nonzero(as_tuple=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# --- 2. Для каждого примера агрегируем hidden states между <en> и </en> ---\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "teg_class_entity = [\"COUNTRY\", \"NATIONALITY\", \"ORGANIZATION\", \"PERSON\", \"PROFESSION\"]\n",
    "lr_m = 1e-6\n",
    "# lr = 1e-6 началось обучение, уменьшение TrainError\n",
    "# добавить волидацию по шагам в течение эпохи обучения, а не каджые N епох\n",
    "# Добавить сохранение ошибки в файлы для построения графиков\n",
    "# проверить методы передачи сущьности (параетром, +тип, или в тексте выделяя тегами).\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"./../ruRoberta-large/\")\n",
    "    #parser.add_argument(\"--model_name\", type=str, default=\"sberbank-ai/ruRoberta-large\", help=\"Имя модели\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=512) #128\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=lr_m)\n",
    "    parser.add_argument(\"--init_checkpoint\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_data\", type=str, required=False, default=\"./../data/train_data.csv\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, required=False, default=\"./../data/validation.csv\")\n",
    "    parser.add_argument(\"--eval_data\", type=str, required=False, default=\"./../data/test.csv\")\n",
    "    parser.add_argument(\"--result\", type=str, default=f\"./result_lr_{lr_m}_ENS_Teg_34_multi_dropout_V3_Token_Target/\")\n",
    "    # Игнорируем аргументы Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    os.makedirs(args.result, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    print(args)  # Проверяем аргументы\n",
    "\n",
    "    base_lr = args.lr\n",
    "    min_lr = base_lr * (1/4)\n",
    "    step_size_up = 400 #400\n",
    "    best_avg_f1 = 0.0\n",
    "    \n",
    "    best_model_path = os.path.join(args.result, \"best_model.pth\")\n",
    "\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.model_name)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained(args.model_name, num_labels=3)\n",
    "    model = RobertaWithMultiSampleDropoutTarget(model_name='./../ruRoberta-large', num_labels=3, use_multi_sample_dropout=True )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset = load_data(args.train_data, tokenizer, args.max_seq_len)\n",
    "    validation_data = load_data(args.validation_data, tokenizer, args.max_seq_len)\n",
    "    eval_dataset = load_data(args.eval_data, tokenizer, args.max_seq_len)\n",
    "\n",
    "    if train_dataset is None or eval_dataset is None or validation_data is None:\n",
    "        sys.exit(f\"Ошибка загрузки данных: убедитесь, что файлы {args.train_data}, {args.validation_data} и {args.eval_data} существуют и содержат нужные колонки.\")\n",
    "\n",
    "    #сохранение текста и токенов, с дабовлением собственных\n",
    "    save_contrel_date(tokenizer,train_dataset)\n",
    "    model.roberta.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    embedding_layer = model.roberta.embeddings.word_embeddings\n",
    "    print(embedding_layer.weight[tokenizer.convert_tokens_to_ids(\"<en>\")])\n",
    "    \n",
    "    # Получаем метки классов из тренировочного датасета\n",
    "    train_labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "    # Вычисляем веса классов\n",
    "    class_weights = compute_ens_weights(train_labels, beta=0.999)\n",
    "\n",
    "    # Вывод весов классов\n",
    "    print(f\"class_weights = {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=args.batch_size)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    #scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr = base_lr, step_size_up = step_size_up, mode=\"triangular2\",cycle_momentum=False )\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        batches_per_validation = (len(train_loader) // 2)+2\n",
    "        batches_per_test = (len(train_loader) // 5)+2\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"Epoch: {epoch}/{args.epochs}\")\n",
    "            total_loss = 0\n",
    "            for i,batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Batches\")):\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                if(i % batches_per_validation == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Validation\", vall_train = True)\n",
    "                if(i % batches_per_test == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Test\", flag_print = True)\n",
    "                \n",
    "            logging.info(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Step: {len(train_loader)}\")\n",
    "            # Валидация с обратным распространением ошибки каждые 2 эпохи\n",
    "            evaluate(epoch , backprop=\"Train\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Test\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Validation\", flag_print = True, vall_train = True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def evaluate(epoch = None, backprop = \"None\", flag_print = False, vall_train = False):\n",
    "        global best_avg_f1\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        total_loss = 0\n",
    "        print(f\"evaluate, backprop: {backprop}\")\n",
    "        loader = validation_loader\n",
    "        if backprop == \"Validation\":\n",
    "            loader = validation_loader\n",
    "        elif backprop == \"Test\":\n",
    "            loader = eval_loader\n",
    "        elif backprop == \"Train\":\n",
    "            loader = train_loader\n",
    "        \n",
    "        else: loader = eval_loader\n",
    "        with torch.no_grad() if not backprop == \"Validation\" else torch.enable_grad():  # Включаем градиенты для обучения на валидации\n",
    "            for batch in loader:\n",
    "            #for batch in loader:\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if backprop == \"Validation\" and vall_train:\n",
    "                    #уменьшая тк обучающие данные удвоились\n",
    "                    loss = loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #scheduler.step()\n",
    "                    loss = loss\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        f1_pn = f1_score(all_labels, all_preds, labels=[1, 2], average='macro')\n",
    "        avg_f1 = (f1 + f1_pn) / 2\n",
    "\n",
    "        if(flag_print):\n",
    "            print()\n",
    "            print(\"--\"*20)\n",
    "            print(f\"Result evaluate in {backprop}\")\n",
    "            #logging.info(f\"{backprop} Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "            #print(classification_report(all_labels, all_preds))\n",
    "            castom_classification_report(all_labels, all_preds)\n",
    "\n",
    "        # 💾 Сохраняем модель только при улучшении средней метрики\n",
    "        if (avg_f1 > best_avg_f1) and backprop == \"Test\":\n",
    "            best_avg_f1 = avg_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            \n",
    "            print(f\"[Checkpoint] 🎯 Новый лучший средний F1: {best_avg_f1:.4f}\")\n",
    "            print(f\"[Checkpoint] 💾 Модель сохранена: {best_model_path}\")\n",
    "            # 🔸 Сохраняем значение лучшего F1 в файл\n",
    "            best_score_path = os.path.join(args.result, \"best_score.txt\")\n",
    "            save_metrics_best(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "            save_confusion_matrix(epoch, all_labels, all_preds, args.result, backprop)\n",
    "            with open(best_score_path, \"w\") as f:\n",
    "                f.write(f\"Epoch: {epoch}\\n\")\n",
    "                f.write(f\"Loss: {avg_loss:.4f}\\n\")\n",
    "                f.write(f\"F1-pn0: {f1:.4f}\\n\")\n",
    "                f.write(f\"F1-pn: {f1_pn:.4f}\\n\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "\n",
    "\n",
    "        if epoch is not None:\n",
    "            save_metrics(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "        \n",
    "    if args.init_checkpoint:\n",
    "        model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n",
    "\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4520d-65bf-4708-99bc-4807f25ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805557fd-243e-47ff-b33c-4ce8c82c159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Загружаем токенизатор и модель\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Добавим специальные токены\n",
    "special_tokens = {\"additional_special_tokens\": [\"<en>\", \"</en>\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Пример текста\n",
    "text = \"This is <en> Apple  company </en>.\"\n",
    "\n",
    "# Токенизация\n",
    "encoding = tokenizer(text, return_tensors='pt')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "# Пропускаем через модель\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = outputs.last_hidden_state\n",
    "\n",
    "# Получаем ID спецтокенов\n",
    "en_token_id = tokenizer.convert_tokens_to_ids(\"<en>\")\n",
    "end_en_token_id = tokenizer.convert_tokens_to_ids(\"</en>\")\n",
    "\n",
    "# Извлекаем эмбеддинги сущности\n",
    "input_id = input_ids[0]\n",
    "output = sequence_output[0]\n",
    "\n",
    "# Ищем индексы <en> и </en>\n",
    "start = (input_id == en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "end = (input_id == end_en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "\n",
    "# Эмбеддинги между <en> и </en>\n",
    "entity_tokens = output[start + 1:end]\n",
    "\n",
    "print(f\"Токены сущности: {tokenizer.convert_ids_to_tokens(input_id[start+1:end])}\")\n",
    "print(f\"Форма эмбеддингов: {entity_tokens.shape}\")\n",
    "\n",
    "\n",
    "# Среднее по токенам сущности\n",
    "entity_embedding = entity_tokens.mean(dim=0)\n",
    "print(f\"Размерность итогового эмбеддинга сущности: {entity_embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9444b-5431-4eb6-8ff8-9074d559598b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ryumin_env",
   "language": "python",
   "name": "ryumin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
