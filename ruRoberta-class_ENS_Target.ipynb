{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd128c19-762d-49e7-959a-845e0599a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CyclicLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f20af-edf7-4cf5-84b3-bc8e437c24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaWithMultiSampleDropoutTarget(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3, num_dropouts=5, use_multi_sample_dropout=True):\n",
    "        super(RobertaWithMultiSampleDropoutTarget, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.use_multi_sample_dropout = use_multi_sample_dropout\n",
    "        self.hidden_size = self.roberta.config.hidden_size\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(dropout_rate) for _ in range(num_dropouts)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.classifier = nn.Linear(self.hidden_size, num_labels)\n",
    "\n",
    "    def extract_entity_embeddings(self, input_ids, sequence_output, en_token_id, end_en_token_id):\n",
    "        batch_size = input_ids.size(0)\n",
    "        entity_representations = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            input_id = input_ids[i]\n",
    "            output = sequence_output[i]\n",
    "\n",
    "            try:\n",
    "                start = (input_id == en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "                end = (input_id == end_en_token_id).nonzero(as_tuple=True)[0].item()\n",
    "            except IndexError:\n",
    "                # если вдруг токены не найдены — fallback на [CLS]\n",
    "                entity_representations.append(output[0])\n",
    "                continue\n",
    "\n",
    "            # вырезаем эмбеддинги между <en> и </en>\n",
    "            entity_tokens = output[start + 1:end]\n",
    "            if entity_tokens.shape[0] == 0:\n",
    "                entity_representations.append(output[0])  # fallback на [CLS]\n",
    "            else:\n",
    "                entity_representations.append(entity_tokens.mean(dim=0))  # mean pooling\n",
    "\n",
    "        return torch.stack(entity_representations)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        sequence_output = outputs[0]  # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # --- 1. Находим позиции <en> и </en> ---\n",
    "        start_token_id = tokenizer.convert_tokens_to_ids(\"<en>\")\n",
    "        end_token_id = tokenizer.convert_tokens_to_ids(\"</en>\")\n",
    "    \n",
    "        start_positions = (input_ids == start_token_id).nonzero(as_tuple=False)\n",
    "        end_positions = (input_ids == end_token_id).nonzero(as_tuple=False)\n",
    "\n",
    "        # --- 2. Для каждого примера агрегируем hidden states между <en> и </en> ---\n",
    "        pooled_output = []\n",
    "        for batch_idx in range(input_ids.size(0)):\n",
    "            start_pos = start_positions[start_positions[:, 0] == batch_idx][:, 1]\n",
    "            end_pos = end_positions[end_positions[:, 0] == batch_idx][:, 1]\n",
    "            if len(start_pos) > 0 and len(end_pos) > 0:\n",
    "                s, e = start_pos[0].item() + 1, end_pos[0].item()  # между тегами\n",
    "                if e > s:\n",
    "                    token_embeds = sequence_output[batch_idx, s:e, :]  # [num_entity_tokens, hidden]\n",
    "                    pooled = torch.mean(token_embeds, dim=0)  # Mean-pooling\n",
    "                else:\n",
    "                    pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "            else:\n",
    "                pooled = sequence_output[batch_idx, 0, :]  # fallback to [CLS]\n",
    "\n",
    "            pooled_output.append(pooled)\n",
    "\n",
    "        pooled_output = torch.stack(pooled_output)  # [batch_size, hidden_size]\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            logits_list = [self.classifier(dropout(pooled_output)) for dropout in self.dropouts]\n",
    "            avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "        else:\n",
    "            avg_logits = self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "        return SequenceClassifierOutput(logits=avg_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1746-8eac-4865-8f99-828b9055d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_best(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metrics_file = os.path.join(result_path, \"metrics_best.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Создаем словарь с метриками\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop,\n",
    "        \"loss\": loss\n",
    "    }\n",
    "\n",
    "    # Добавляем метрики по каждому классу\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "\n",
    "    # Создаем DataFrame и сохраняем его в CSV (перезапись файла)\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2886be9d-a3f4-4164-8002-b4cc31a22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ens_weights(train_labels, beta: float = 0.999):\n",
    "    train_labels = np.array(train_labels)\n",
    "    classes, counts = np.unique(train_labels, return_counts=True)\n",
    "    effective_num = (1 - np.power(beta, counts)) / (1 - beta)\n",
    "    weights = 1.0 / effective_num\n",
    "    weights = weights / np.sum(weights) * len(classes)  # нормализация как в оригинальной статье\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d52154-884f-4289-8b00-b19358f419e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tags_from_files(*file_paths):\n",
    "    all_tags = set()\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "            if \"entity_tag\" in df.columns:\n",
    "                tags = df[\"entity_tag\"].dropna().unique().tolist()\n",
    "                all_tags.update(tags)\n",
    "        except Exception as e:\n",
    "            print(f\"[Ошибка] Не удалось загрузить {path}: {e}\")\n",
    "    return sorted(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be23ac59-6617-40d9-b01b-be5ff22e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, tokenizer, max_seq_len):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # Загружаем CSV (TSV)\n",
    "\n",
    "        # Проверка нужных колонок\n",
    "        required_columns = {\n",
    "            \"sentence\", \"entity\", \"label\", \"entity_tag\",\n",
    "            \"entity_pos_start_rel\", \"entity_pos_end_rel\"\n",
    "        }\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Ожидаемые колонки: {required_columns}, но в файле: {df.columns}\")\n",
    "\n",
    "        # Заменяем -1 на 2 (если есть)\n",
    "        df[\"label\"] = df[\"label\"].replace(-1, 2)\n",
    "\n",
    "        # Размечаем предложения с [ENTITY] токенами\n",
    "        def mark_entity_inline(row):\n",
    "            sent = row[\"sentence\"]\n",
    "            start = row[\"entity_pos_start_rel\"]\n",
    "            end = row[\"entity_pos_end_rel\"]\n",
    "            tag = row[\"entity_tag\"]\n",
    "            tag_token = f\"<en>\"\n",
    "            tag_token_close = f\"</en>\"\n",
    "            return (\n",
    "                sent[:start] +\n",
    "                f\"{tag_token} \" + sent[start:end] + f\" {tag_token_close}\" +\n",
    "                sent[end:]\n",
    "            )\n",
    "\n",
    "        df[\"input_text\"] = df.apply(mark_entity_inline, axis=1)\n",
    "        texts = df[\"input_text\"].tolist()\n",
    "        labels = torch.tensor(df[\"label\"].astype(int).tolist(), dtype=torch.long)\n",
    "\n",
    "        # Токенизируем\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True,\n",
    "                              max_length=max_seq_len, return_tensors='pt')\n",
    "        dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "        return dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Файл {file_path} не найден!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbfe22-f0f3-4f70-b366-53259c79ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_metrics(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    metrics_file = os.path.join(result_path, \"metrics_class_weights.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    \n",
    "    # Создаем DataFrame для метрик\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop , # (Добавлено)\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    \n",
    "    # Добавляем метрики для каждого класса\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):  # Пропускаем 'accuracy', так как это float\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    # Создаем DataFrame и сохраняем в CSV\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='a', header=not os.path.exists(metrics_file), index=False)\n",
    "\n",
    "def save_confusion_matrix(epoch, y_true, y_pred, result_path,backprop):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"Pred_0\", \"Pred_1\", \"Pred_2\"], index=[\"True_0\", \"True_1\", \"True_2\"])\n",
    "    cm_file = os.path.join(result_path, f\"confusion_matrix_class_weights_epoch_{epoch}_backprop_{backprop}.csv\")\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd447891-39c3-42bc-981d-96b2800a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def castom_classification_report(all_labels, all_preds):\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    data = []\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):  # Для всех метрик, кроме accuracy\n",
    "            row = {'label': label}\n",
    "            for metric, value in metrics.items():\n",
    "                row[metric] = round(value * 100, 3) if metric != 'support' else value\n",
    "            data.append(row)\n",
    "        else:  # Для accuracy\n",
    "            data.append({'label': 'accuracy', 'precision': round(metrics * 100, 3), 'recall': None, 'f1-score': None, 'support': None})\n",
    "\n",
    "    # Добавляем macro F1 для классов 1 и 2\n",
    "    if '1' in report and '2' in report:\n",
    "        f1_1 = report['1']['f1-score']\n",
    "        f1_2 = report['2']['f1-score']\n",
    "        f1_macro_1_2 = (f1_1 + f1_2) / 2\n",
    "        data.append({\n",
    "            'label': 'avg f1 (class 1&2)',\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': round(f1_macro_1_2 * 100, 3),\n",
    "            'support': None\n",
    "        })\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = [''] * len(df)\n",
    "\n",
    "    # Выводим таблицу\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447e1ed-4fc6-43aa-a54c-d9023898afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token(flag = False):\n",
    "    # Формируем список специальных токенов\n",
    "    if not flag: return None\n",
    "    special_tokens = {\n",
    "        \"additional_special_tokens\": \n",
    "            [\"<en>\", \"</en>\"]\n",
    "    }\n",
    "\n",
    "    print(\"Добавленные специальные токены:\")\n",
    "    for token in special_tokens[\"additional_special_tokens\"]:\n",
    "        print(token)\n",
    "    return special_tokens\n",
    "\n",
    "def save_contrel_date(tokenizer, train_dataset):\n",
    "    special_tokens = add_token(flag = True)\n",
    "    if special_tokens != None: \n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "    tokenizer.save_pretrained(os.path.join(args.result, \"tokenizer\"))\n",
    "    print(tokenizer.special_tokens_map)\n",
    "    print(tokenizer.additional_special_tokens)\n",
    "\n",
    "    \n",
    "    file_control_text = os.path.join(args.result, \"use_market_text.txt\")\n",
    "    input_ids, attention_mask, label = train_dataset[0]\n",
    "    decoded_text_token = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    decoded_text = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    with open(file_control_text, \"w\") as f:\n",
    "        f.write(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "        f.write(f\"Text:\\n{decoded_text}\\n\\n\")\n",
    "    print(f\"Text token:\\n{decoded_text_token}\\n\\n\")\n",
    "    print(f\"Text:\\n{decoded_text}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af33277-341d-43ba-8b31-c9bba05cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_name='./../ruRoberta-large/', max_seq_len=512, batch_size=16, epochs=10, lr=1e-06, init_checkpoint=None, train_data='./../data/train_data.csv', validation_data='./../data/validation.csv', eval_data='./../data/test.csv', result='./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./../ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавленные специальные токены:\n",
      "<en>\n",
      "</en>\n",
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<en>', '</en>']}\n",
      "['<en>', '</en>']\n",
      "Text token:\n",
      "<s>Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена </en> остановить бой, но тот хотел продолжать.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "\n",
      "\n",
      "Text:\n",
      "Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского <en> спортсмена </en> остановить бой, но тот хотел продолжать.\n",
      "\n",
      "\n",
      "tensor([-0.0327, -0.0121,  0.0661,  ..., -0.1582, -0.0727,  0.0517],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "class_weights = tensor([0.7001, 1.2066, 1.0934])\n",
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  20%|██        | 85/415 [00:45<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.8128\n",
      "F1-macro: 0.2924\n",
      "F1-pn: 0.0229\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.731  98.864    83.140    616.0\n",
      "                 1     50.000   0.901     1.770    111.0\n",
      "                 2     22.222   1.504     2.817    133.0\n",
      "          accuracy     71.163     NaN       NaN      NaN\n",
      "         macro avg     47.985  33.756    29.242    860.0\n",
      "      weighted avg     61.270  71.163    60.215    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     2.293      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  21%|██        | 86/415 [00:53<16:29,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1577\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.8128\n",
      "F1-macro: 0.2924\n",
      "F1-pn: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 170/415 [01:37<02:08,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  41%|████      | 171/415 [01:44<10:07,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7599\n",
      "F1-macro: 0.2841\n",
      "F1-pn: 0.0088\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.678  99.838    83.446    616.0\n",
      "                 1     50.000   0.901     1.770    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.628     NaN       NaN      NaN\n",
      "         macro avg     40.559  33.580    28.405    860.0\n",
      "      weighted avg     57.795  71.628    59.999    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.885      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  50%|████▉     | 207/415 [02:03<01:49,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  61%|██████▏   | 255/415 [03:16<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7547\n",
      "F1-macro: 0.3246\n",
      "F1-pn: 0.0693\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.381  98.701    83.516    616.0\n",
      "                 1     50.000   4.505     8.264    111.0\n",
      "                 2     40.000   3.008     5.594    133.0\n",
      "          accuracy     71.744     NaN       NaN      NaN\n",
      "         macro avg     54.127  35.404    32.458    860.0\n",
      "      weighted avg     64.484  71.744    61.753    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     6.929      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  62%|██████▏   | 256/415 [03:26<09:18,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1969\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7547\n",
      "F1-macro: 0.3246\n",
      "F1-pn: 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 340/415 [04:10<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7125\n",
      "F1-macro: 0.3332\n",
      "F1-pn: 0.0825\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     72.488  98.377    83.471    616.0\n",
      "                 1     66.667   1.802     3.509    111.0\n",
      "                 2     47.619   7.519    12.987    133.0\n",
      "          accuracy     71.860     NaN       NaN      NaN\n",
      "         macro avg     62.258  35.899    33.322    860.0\n",
      "      weighted avg     67.891  71.860    62.250    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     8.248      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 341/415 [04:21<04:20,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2079\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.7125\n",
      "F1-macro: 0.3332\n",
      "F1-pn: 0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches: 100%|██████████| 415/415 [05:00<00:00,  1.38it/s]\n",
      "INFO:root:Epoch 1, Loss: 0.8886837448700364, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.7759\n",
      "F1-macro: 0.4048\n",
      "F1-pn: 0.1858\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     74.316  97.340    84.284   4774.0\n",
      "                 1     68.519   4.322     8.132    856.0\n",
      "                 2     58.788  19.265    29.020   1007.0\n",
      "          accuracy     73.497     NaN       NaN      NaN\n",
      "         macro avg     67.208  40.309    40.479   6637.0\n",
      "      weighted avg     71.213  73.497    66.077   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    18.576      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6929\n",
      "F1-macro: 0.3769\n",
      "F1-pn: 0.1474\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     73.374  97.078    83.578    616.0\n",
      "                 1     83.333   4.505     8.547    111.0\n",
      "                 2     46.154  13.534    20.930    133.0\n",
      "          accuracy     72.209     NaN       NaN      NaN\n",
      "         macro avg     67.620  38.372    37.685    860.0\n",
      "      weighted avg     70.450  72.209    64.205    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    14.739      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2621\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6929\n",
      "F1-macro: 0.3769\n",
      "F1-pn: 0.1474\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.7084\n",
      "F1-macro: 0.4219\n",
      "F1-pn: 0.2021\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.989  99.440    86.147   1429.0\n",
      "                 1     50.000   1.992     3.831    251.0\n",
      "                 2     71.429  24.590    36.585    305.0\n",
      "          accuracy     75.617     NaN       NaN      NaN\n",
      "         macro avg     65.806  42.007    42.188   1985.0\n",
      "      weighted avg     72.002  75.617    68.123   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    20.208      NaN\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  20%|██        | 85/415 [00:44<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6643\n",
      "F1-macro: 0.4590\n",
      "F1-pn: 0.2688\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.128  95.130    83.954    616.0\n",
      "                 1     70.833  15.315    25.185    111.0\n",
      "                 2     48.214  20.301    28.571    133.0\n",
      "          accuracy     73.256     NaN       NaN      NaN\n",
      "         macro avg     64.725  43.582    45.904    860.0\n",
      "      weighted avg     70.412  73.256    67.804    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    26.878      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  21%|██        | 86/415 [00:55<19:29,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3639\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6643\n",
      "F1-macro: 0.4590\n",
      "F1-pn: 0.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 170/415 [01:39<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6583\n",
      "F1-macro: 0.5470\n",
      "F1-pn: 0.4000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.481  90.584    84.099    616.0\n",
      "                 1     58.000  26.126    36.025    111.0\n",
      "                 2     51.515  38.346    43.966    133.0\n",
      "          accuracy     74.186     NaN       NaN      NaN\n",
      "         macro avg     62.665  51.685    54.697    860.0\n",
      "      weighted avg     71.667  74.186    71.688    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    39.995      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 171/415 [01:50<14:32,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.4735\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6583\n",
      "F1-macro: 0.5470\n",
      "F1-pn: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  50%|█████     | 209/415 [02:10<01:48,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  61%|██████▏   | 255/415 [03:22<01:24,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  62%|██████▏   | 256/415 [03:29<06:38,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6163\n",
      "F1-macro: 0.5283\n",
      "F1-pn: 0.3709\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     77.778  92.045    84.312    616.0\n",
      "                 1     69.231  16.216    26.277    111.0\n",
      "                 2     54.286  42.857    47.899    133.0\n",
      "          accuracy     74.651     NaN       NaN      NaN\n",
      "         macro avg     67.098  50.373    52.830    860.0\n",
      "      weighted avg     73.042  74.651    71.190    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    37.088      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 340/415 [04:13<00:39,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6001\n",
      "F1-macro: 0.5543\n",
      "F1-pn: 0.4095\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.762  90.909    84.401    616.0\n",
      "                 1     64.103  22.523    33.333    111.0\n",
      "                 2     53.636  44.361    48.560    133.0\n",
      "          accuracy     74.884     NaN       NaN      NaN\n",
      "         macro avg     65.500  52.598    55.431    860.0\n",
      "      weighted avg     72.984  74.884    72.267    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    40.947      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 341/415 [04:24<04:21,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.4819\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.6001\n",
      "F1-macro: 0.5543\n",
      "F1-pn: 0.4095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches: 100%|██████████| 415/415 [05:03<00:00,  1.37it/s]\n",
      "INFO:root:Epoch 2, Loss: 0.7459811371493053, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.6267\n",
      "F1-macro: 0.6291\n",
      "F1-pn: 0.5134\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     82.887  89.485    86.060   4774.0\n",
      "                 1     68.217  30.841    42.478    856.0\n",
      "                 2     57.755  62.860    60.200   1007.0\n",
      "          accuracy     77.882     NaN       NaN      NaN\n",
      "         macro avg     69.620  61.062    62.912   6637.0\n",
      "      weighted avg     77.182  77.882    76.515   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    51.339      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5950\n",
      "F1-macro: 0.5758\n",
      "F1-pn: 0.4423\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.896  87.987    84.292    616.0\n",
      "                 1     63.636  25.225    36.129    111.0\n",
      "                 2     50.000  54.887    52.330    133.0\n",
      "          accuracy     74.767     NaN       NaN      NaN\n",
      "         macro avg     64.844  56.033    57.584    860.0\n",
      "      weighted avg     73.890  74.767    73.133    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    44.229      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5091\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5950\n",
      "F1-macro: 0.5758\n",
      "F1-pn: 0.4423\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.5640\n",
      "F1-macro: 0.5531\n",
      "F1-pn: 0.3923\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     79.689  96.921    87.464   1429.0\n",
      "                 1     43.636   9.562    15.686    251.0\n",
      "                 2     81.250  51.148    62.777    305.0\n",
      "          accuracy     78.841     NaN       NaN      NaN\n",
      "         macro avg     68.192  52.543    55.309   1985.0\n",
      "      weighted avg     75.370  78.841    74.595   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    39.231      NaN\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  20%|██        | 85/415 [00:44<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5697\n",
      "F1-macro: 0.5905\n",
      "F1-pn: 0.4580\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.516  91.234    85.540    616.0\n",
      "                 1     63.265  27.928    38.750    111.0\n",
      "                 2     57.522  48.872    52.846    133.0\n",
      "          accuracy     76.512     NaN       NaN      NaN\n",
      "         macro avg     67.101  56.011    59.045    860.0\n",
      "      weighted avg     74.733  76.512    74.445    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    45.798      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  21%|██        | 86/415 [00:56<21:44,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5242\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5697\n",
      "F1-macro: 0.5905\n",
      "F1-pn: 0.4580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 170/415 [01:41<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5522\n",
      "F1-macro: 0.6104\n",
      "F1-pn: 0.4883\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.967  89.286    85.470    616.0\n",
      "                 1     58.462  34.234    43.182    111.0\n",
      "                 2     56.452  52.632    54.475    133.0\n",
      "          accuracy     76.512     NaN       NaN      NaN\n",
      "         macro avg     65.627  58.717    61.042    860.0\n",
      "      weighted avg     74.987  76.512    75.218    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    48.828      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 171/415 [01:51<14:20,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5494\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5522\n",
      "F1-macro: 0.6104\n",
      "F1-pn: 0.4883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  50%|█████     | 209/415 [02:11<01:48,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  61%|██████▏   | 255/415 [03:23<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  62%|██████▏   | 256/415 [03:30<06:38,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5492\n",
      "F1-macro: 0.5985\n",
      "F1-pn: 0.4709\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.753  90.584    85.386    616.0\n",
      "                 1     60.000  32.432    42.105    111.0\n",
      "                 2     57.798  47.368    52.066    133.0\n",
      "          accuracy     76.395     NaN       NaN      NaN\n",
      "         macro avg     66.184  56.795    59.853    860.0\n",
      "      weighted avg     74.524  76.395    74.647    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    47.086      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 340/415 [04:14<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5251\n",
      "F1-macro: 0.6125\n",
      "F1-pn: 0.4877\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     81.991  90.909    86.220    616.0\n",
      "                 1     68.085  28.829    40.506    111.0\n",
      "                 2     57.692  56.391    57.034    133.0\n",
      "          accuracy     77.558     NaN       NaN      NaN\n",
      "         macro avg     69.256  58.710    61.254    860.0\n",
      "      weighted avg     76.439  77.558    75.806    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    48.770      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 341/415 [04:25<04:21,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5501\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5251\n",
      "F1-macro: 0.6125\n",
      "F1-pn: 0.4877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches: 100%|██████████| 415/415 [05:04<00:00,  1.36it/s]\n",
      "INFO:root:Epoch 3, Loss: 0.6200981029185904, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.5107\n",
      "F1-macro: 0.7168\n",
      "F1-pn: 0.6337\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.819  88.793    88.303   4774.0\n",
      "                 1     64.380  51.519    57.236    856.0\n",
      "                 2     65.867  73.585    69.512   1007.0\n",
      "          accuracy     81.678     NaN       NaN      NaN\n",
      "         macro avg     72.688  71.299    71.684   6637.0\n",
      "      weighted avg     81.465  81.678    81.445   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.374      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5269\n",
      "F1-macro: 0.6682\n",
      "F1-pn: 0.5703\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.129  86.688    86.408    616.0\n",
      "                 1     60.494  44.144    51.042    111.0\n",
      "                 2     57.862  69.173    63.014    133.0\n",
      "          accuracy     78.488     NaN       NaN      NaN\n",
      "         macro avg     68.161  66.668    66.821    860.0\n",
      "      weighted avg     78.449  78.488    78.225    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    57.028      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6192\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5269\n",
      "F1-macro: 0.6682\n",
      "F1-pn: 0.5703\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.4474\n",
      "F1-macro: 0.6428\n",
      "F1-pn: 0.5191\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.121  95.801    89.012   1429.0\n",
      "                 1     51.546  19.920    28.736    251.0\n",
      "                 2     85.062  67.213    75.092    305.0\n",
      "          accuracy     81.814     NaN       NaN      NaN\n",
      "         macro avg     73.243  60.978    64.280   1985.0\n",
      "      weighted avg     79.427  81.814    79.251   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    51.914      NaN\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  20%|██        | 85/415 [00:44<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5482\n",
      "F1-macro: 0.6745\n",
      "F1-pn: 0.5837\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.831  82.630    85.618    616.0\n",
      "                 1     52.632  54.054    53.333    111.0\n",
      "                 2     56.069  72.932    63.399    133.0\n",
      "          accuracy     77.442     NaN       NaN      NaN\n",
      "         macro avg     65.844  69.872    67.450    860.0\n",
      "      weighted avg     79.092  77.442    78.015    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.366      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  21%|██        | 86/415 [00:55<19:19,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6291\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5482\n",
      "F1-macro: 0.6745\n",
      "F1-pn: 0.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 170/415 [01:39<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 171/415 [01:46<10:11,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5041\n",
      "F1-macro: 0.6720\n",
      "F1-pn: 0.5746\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.196  87.175    86.683    616.0\n",
      "                 1     59.524  45.045    51.282    111.0\n",
      "                 2     59.477  68.421    63.636    133.0\n",
      "          accuracy     78.837     NaN       NaN      NaN\n",
      "         macro avg     68.399  66.880    67.200    860.0\n",
      "      weighted avg     78.621  78.837    78.549    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    57.459      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  50%|█████     | 209/415 [02:06<01:48,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  61%|██████▏   | 255/415 [03:18<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  62%|██████▏   | 256/415 [03:25<06:39,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5015\n",
      "F1-macro: 0.6579\n",
      "F1-pn: 0.5542\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.086  87.987    86.512    616.0\n",
      "                 1     59.494  42.342    49.474    111.0\n",
      "                 2     59.028  63.910    61.372    133.0\n",
      "          accuracy     78.372     NaN       NaN      NaN\n",
      "         macro avg     67.869  64.746    65.786    860.0\n",
      "      weighted avg     77.753  78.372    77.844    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    55.423      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 340/415 [04:09<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 341/415 [04:17<03:05,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4947\n",
      "F1-macro: 0.6721\n",
      "F1-pn: 0.5738\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.234  86.526    86.879    616.0\n",
      "                 1     57.778  46.847    51.741    111.0\n",
      "                 2     57.862  69.173    63.014    133.0\n",
      "          accuracy     78.721     NaN       NaN      NaN\n",
      "         macro avg     67.624  67.515    67.211    860.0\n",
      "      weighted avg     78.890  78.721    78.653    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    57.377      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches: 100%|██████████| 415/415 [04:56<00:00,  1.40it/s]\n",
      "INFO:root:Epoch 4, Loss: 0.5244151362453598, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4321\n",
      "F1-macro: 0.7649\n",
      "F1-pn: 0.6978\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.355  89.485    89.918   4774.0\n",
      "                 1     71.248  59.346    64.755    856.0\n",
      "                 2     68.896  81.827    74.807   1007.0\n",
      "          accuracy     84.436     NaN       NaN      NaN\n",
      "         macro avg     76.833  76.886    76.493   6637.0\n",
      "      weighted avg     84.635  84.436    84.380   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    69.781      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4924\n",
      "F1-macro: 0.6763\n",
      "F1-pn: 0.5829\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.752  84.903    86.304    616.0\n",
      "                 1     58.889  47.748    52.736    111.0\n",
      "                 2     56.322  73.684    63.844    133.0\n",
      "          accuracy     78.372     NaN       NaN      NaN\n",
      "         macro avg     67.654  68.778    67.628    860.0\n",
      "      weighted avg     79.166  78.372    78.498    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.290      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6296\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4924\n",
      "F1-macro: 0.6763\n",
      "F1-pn: 0.5829\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.3653\n",
      "F1-macro: 0.7345\n",
      "F1-pn: 0.6453\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.475  96.641    91.276   1429.0\n",
      "                 1     71.654  36.255    48.148    251.0\n",
      "                 2     87.739  75.082    80.919    305.0\n",
      "          accuracy     85.693     NaN       NaN      NaN\n",
      "         macro avg     81.956  69.326    73.447   1985.0\n",
      "      weighted avg     84.795  85.693    84.231   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.533      NaN\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  20%|██        | 85/415 [00:44<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5181\n",
      "F1-macro: 0.7055\n",
      "F1-pn: 0.6267\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.927  81.331    86.305    616.0\n",
      "                 1     56.667  61.261    58.874    111.0\n",
      "                 2     55.897  81.955    66.463    133.0\n",
      "          accuracy     78.837     NaN       NaN      NaN\n",
      "         macro avg     68.164  74.849    70.548    860.0\n",
      "      weighted avg     81.804  78.837    79.696    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.669      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  21%|██        | 86/415 [00:55<19:21,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6661\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5181\n",
      "F1-macro: 0.7055\n",
      "F1-pn: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 170/415 [01:39<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 171/415 [01:46<10:12,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4800\n",
      "F1-macro: 0.6989\n",
      "F1-pn: 0.6152\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.310  84.091    86.622    616.0\n",
      "                 1     56.667  61.261    58.874    111.0\n",
      "                 2     58.750  70.677    64.164    133.0\n",
      "          accuracy     79.070     NaN       NaN      NaN\n",
      "         macro avg     68.242  72.010    69.887    860.0\n",
      "      weighted avg     80.371  79.070    79.568    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.519      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  50%|█████     | 209/415 [02:07<01:48,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  61%|██████▏   | 255/415 [03:18<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  62%|██████▏   | 256/415 [03:25<06:39,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4733\n",
      "F1-macro: 0.6843\n",
      "F1-pn: 0.5899\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.871  88.799    87.310    616.0\n",
      "                 1     58.947  50.450    54.369    111.0\n",
      "                 2     64.844  62.406    63.602    133.0\n",
      "          accuracy     79.767     NaN       NaN      NaN\n",
      "         macro avg     69.887  67.218    68.427    860.0\n",
      "      weighted avg     79.144  79.767    79.392    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.985      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 340/415 [04:10<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 341/415 [04:17<03:06,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4719\n",
      "F1-macro: 0.6995\n",
      "F1-pn: 0.6149\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.403  85.390    86.870    616.0\n",
      "                 1     57.273  56.757    57.014    111.0\n",
      "                 2     61.290  71.429    65.972    133.0\n",
      "          accuracy     79.535     NaN       NaN      NaN\n",
      "         macro avg     68.989  71.192    69.952    860.0\n",
      "      weighted avg     80.192  79.535    79.785    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.493      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches: 100%|██████████| 415/415 [04:56<00:00,  1.40it/s]\n",
      "INFO:root:Epoch 5, Loss: 0.4391646843717759, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3435\n",
      "F1-macro: 0.8288\n",
      "F1-pn: 0.7810\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     93.265  91.663    92.457   4774.0\n",
      "                 1     72.062  75.935    73.948    856.0\n",
      "                 2     80.825  83.714    82.244   1007.0\n",
      "          accuracy     88.429     NaN       NaN      NaN\n",
      "         macro avg     82.051  83.771    82.883   6637.0\n",
      "      weighted avg     88.643  88.429    88.520   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    78.096      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4732\n",
      "F1-macro: 0.7100\n",
      "F1-pn: 0.6298\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.116  85.065    87.043    616.0\n",
      "                 1     56.250  64.865    60.251    111.0\n",
      "                 2     63.194  68.421    65.704    133.0\n",
      "          accuracy     79.884     NaN       NaN      NaN\n",
      "         macro avg     69.520  72.784    70.999    860.0\n",
      "      weighted avg     80.865  79.884    80.285    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.978      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6699\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4732\n",
      "F1-macro: 0.7100\n",
      "F1-pn: 0.6298\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.2662\n",
      "F1-macro: 0.8364\n",
      "F1-pn: 0.7838\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.939  97.621    94.161   1429.0\n",
      "                 1     83.929  56.175    67.303    251.0\n",
      "                 2     92.933  86.230    89.456    305.0\n",
      "          accuracy     90.630     NaN       NaN      NaN\n",
      "         macro avg     89.267  80.009    83.640   1985.0\n",
      "      weighted avg     90.359  90.630    90.042   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    78.379      NaN\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  20%|██        | 85/415 [00:44<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4859\n",
      "F1-macro: 0.7179\n",
      "F1-pn: 0.6401\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.295  84.578    87.343    616.0\n",
      "                 1     55.396  69.369    61.600    111.0\n",
      "                 2     63.889  69.173    66.426    133.0\n",
      "          accuracy     80.233     NaN       NaN      NaN\n",
      "         macro avg     69.860  74.373    71.790    860.0\n",
      "      weighted avg     81.707  80.233    80.785    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.013      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  21%|██        | 86/415 [00:55<19:26,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6790\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4859\n",
      "F1-macro: 0.7179\n",
      "F1-pn: 0.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 170/415 [01:39<02:09,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4735\n",
      "F1-macro: 0.7289\n",
      "F1-pn: 0.6533\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.273  85.877    88.020    616.0\n",
      "                 1     60.504  64.865    62.609    111.0\n",
      "                 2     63.226  73.684    68.056    133.0\n",
      "          accuracy     81.279     NaN       NaN      NaN\n",
      "         macro avg     71.334  74.809    72.895    860.0\n",
      "      weighted avg     82.248  81.279    81.653    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.332      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 171/415 [01:50<14:25,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6911\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4735\n",
      "F1-macro: 0.7289\n",
      "F1-pn: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  50%|█████     | 209/415 [02:10<01:49,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  61%|██████▏   | 255/415 [03:22<01:25,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  62%|██████▏   | 256/415 [03:29<06:42,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4726\n",
      "F1-macro: 0.7168\n",
      "F1-pn: 0.6337\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.091  87.500    88.288    616.0\n",
      "                 1     61.682  59.459    60.550    111.0\n",
      "                 2     62.838  69.925    66.192    133.0\n",
      "          accuracy     81.163     NaN       NaN      NaN\n",
      "         macro avg     71.204  72.295    71.677    860.0\n",
      "      weighted avg     81.493  81.163    81.291    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.371      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 340/415 [04:14<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 341/415 [04:21<03:07,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4676\n",
      "F1-macro: 0.7234\n",
      "F1-pn: 0.6449\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.273  85.877    88.020    616.0\n",
      "                 1     59.829  63.063    61.404    111.0\n",
      "                 2     62.420  73.684    67.586    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     70.841  74.208    72.337    860.0\n",
      "      weighted avg     82.036  81.047    81.424    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.495      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches: 100%|██████████| 415/415 [05:00<00:00,  1.38it/s]\n",
      "INFO:root:Epoch 6, Loss: 0.3508994158132967, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.2578\n",
      "F1-macro: 0.8792\n",
      "F1-pn: 0.8449\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.520  95.015    94.767   4774.0\n",
      "                 1     84.489  78.271    81.261    856.0\n",
      "                 2     86.124  89.374    87.719   1007.0\n",
      "          accuracy     91.999     NaN       NaN      NaN\n",
      "         macro avg     88.378  87.553    87.916   6637.0\n",
      "      weighted avg     91.952  91.999    91.955   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    84.490      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4532\n",
      "F1-macro: 0.7045\n",
      "F1-pn: 0.6180\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.561  87.987    87.773    616.0\n",
      "                 1     62.245  54.955    58.373    111.0\n",
      "                 2     62.937  67.669    65.217    133.0\n",
      "          accuracy     80.581     NaN       NaN      NaN\n",
      "         macro avg     70.914  70.204    70.455    860.0\n",
      "      weighted avg     80.485  80.581    80.490    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.795      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1772\n",
      "F1-macro: 0.9145\n",
      "F1-pn: 0.8875\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.776  99.020    96.851   1429.0\n",
      "                 1     93.878  73.307    82.327    251.0\n",
      "                 2     96.622  93.770    95.175    305.0\n",
      "          accuracy     94.962     NaN       NaN      NaN\n",
      "         macro avg     95.092  88.699    91.451   1985.0\n",
      "      weighted avg     94.946  94.962    94.757   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    88.751      NaN\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  20%|██        | 85/415 [00:45<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4748\n",
      "F1-macro: 0.7343\n",
      "F1-pn: 0.6567\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.752  88.149    88.943    616.0\n",
      "                 1     63.248  66.667    64.912    111.0\n",
      "                 2     65.217  67.669    66.421    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.739  74.162    73.425    860.0\n",
      "      weighted avg     82.537  82.209    82.359    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.666      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  21%|██        | 86/415 [00:55<19:26,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6955\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4748\n",
      "F1-macro: 0.7343\n",
      "F1-pn: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 170/415 [01:40<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 171/415 [01:47<10:14,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4711\n",
      "F1-macro: 0.7067\n",
      "F1-pn: 0.6204\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.018  86.851    87.921    616.0\n",
      "                 1     61.224  54.054    57.416    111.0\n",
      "                 2     60.870  73.684    66.667    133.0\n",
      "          accuracy     80.581     NaN       NaN      NaN\n",
      "         macro avg     70.371  71.530    70.668    860.0\n",
      "      weighted avg     81.078  80.581    80.697    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.041      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  50%|█████     | 209/415 [02:07<01:49,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  61%|██████▏   | 255/415 [03:18<01:24,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  62%|██████▏   | 256/415 [03:25<06:41,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4751\n",
      "F1-macro: 0.7155\n",
      "F1-pn: 0.6340\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.742  87.013    87.869    616.0\n",
      "                 1     58.824  63.063    60.870    111.0\n",
      "                 2     64.964  66.917    65.926    133.0\n",
      "          accuracy     80.814     NaN       NaN      NaN\n",
      "         macro avg     70.843  72.331    71.555    860.0\n",
      "      weighted avg     81.203  80.814    80.991    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    63.398      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 340/415 [04:10<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4728\n",
      "F1-macro: 0.7352\n",
      "F1-pn: 0.6631\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.690  85.390    87.960    616.0\n",
      "                 1     59.398  71.171    64.754    111.0\n",
      "                 2     64.626  71.429    67.857    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.571  75.996    73.524    860.0\n",
      "      weighted avg     82.620  81.395    81.856    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.306      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 341/415 [04:20<04:22,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6991\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4728\n",
      "F1-macro: 0.7352\n",
      "F1-pn: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches: 100%|██████████| 415/415 [05:00<00:00,  1.38it/s]\n",
      "INFO:root:Epoch 7, Loss: 0.2633613132434078, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1720\n",
      "F1-macro: 0.9325\n",
      "F1-pn: 0.9139\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.010  95.936    96.962   4774.0\n",
      "                 1     86.300  93.458    89.736    856.0\n",
      "                 2     91.707  94.439    93.053   1007.0\n",
      "          accuracy     95.389     NaN       NaN      NaN\n",
      "         macro avg     92.006  94.611    93.250   6637.0\n",
      "      weighted avg     95.543  95.389    95.437   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    91.395      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4711\n",
      "F1-macro: 0.7413\n",
      "F1-pn: 0.6679\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.267  86.526    88.833    616.0\n",
      "                 1     60.465  70.270    65.000    111.0\n",
      "                 2     65.306  72.180    68.571    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.346  76.326    74.135    860.0\n",
      "      weighted avg     83.277  82.209    82.624    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.786      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7046\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.4711\n",
      "F1-macro: 0.7413\n",
      "F1-pn: 0.6679\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1006\n",
      "F1-macro: 0.9642\n",
      "F1-pn: 0.9528\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.000  99.440    98.715   1429.0\n",
      "                 1     96.581  90.040    93.196    251.0\n",
      "                 2     98.007  96.721    97.360    305.0\n",
      "          accuracy     97.834     NaN       NaN      NaN\n",
      "         macro avg     97.529  95.400    96.423   1985.0\n",
      "      weighted avg     97.822  97.834    97.809   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    95.278      NaN\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  20%|██        | 85/415 [00:45<02:55,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  21%|██        | 86/415 [00:52<13:51,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4976\n",
      "F1-macro: 0.7343\n",
      "F1-pn: 0.6600\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.769  85.065    88.290    616.0\n",
      "                 1     57.241  74.775    64.844    111.0\n",
      "                 2     64.583  69.925    67.148    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.198  76.588    73.427    860.0\n",
      "      weighted avg     83.108  81.395    81.994    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.996      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 170/415 [01:36<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 171/415 [01:43<10:14,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4836\n",
      "F1-macro: 0.7354\n",
      "F1-pn: 0.6574\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.655  88.636    89.143    616.0\n",
      "                 1     64.286  64.865    64.574    111.0\n",
      "                 2     65.468  68.421    66.912    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.136  73.974    73.543    860.0\n",
      "      weighted avg     82.640  82.442    82.534    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.743      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  50%|█████     | 209/415 [02:04<01:49,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  61%|██████▏   | 255/415 [03:15<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5013\n",
      "F1-macro: 0.7444\n",
      "F1-pn: 0.6681\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.627  89.773    89.700    616.0\n",
      "                 1     66.055  64.865    65.455    111.0\n",
      "                 2     67.910  68.421    68.165    133.0\n",
      "          accuracy     83.256     NaN       NaN      NaN\n",
      "         macro avg     74.531  74.353    74.440    860.0\n",
      "      weighted avg     83.226  83.256    83.240    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.810      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  62%|██████▏   | 256/415 [03:26<09:23,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7062\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5013\n",
      "F1-macro: 0.7444\n",
      "F1-pn: 0.6681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 340/415 [04:10<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 341/415 [04:17<03:06,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5114\n",
      "F1-macro: 0.7366\n",
      "F1-pn: 0.6616\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.237  86.201    88.648    616.0\n",
      "                 1     59.542  70.270    64.463    111.0\n",
      "                 2     64.626  71.429    67.857    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     71.802  75.967    73.656    860.0\n",
      "      weighted avg     83.031  81.860    82.311    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.160      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches: 100%|██████████| 415/415 [04:57<00:00,  1.40it/s]\n",
      "INFO:root:Epoch 8, Loss: 0.1732703997315951, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1006\n",
      "F1-macro: 0.9677\n",
      "F1-pn: 0.9586\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.007  98.178    98.591   4774.0\n",
      "                 1     94.381  96.145    95.255    856.0\n",
      "                 2     95.344  97.617    96.467   1007.0\n",
      "          accuracy     97.830     NaN       NaN      NaN\n",
      "         macro avg     96.244  97.313    96.771   6637.0\n",
      "      weighted avg     97.855  97.830    97.838   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    95.861      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5018\n",
      "F1-macro: 0.7491\n",
      "F1-pn: 0.6751\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.849  88.636    89.729    616.0\n",
      "                 1     65.789  67.568    66.667    111.0\n",
      "                 2     65.517  71.429    68.345    133.0\n",
      "          accuracy     83.256     NaN       NaN      NaN\n",
      "         macro avg     74.052  75.878    74.914    860.0\n",
      "      weighted avg     83.697  83.256    83.445    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.506      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7121\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_multi_dropout_V3_Token_Target/best_model.pth\n",
      "Loss: 0.5018\n",
      "F1-macro: 0.7491\n",
      "F1-pn: 0.6751\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0501\n",
      "F1-macro: 0.9902\n",
      "F1-pn: 0.9871\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.581  99.720    99.650   1429.0\n",
      "                 1     98.795  98.008    98.400    251.0\n",
      "                 2     99.016  99.016    99.016    305.0\n",
      "          accuracy     99.395     NaN       NaN      NaN\n",
      "         macro avg     99.131  98.915    99.022   1985.0\n",
      "      weighted avg     99.395  99.395    99.395   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    98.708      NaN\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  20%|██        | 85/415 [00:45<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  21%|██        | 86/415 [00:52<13:50,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5455\n",
      "F1-macro: 0.7368\n",
      "F1-pn: 0.6613\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.404  87.175    88.760    616.0\n",
      "                 1     60.317  68.468    64.135    111.0\n",
      "                 2     66.429  69.925    68.132    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.383  75.190    73.676    860.0\n",
      "      weighted avg     82.813  82.093    82.392    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.133      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 170/415 [01:36<02:10,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 171/415 [01:43<10:17,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5360\n",
      "F1-macro: 0.7436\n",
      "F1-pn: 0.6685\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.356  87.500    89.386    616.0\n",
      "                 1     61.905  70.270    65.823    111.0\n",
      "                 2     65.278  70.677    67.870    133.0\n",
      "          accuracy     82.674     NaN       NaN      NaN\n",
      "         macro avg     72.846  76.149    74.360    860.0\n",
      "      weighted avg     83.522  82.674    83.018    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.846      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  50%|█████     | 209/415 [02:04<01:48,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  61%|██████▏   | 255/415 [03:15<01:24,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  62%|██████▏   | 256/415 [03:22<06:40,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5430\n",
      "F1-macro: 0.7393\n",
      "F1-pn: 0.6585\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.567  90.584    90.073    616.0\n",
      "                 1     67.677  60.360    63.810    111.0\n",
      "                 2     66.667  69.173    67.897    133.0\n",
      "          accuracy     83.372     NaN       NaN      NaN\n",
      "         macro avg     74.637  73.373    73.926    860.0\n",
      "      weighted avg     83.200  83.372    83.253    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.853      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 340/415 [04:07<00:39,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 341/415 [04:14<03:06,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5453\n",
      "F1-macro: 0.7317\n",
      "F1-pn: 0.6538\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.541  87.013    88.742    616.0\n",
      "                 1     62.832  63.964    63.393    111.0\n",
      "                 2     62.581  72.932    67.361    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     71.984  74.636    73.165    860.0\n",
      "      weighted avg     82.640  81.860    82.163    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.377      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches: 100%|██████████| 415/415 [04:53<00:00,  1.41it/s]\n",
      "INFO:root:Epoch 9, Loss: 0.0964221142872001, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0503\n",
      "F1-macro: 0.9891\n",
      "F1-pn: 0.9858\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.790  99.351    99.570   4774.0\n",
      "                 1     97.924  99.182    98.549    856.0\n",
      "                 2     98.132  99.106    98.617   1007.0\n",
      "          accuracy     99.292     NaN       NaN      NaN\n",
      "         macro avg     98.615  99.213    98.912   6637.0\n",
      "      weighted avg     99.297  99.292    99.293   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    98.583      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5352\n",
      "F1-macro: 0.7405\n",
      "F1-pn: 0.6615\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.013  90.747    89.871    616.0\n",
      "                 1     66.667  61.261    63.850    111.0\n",
      "                 2     69.231  67.669    68.441    133.0\n",
      "          accuracy     83.372     NaN       NaN      NaN\n",
      "         macro avg     74.970  73.226    74.054    860.0\n",
      "      weighted avg     83.069  83.372    83.199    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.145      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0223\n",
      "F1-macro: 0.9978\n",
      "F1-pn: 0.9972\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.930  99.860    99.895   1429.0\n",
      "                 1     99.602  99.602    99.602    251.0\n",
      "                 2     99.673 100.000    99.836    305.0\n",
      "          accuracy     99.849     NaN       NaN      NaN\n",
      "         macro avg     99.735  99.821    99.778   1985.0\n",
      "      weighted avg     99.849  99.849    99.849   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.719      NaN\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  20%|██        | 85/415 [00:45<02:54,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  21%|██        | 86/415 [00:52<13:48,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5886\n",
      "F1-macro: 0.7359\n",
      "F1-pn: 0.6579\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.620  87.825    89.200    616.0\n",
      "                 1     63.248  66.667    64.912    111.0\n",
      "                 2     63.699  69.925    66.667    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     72.522  74.805    73.593    860.0\n",
      "      weighted avg     82.923  82.326    82.581    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.789      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 170/415 [01:36<02:09,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 171/415 [01:43<10:15,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5943\n",
      "F1-macro: 0.7303\n",
      "F1-pn: 0.6502\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.769  88.312    89.034    616.0\n",
      "                 1     63.478  65.766    64.602    111.0\n",
      "                 2     64.029  66.917    65.441    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.425  73.665    73.026    860.0\n",
      "      weighted avg     82.395  82.093    82.232    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.021      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  50%|█████     | 209/415 [02:03<01:48,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  61%|██████▏   | 255/415 [03:15<01:24,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  62%|██████▏   | 256/415 [03:22<06:40,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6200\n",
      "F1-macro: 0.7237\n",
      "F1-pn: 0.6432\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.799  87.175    88.468    616.0\n",
      "                 1     62.832  63.964    63.393    111.0\n",
      "                 2     61.745  69.173    65.248    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.459  73.437    72.370    860.0\n",
      "      weighted avg     81.980  81.395    81.641    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.321      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 340/415 [04:07<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 341/415 [04:14<03:06,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6194\n",
      "F1-macro: 0.7301\n",
      "F1-pn: 0.6481\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.050  89.773    89.410    616.0\n",
      "                 1     64.762  61.261    62.963    111.0\n",
      "                 2     66.418  66.917    66.667    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.410  72.650    73.013    860.0\n",
      "      weighted avg     82.415  82.558    82.479    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.815      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches: 100%|██████████| 415/415 [04:53<00:00,  1.41it/s]\n",
      "INFO:root:Epoch 10, Loss: 0.04621558942809611, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0200\n",
      "F1-macro: 0.9970\n",
      "F1-pn: 0.9962\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.958  99.791    99.874   4774.0\n",
      "                 1     99.188  99.883    99.534    856.0\n",
      "                 2     99.604  99.801    99.702   1007.0\n",
      "          accuracy     99.804     NaN       NaN      NaN\n",
      "         macro avg     99.583  99.825    99.704   6637.0\n",
      "      weighted avg     99.805  99.804    99.804   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.618      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6315\n",
      "F1-macro: 0.7294\n",
      "F1-pn: 0.6495\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.884  87.987    88.925    616.0\n",
      "                 1     62.609  64.865    63.717    111.0\n",
      "                 2     64.085  68.421    66.182    133.0\n",
      "          accuracy     81.977     NaN       NaN      NaN\n",
      "         macro avg     72.192  73.758    72.941    860.0\n",
      "      weighted avg     82.374  81.977    82.154    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.949      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0099\n",
      "F1-macro: 1.0000\n",
      "F1-pn: 1.0000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0      100.0   100.0     100.0   1429.0\n",
      "                 1      100.0   100.0     100.0    251.0\n",
      "                 2      100.0   100.0     100.0    305.0\n",
      "          accuracy      100.0     NaN       NaN      NaN\n",
      "         macro avg      100.0   100.0     100.0   1985.0\n",
      "      weighted avg      100.0   100.0     100.0   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN     100.0      NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_m = 1e-6\n",
    "# lr = 1e-6 началось обучение, уменьшение TrainError\n",
    "# добавить волидацию по шагам в течение эпохи обучения, а не каджые N епох\n",
    "# Добавить сохранение ошибки в файлы для построения графиков\n",
    "# проверить методы передачи сущьности (параетром, +тип, или в тексте выделяя тегами).\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"./../ruRoberta-large/\")\n",
    "    #parser.add_argument(\"--model_name\", type=str, default=\"sberbank-ai/ruRoberta-large\", help=\"Имя модели\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=512) #128\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "    parser.add_argument(\"--lr\", type=float, default=lr_m)\n",
    "    parser.add_argument(\"--init_checkpoint\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_data\", type=str, required=False, default=\"./../data/train_data.csv\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, required=False, default=\"./../data/validation.csv\")\n",
    "    parser.add_argument(\"--eval_data\", type=str, required=False, default=\"./../data/test.csv\")\n",
    "    parser.add_argument(\"--result\", type=str, default=f\"./result_lr_{lr_m}_ENS_Teg_multi_dropout_V3_Token_Target/\")\n",
    "    # Игнорируем аргументы Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    os.makedirs(args.result, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    print(args)  # Проверяем аргументы\n",
    "\n",
    "    base_lr = args.lr\n",
    "    min_lr = base_lr * (1/4)\n",
    "    step_size_up = 400 #400\n",
    "    best_avg_f1 = 0.0\n",
    "    \n",
    "    best_model_path = os.path.join(args.result, \"best_model.pth\")\n",
    "\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.model_name)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained(args.model_name, num_labels=3)\n",
    "    model = RobertaWithMultiSampleDropoutTarget(model_name='./../ruRoberta-large', num_labels=3, use_multi_sample_dropout=True )\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataset = load_data(args.train_data, tokenizer, args.max_seq_len)\n",
    "    validation_data = load_data(args.validation_data, tokenizer, args.max_seq_len)\n",
    "    eval_dataset = load_data(args.eval_data, tokenizer, args.max_seq_len)\n",
    "\n",
    "    if train_dataset is None or eval_dataset is None or validation_data is None:\n",
    "        sys.exit(f\"Ошибка загрузки данных: убедитесь, что файлы {args.train_data}, {args.validation_data} и {args.eval_data} существуют и содержат нужные колонки.\")\n",
    "\n",
    "    #сохранение текста и токенов, с дабовлением собственных\n",
    "    save_contrel_date(tokenizer,train_dataset)\n",
    "    model.roberta.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    embedding_layer = model.roberta.embeddings.word_embeddings\n",
    "    print(embedding_layer.weight[tokenizer.convert_tokens_to_ids(\"<en>\")])\n",
    "    \n",
    "    # Получаем метки классов из тренировочного датасета\n",
    "    train_labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "    # Вычисляем веса классов\n",
    "    class_weights = compute_ens_weights(train_labels, beta=0.999)\n",
    "\n",
    "    # Вывод весов классов\n",
    "    print(f\"class_weights = {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=args.batch_size)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    #scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr = base_lr, step_size_up = step_size_up, mode=\"triangular2\",cycle_momentum=False )\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        batches_per_validation = (len(train_loader) // 2)+2\n",
    "        batches_per_test = (len(train_loader) // 5)+2\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"Epoch: {epoch}/{args.epochs}\")\n",
    "            total_loss = 0\n",
    "            for i,batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Batches\")):\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                if(i % batches_per_validation == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Validation\", vall_train = True)\n",
    "                if(i % batches_per_test == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Test\", flag_print = True)\n",
    "                \n",
    "            logging.info(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Step: {len(train_loader)}\")\n",
    "            # Валидация с обратным распространением ошибки каждые 2 эпохи\n",
    "            evaluate(epoch , backprop=\"Train\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Test\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Validation\", flag_print = True, vall_train = True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def evaluate(epoch = None, backprop = \"None\", flag_print = False, vall_train = False):\n",
    "        global best_avg_f1\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        total_loss = 0\n",
    "        print(f\"evaluate, backprop: {backprop}\")\n",
    "        loader = validation_loader\n",
    "        if backprop == \"Validation\":\n",
    "            loader = validation_loader\n",
    "        elif backprop == \"Test\":\n",
    "            loader = eval_loader\n",
    "        elif backprop == \"Train\":\n",
    "            loader = train_loader\n",
    "        \n",
    "        else: loader = eval_loader\n",
    "        with torch.no_grad() if not backprop == \"Validation\" else torch.enable_grad():  # Включаем градиенты для обучения на валидации\n",
    "            for batch in loader:\n",
    "            #for batch in loader:\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if backprop == \"Validation\" and vall_train:\n",
    "                    #уменьшая тк обучающие данные удвоились\n",
    "                    loss = loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #scheduler.step()\n",
    "                    loss = loss\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        f1_pn = f1_score(all_labels, all_preds, labels=[1, 2], average='macro')\n",
    "        avg_f1 = (f1 + f1_pn) / 2\n",
    "\n",
    "        if(flag_print):\n",
    "            print()\n",
    "            print(\"--\"*20)\n",
    "            print(f\"Result evaluate in {backprop}\")\n",
    "            #logging.info(f\"{backprop} Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "            #print(classification_report(all_labels, all_preds))\n",
    "            castom_classification_report(all_labels, all_preds)\n",
    "\n",
    "        # 💾 Сохраняем модель только при улучшении средней метрики\n",
    "        if (avg_f1 > best_avg_f1) and backprop == \"Test\":\n",
    "            best_avg_f1 = avg_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            \n",
    "            print(f\"[Checkpoint] 🎯 Новый лучший средний F1: {best_avg_f1:.4f}\")\n",
    "            print(f\"[Checkpoint] 💾 Модель сохранена: {best_model_path}\")\n",
    "            # 🔸 Сохраняем значение лучшего F1 в файл\n",
    "            best_score_path = os.path.join(args.result, \"best_score.txt\")\n",
    "            save_metrics_best(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "            save_confusion_matrix(epoch, all_labels, all_preds, args.result, backprop)\n",
    "            with open(best_score_path, \"w\") as f:\n",
    "                f.write(f\"Epoch: {epoch}\\n\")\n",
    "                f.write(f\"Loss: {avg_loss:.4f}\\n\")\n",
    "                f.write(f\"F1-pn0: {f1:.4f}\\n\")\n",
    "                f.write(f\"F1-pn: {f1_pn:.4f}\\n\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "\n",
    "\n",
    "        if epoch is not None:\n",
    "            save_metrics(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "        \n",
    "    if args.init_checkpoint:\n",
    "        model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n",
    "\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4520d-65bf-4708-99bc-4807f25ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "805557fd-243e-47ff-b33c-4ce8c82c159f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './result_lr_1e-06_test/metrics_class_weights.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Пример использования\u001b[39;00m\n\u001b[32m     54\u001b[39m metrics_file = \u001b[33m\"\u001b[39m\u001b[33m./result_lr_1e-06_test/metrics_class_weights.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mload_and_display_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_and_display_metrics\u001b[39m\u001b[34m(metrics_file)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_and_display_metrics\u001b[39m(metrics_file):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Загружаем CSV-файл\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     df = df[df[\u001b[33m\"\u001b[39m\u001b[33mbackprop\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mTest\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Определяем количество эпох\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './result_lr_1e-06_test/metrics_class_weights.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_display_metrics(metrics_file):\n",
    "    # Загружаем CSV-файл\n",
    "    df = pd.read_csv(metrics_file)\n",
    "    df = df[df[\"backprop\"] == \"Test\"]\n",
    "    # Определяем количество эпох\n",
    "    epochs = df[\"epoch\"].unique()\n",
    "    print(epochs)\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # Фильтруем данные по эпохе\n",
    "        epoch_df = df[df[\"epoch\"] == epoch]\n",
    "        \n",
    "        for idx, row in epoch_df.iterrows():\n",
    "            loss = row[\"loss\"]\n",
    "            backprop_value = row[\"backprop\"]\n",
    "            print(f\"\\nEpoch {epoch} (Backprop: {backprop_value}) (Loss: {loss})\\n\" + \"-\"*30)\n",
    "            # Формируем таблицу в стиле classification_report\n",
    "            table_data = {}\n",
    "            class_labels = sorted(\n",
    "                set(col.split(\"_\")[1] for col in df.columns \n",
    "                    if col.startswith(\"class_\") and \"precision\" in col)\n",
    "            )\n",
    "            \n",
    "            # Фильтруем только числовые метки классов\n",
    "            class_labels = [label for label in class_labels if label.isdigit()]\n",
    "            \n",
    "            for label in class_labels:\n",
    "                table_data[int(label)] = {\n",
    "                    \"precision\": row[f\"class_{label}_precision\"],\n",
    "                    \"recall\": row[f\"class_{label}_recall\"],\n",
    "                    \"f1-score\": row[f\"class_{label}_f1\"],\n",
    "                }\n",
    "            \n",
    "            # Добавляем средние значения\n",
    "            table_data[\"accuracy\"] = {\"precision\": \"\", \"recall\": \"\", \"f1-score\": row[\"accuracy\"] }\n",
    "            table_data[\"macro avg\"] = {\n",
    "                \"precision\": row[\"macro_precision\"],\n",
    "                \"recall\": row[\"macro_recall\"],\n",
    "                \"f1-score\": row[\"macro_f1\"],\n",
    "            }\n",
    "            table_data[\"weighted avg\"] = {\n",
    "                \"precision\": row[\"weighted_precision\"],\n",
    "                \"recall\": row[\"weighted_recall\"],\n",
    "                \"f1-score\": row[\"weighted_f1\"],\n",
    "            }\n",
    "            \n",
    "            # Выводим таблицу\n",
    "            df_table = pd.DataFrame.from_dict(table_data, orient=\"index\")\n",
    "            print(df_table.to_string())\n",
    "\n",
    "# Пример использования\n",
    "metrics_file = \"./result_lr_1e-06_test/metrics_class_weights.csv\"\n",
    "load_and_display_metrics(metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9444b-5431-4eb6-8ff8-9074d559598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка CSV-файла\n",
    "df = pd.read_csv(\"metrics_class_weights.csv\")  # укажи путь к файлу, если он отличается\n",
    "\n",
    "# Построение графика loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for stage in ['Train', 'Validation', 'Test']:\n",
    "    stage_data = df[df['backprop'] == stage]\n",
    "    plt.plot(stage_data['epoch'], stage_data['loss'], label=stage)\n",
    "\n",
    "plt.title('Значение Loss по эпохам')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ryumin_env",
   "language": "python",
   "name": "ryumin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
