{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd128c19-762d-49e7-959a-845e0599a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import CyclicLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1f20af-edf7-4cf5-84b3-bc8e437c24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class RobertaWithMultiSampleDropout(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.3, num_dropouts=5, use_multi_sample_dropout=True):\n",
    "        super(RobertaWithMultiSampleDropout, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(model_name)\n",
    "        self.use_multi_sample_dropout = use_multi_sample_dropout\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(dropout_rate) for _ in range(num_dropouts)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[0]  # последний скрытый слой\n",
    "\n",
    "        if self.use_multi_sample_dropout:\n",
    "            logits_list = []\n",
    "            for dropout in self.dropouts:\n",
    "                dropped = dropout(sequence_output[:, 0, :])  # [CLS]-токен\n",
    "                logits_list.append(self.classifier(dropped))\n",
    "            avg_logits = torch.mean(torch.stack(logits_list), dim=0)\n",
    "        else:\n",
    "            dropped = self.dropout(sequence_output[:, 0, :])  # [CLS]-токен\n",
    "            avg_logits = self.classifier(dropped)\n",
    "\n",
    "        return SequenceClassifierOutput(logits=avg_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecb1746-8eac-4865-8f99-828b9055d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_best(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    metrics_file = os.path.join(result_path, \"metrics_best.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "    # Создаем словарь с метриками\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop,\n",
    "        \"loss\": loss\n",
    "    }\n",
    "\n",
    "    # Добавляем метрики по каждому классу\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "\n",
    "    # Создаем DataFrame и сохраняем его в CSV (перезапись файла)\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2886be9d-a3f4-4164-8002-b4cc31a22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ens_weights(train_labels, beta: float = 0.999):\n",
    "    train_labels = np.array(train_labels)\n",
    "    classes, counts = np.unique(train_labels, return_counts=True)\n",
    "    effective_num = (1 - np.power(beta, counts)) / (1 - beta)\n",
    "    weights = 1.0 / effective_num\n",
    "    weights = weights / np.sum(weights) * len(classes)  # нормализация как в оригинальной статье\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d52154-884f-4289-8b00-b19358f419e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tags_from_files(*file_paths):\n",
    "    all_tags = set()\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep='\\t')\n",
    "            if \"entity_tag\" in df.columns:\n",
    "                tags = df[\"entity_tag\"].dropna().unique().tolist()\n",
    "                all_tags.update(tags)\n",
    "        except Exception as e:\n",
    "            print(f\"[Ошибка] Не удалось загрузить {path}: {e}\")\n",
    "    return sorted(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be23ac59-6617-40d9-b01b-be5ff22e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, tokenizer, max_seq_len):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')  # Загружаем CSV (TSV)\n",
    "\n",
    "        # Проверка нужных колонок\n",
    "        required_columns = {\n",
    "            \"sentence\", \"entity\", \"label\", \"entity_tag\",\n",
    "            \"entity_pos_start_rel\", \"entity_pos_end_rel\"\n",
    "        }\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            raise ValueError(f\"Ожидаемые колонки: {required_columns}, но в файле: {df.columns}\")\n",
    "\n",
    "        # Заменяем -1 на 2 (если есть)\n",
    "        df[\"label\"] = df[\"label\"].replace(-1, 2)\n",
    "\n",
    "        # Размечаем предложения с [ENTITY] токенами\n",
    "        def mark_entity_inline(row):\n",
    "            sent = row[\"sentence\"]\n",
    "            start = row[\"entity_pos_start_rel\"]\n",
    "            end = row[\"entity_pos_end_rel\"]\n",
    "            tag = row[\"entity_tag\"]\n",
    "            tag_token = f\"[ENTITY:{tag}]\"\n",
    "            tag_token_close = f\"[/ENTITY:{tag}]\"\n",
    "            return (\n",
    "                sent[:start] +\n",
    "                f\"{tag_token} \" + sent[start:end] + f\" {tag_token_close}\" +\n",
    "                sent[end:]\n",
    "            )\n",
    "\n",
    "        df[\"input_text\"] = df.apply(mark_entity_inline, axis=1)\n",
    "        texts = df[\"input_text\"].tolist()\n",
    "        labels = torch.tensor(df[\"label\"].astype(int).tolist(), dtype=torch.long)\n",
    "\n",
    "        # Токенизируем\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True,\n",
    "                              max_length=max_seq_len, return_tensors='pt')\n",
    "        dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], labels)\n",
    "        return dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Файл {file_path} не найден!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfbbfe22-f0f3-4f70-b366-53259c79ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_metrics(epoch, all_labels, all_preds, result_path, backprop, loss):\n",
    "    metrics_file = os.path.join(result_path, \"metrics_class_weights.csv\")\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    \n",
    "    # Создаем DataFrame для метрик\n",
    "    metrics_data = {\n",
    "        \"epoch\": epoch,\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"macro_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"backprop\": backprop , # (Добавлено)\n",
    "        \"loss\": loss\n",
    "    }\n",
    "    \n",
    "    # Добавляем метрики для каждого класса\n",
    "    for label in sorted(report.keys()):\n",
    "        if isinstance(report[label], dict):  # Пропускаем 'accuracy', так как это float\n",
    "            metrics_data[f\"class_{label}_precision\"] = report[label][\"precision\"]\n",
    "            metrics_data[f\"class_{label}_recall\"] = report[label][\"recall\"]\n",
    "            metrics_data[f\"class_{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    # Создаем DataFrame и сохраняем в CSV\n",
    "    metrics_df = pd.DataFrame([metrics_data])\n",
    "    metrics_df.to_csv(metrics_file, mode='a', header=not os.path.exists(metrics_file), index=False)\n",
    "\n",
    "def save_confusion_matrix(epoch, y_true, y_pred, result_path,backprop):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns=[\"Pred_0\", \"Pred_1\", \"Pred_2\"], index=[\"True_0\", \"True_1\", \"True_2\"])\n",
    "    cm_file = os.path.join(result_path, f\"confusion_matrix_class_weights_epoch_{epoch}_backprop_{backprop}.csv\")\n",
    "    cm_df.to_csv(cm_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd447891-39c3-42bc-981d-96b2800a41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def castom_classification_report(all_labels, all_preds):\n",
    "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    data = []\n",
    "    for label, metrics in report.items():\n",
    "        if isinstance(metrics, dict):  # Для всех метрик, кроме accuracy\n",
    "            row = {'label': label}\n",
    "            for metric, value in metrics.items():\n",
    "                row[metric] = round(value * 100, 3) if metric != 'support' else value\n",
    "            data.append(row)\n",
    "        else:  # Для accuracy\n",
    "            data.append({'label': 'accuracy', 'precision': round(metrics * 100, 3), 'recall': None, 'f1-score': None, 'support': None})\n",
    "\n",
    "    # Добавляем macro F1 для классов 1 и 2\n",
    "    if '1' in report and '2' in report:\n",
    "        f1_1 = report['1']['f1-score']\n",
    "        f1_2 = report['2']['f1-score']\n",
    "        f1_macro_1_2 = (f1_1 + f1_2) / 2\n",
    "        data.append({\n",
    "            'label': 'avg f1 (class 1&2)',\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': round(f1_macro_1_2 * 100, 3),\n",
    "            'support': None\n",
    "        })\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index = [''] * len(df)\n",
    "\n",
    "    # Выводим таблицу\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9447e1ed-4fc6-43aa-a54c-d9023898afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_contrel_date():\n",
    "    pass\n",
    "\n",
    "def add_token():\n",
    "    pass\n",
    "\n",
    "\n",
    "def use_CyclicLR():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af33277-341d-43ba-8b31-c9bba05cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_name='./ruRoberta-large/', max_seq_len=512, batch_size=16, epochs=15, lr=1e-06, init_checkpoint=None, train_data='./data/train_data.csv', validation_data='./data/validation.csv', eval_data='./data/test.csv', result='./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./ruRoberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: <s>Джеймс «Бадди» Макгирт (James (Buddy) McGirt, тренер Дадашева упрашивал дагестанского [ENTITY:PROFESSION] спортсмена [/ENTITY:PROFESSION] остановить бой, но тот хотел продолжать.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Label: 0\n",
      "--------------------------------------------------\n",
      "Text: <s>«За всю нашу долгую карьеру нам довелось играть во многих интересных местах, но это шоу в Гаване станет для нас важнейшим событием, и мы надеемся, что и для наших кубинских друзей тоже», — это было отмечено в заявлении группы, опубликованном перед прибытием [ENTITY:PROFESSION] музыкантов [/ENTITY:PROFESSION] на Кубу.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "Label: 0\n",
      "--------------------------------------------------\n",
      "class_weights = tensor([0.7001, 1.2066, 1.0934])\n",
      "Epoch: 0/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  20%|██        | 85/415 [00:50<03:15,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7907\n",
      "F1-macro: 0.2782\n",
      "F1-pn: 0.0000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.628 100.000    83.469    616.0\n",
      "                 1      0.000   0.000     0.000    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.628     NaN       NaN      NaN\n",
      "         macro avg     23.876  33.333    27.823    860.0\n",
      "      weighted avg     51.306  71.628    59.787    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     0.000      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  21%|██        | 86/415 [00:59<17:31,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1391\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.7907\n",
      "F1-macro: 0.2782\n",
      "F1-pn: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  41%|████      | 170/415 [01:49<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7354\n",
      "F1-macro: 0.2901\n",
      "F1-pn: 0.0174\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.846  99.838    83.560    616.0\n",
      "                 1     50.000   1.802     3.478    111.0\n",
      "                 2      0.000   0.000     0.000    133.0\n",
      "          accuracy     71.744     NaN       NaN      NaN\n",
      "         macro avg     40.615  33.880    29.013    860.0\n",
      "      weighted avg     57.915  71.744    60.301    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     1.739      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  41%|████      | 171/415 [01:59<14:53,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1538\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.7354\n",
      "F1-macro: 0.2901\n",
      "F1-pn: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  50%|█████     | 209/415 [02:22<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  61%|██████▏   | 255/415 [03:42<01:33,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7537\n",
      "F1-macro: 0.3003\n",
      "F1-pn: 0.0331\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     71.864  99.513    83.458    616.0\n",
      "                 1     50.000   2.703     5.128    111.0\n",
      "                 2    100.000   0.752     1.493    133.0\n",
      "          accuracy     71.744     NaN       NaN      NaN\n",
      "         macro avg     73.955  34.323    30.026    860.0\n",
      "      weighted avg     73.393  71.744    60.672    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN     3.310      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  62%|██████▏   | 256/415 [03:53<09:42,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.1667\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.7537\n",
      "F1-macro: 0.3003\n",
      "F1-pn: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches:  82%|████████▏ | 340/415 [04:42<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.7015\n",
      "F1-macro: 0.3489\n",
      "F1-pn: 0.1043\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     73.012  98.377    83.817    616.0\n",
      "                 1      0.000   0.000     0.000    111.0\n",
      "                 2     56.667  12.782    20.859    133.0\n",
      "          accuracy     72.442     NaN       NaN      NaN\n",
      "         macro avg     43.226  37.053    34.892    860.0\n",
      "      weighted avg     61.061  72.442    63.263    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    10.429      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/student/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Epoch 1 - Batches:  82%|████████▏ | 341/415 [04:53<04:33,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.2266\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.7015\n",
      "F1-macro: 0.3489\n",
      "F1-pn: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Batches: 100%|██████████| 415/415 [05:37<00:00,  1.23it/s]\n",
      "INFO:root:Epoch 1, Loss: 0.8886691056102155, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.7634\n",
      "F1-macro: 0.4279\n",
      "F1-pn: 0.2190\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.315  96.376    84.554   4774.0\n",
      "                 1     69.767   3.505     6.674    856.0\n",
      "                 2     57.113  27.507    37.131   1007.0\n",
      "          accuracy     73.949     NaN       NaN      NaN\n",
      "         macro avg     67.399  42.463    42.786   6637.0\n",
      "      weighted avg     71.838  73.949    67.314   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    21.903      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6707\n",
      "F1-macro: 0.4341\n",
      "F1-pn: 0.2285\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.349  96.266    84.533    616.0\n",
      "                 1     80.000   3.604     6.897    111.0\n",
      "                 2     57.353  29.323    38.806    133.0\n",
      "          accuracy     73.953     NaN       NaN      NaN\n",
      "         macro avg     70.901  43.064    43.412    860.0\n",
      "      weighted avg     73.166  73.953    67.441    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    22.851      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3313\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.6707\n",
      "F1-macro: 0.4341\n",
      "F1-pn: 0.2285\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.6903\n",
      "F1-macro: 0.4099\n",
      "F1-pn: 0.1887\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.486  97.831    85.218   1429.0\n",
      "                 1      0.000   0.000     0.000    251.0\n",
      "                 2     74.757  25.246    37.745    305.0\n",
      "          accuracy     74.307     NaN       NaN      NaN\n",
      "         macro avg     50.081  41.026    40.988   1985.0\n",
      "      weighted avg     65.829  74.307    67.148   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    18.873      NaN\n",
      "Epoch: 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  20%|██        | 85/415 [00:50<03:14,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6535\n",
      "F1-macro: 0.4757\n",
      "F1-pn: 0.2923\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     75.911  94.643    84.249    616.0\n",
      "                 1     66.667  12.613    21.212    111.0\n",
      "                 2     53.521  28.571    37.255    133.0\n",
      "          accuracy     73.837     NaN       NaN      NaN\n",
      "         macro avg     65.366  45.276    47.572    860.0\n",
      "      weighted avg     71.256  73.837    68.845    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    29.234      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  21%|██        | 86/415 [01:00<19:54,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.3840\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.6535\n",
      "F1-macro: 0.4757\n",
      "F1-pn: 0.2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 170/415 [01:50<02:24,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6403\n",
      "F1-macro: 0.5837\n",
      "F1-pn: 0.4509\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.612  89.773    84.946    616.0\n",
      "                 1     59.259  28.829    38.788    111.0\n",
      "                 2     54.167  48.872    51.383    133.0\n",
      "          accuracy     75.581     NaN       NaN      NaN\n",
      "         macro avg     64.679  55.825    58.373    860.0\n",
      "      weighted avg     73.766  75.581    73.798    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    45.086      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  41%|████      | 171/415 [02:01<15:01,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5173\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.6403\n",
      "F1-macro: 0.5837\n",
      "F1-pn: 0.4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  50%|█████     | 209/415 [02:23<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  61%|██████▏   | 255/415 [03:44<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  62%|██████▏   | 256/415 [03:51<07:08,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6007\n",
      "F1-macro: 0.5540\n",
      "F1-pn: 0.4072\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     79.155  91.234    84.766    616.0\n",
      "                 1     70.370  17.117    27.536    111.0\n",
      "                 2     56.098  51.880    53.906    133.0\n",
      "          accuracy     75.581     NaN       NaN      NaN\n",
      "         macro avg     68.541  53.410    55.403    860.0\n",
      "      weighted avg     74.455  75.581    72.607    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    40.721      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 340/415 [04:41<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5758\n",
      "F1-macro: 0.5864\n",
      "F1-pn: 0.4552\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     80.495  89.773    84.881    616.0\n",
      "                 1     67.568  22.523    33.784    111.0\n",
      "                 2     56.618  57.895    57.249    133.0\n",
      "          accuracy     76.163     NaN       NaN      NaN\n",
      "         macro avg     68.227  56.730    58.638    860.0\n",
      "      weighted avg     75.134  76.163    74.013    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    45.516      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches:  82%|████████▏ | 341/415 [04:51<04:31,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5208\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5758\n",
      "F1-macro: 0.5864\n",
      "F1-pn: 0.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Batches: 100%|██████████| 415/415 [05:35<00:00,  1.24it/s]\n",
      "INFO:root:Epoch 2, Loss: 0.7446353566933828, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.6149\n",
      "F1-macro: 0.6414\n",
      "F1-pn: 0.5307\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     84.705  87.935    86.290   4774.0\n",
      "                 1     69.600  30.491    42.405    856.0\n",
      "                 2     56.432  73.188    63.727   1007.0\n",
      "          accuracy     78.288     NaN       NaN      NaN\n",
      "         macro avg     70.246  63.871    64.140   6637.0\n",
      "      weighted avg     78.467  78.288    77.206   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    53.066      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5817\n",
      "F1-macro: 0.6226\n",
      "F1-pn: 0.5075\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     84.530  86.039    85.278    616.0\n",
      "                 1     69.767  27.027    38.961    111.0\n",
      "                 2     53.158  75.940    62.539    133.0\n",
      "          accuracy     76.860     NaN       NaN      NaN\n",
      "         macro avg     69.152  63.002    62.259    860.0\n",
      "      weighted avg     77.773  76.860    75.783    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    50.750      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5650\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5817\n",
      "F1-macro: 0.6226\n",
      "F1-pn: 0.5075\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.5731\n",
      "F1-macro: 0.5101\n",
      "F1-pn: 0.3354\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     78.308  95.241    85.949   1429.0\n",
      "                 1     21.875   5.578     8.889    251.0\n",
      "                 2     77.596  46.557    58.197    305.0\n",
      "          accuracy     76.423     NaN       NaN      NaN\n",
      "         macro avg     59.260  49.125    51.011   1985.0\n",
      "      weighted avg     71.063  76.423    71.941   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    33.543      NaN\n",
      "Epoch: 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  21%|██        | 86/415 [00:57<14:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5531\n",
      "F1-macro: 0.6177\n",
      "F1-pn: 0.4989\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     82.186  89.123    85.514    616.0\n",
      "                 1     70.455  27.928    40.000    111.0\n",
      "                 2     56.757  63.158    59.786    133.0\n",
      "          accuracy     77.209     NaN       NaN      NaN\n",
      "         macro avg     69.799  60.070    61.767    860.0\n",
      "      weighted avg     76.739  77.209    75.661    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    49.893      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 170/415 [01:47<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5332\n",
      "F1-macro: 0.6355\n",
      "F1-pn: 0.5243\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.436  88.312    85.804    616.0\n",
      "                 1     62.687  37.838    47.191    111.0\n",
      "                 2     56.028  59.398    57.664    133.0\n",
      "          accuracy     77.326     NaN       NaN      NaN\n",
      "         macro avg     67.384  61.849    63.553    860.0\n",
      "      weighted avg     76.519  77.326    76.469    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    52.428      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  41%|████      | 171/415 [01:57<14:59,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5799\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5332\n",
      "F1-macro: 0.6355\n",
      "F1-pn: 0.5243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  50%|█████     | 209/415 [02:20<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  61%|██████▏   | 255/415 [03:40<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5276\n",
      "F1-macro: 0.6424\n",
      "F1-pn: 0.5327\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.107  89.448    86.161    616.0\n",
      "                 1     63.636  37.838    47.458    111.0\n",
      "                 2     59.542  58.647    59.091    133.0\n",
      "          accuracy     78.023     NaN       NaN      NaN\n",
      "         macro avg     68.762  61.978    64.237    860.0\n",
      "      weighted avg     76.950  78.023    76.979    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    53.274      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  62%|██████▏   | 256/415 [03:51<09:45,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.5876\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5276\n",
      "F1-macro: 0.6424\n",
      "F1-pn: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 340/415 [04:40<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches:  82%|████████▏ | 341/415 [04:48<03:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5064\n",
      "F1-macro: 0.6427\n",
      "F1-pn: 0.5320\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     83.714  89.286    86.410    616.0\n",
      "                 1     78.571  29.730    43.137    111.0\n",
      "                 2     57.764  69.925    63.265    133.0\n",
      "          accuracy     78.605     NaN       NaN      NaN\n",
      "         macro avg     73.350  62.980    64.271    860.0\n",
      "      weighted avg     79.037  78.605    77.245    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    53.201      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Batches: 100%|██████████| 415/415 [05:31<00:00,  1.25it/s]\n",
      "INFO:root:Epoch 3, Loss: 0.616292806400592, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4999\n",
      "F1-macro: 0.7328\n",
      "F1-pn: 0.6542\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.672  89.359    89.014   4774.0\n",
      "                 1     68.462  51.986    59.097    856.0\n",
      "                 2     66.582  77.756    71.736   1007.0\n",
      "          accuracy     82.778     NaN       NaN      NaN\n",
      "         macro avg     74.572  73.034    73.282   6637.0\n",
      "      weighted avg     82.714  82.778    82.534   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.417      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5090\n",
      "F1-macro: 0.7023\n",
      "F1-pn: 0.6178\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.591  85.714    87.129    616.0\n",
      "                 1     65.432  47.748    55.208    111.0\n",
      "                 2     59.016  81.203    68.354    133.0\n",
      "          accuracy     80.116     NaN       NaN      NaN\n",
      "         macro avg     71.013  71.555    70.230    860.0\n",
      "      weighted avg     81.028  80.116    80.105    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.781      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6601\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5090\n",
      "F1-macro: 0.7023\n",
      "F1-pn: 0.6178\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.4608\n",
      "F1-macro: 0.6331\n",
      "F1-pn: 0.5085\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     82.601  94.682    88.230   1429.0\n",
      "                 1     46.729  19.920    27.933    251.0\n",
      "                 2     83.750  65.902    73.761    305.0\n",
      "          accuracy     80.806     NaN       NaN      NaN\n",
      "         macro avg     71.027  60.168    63.308   1985.0\n",
      "      weighted avg     78.241  80.806    78.382   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    50.847      NaN\n",
      "Epoch: 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  20%|██        | 85/415 [00:49<03:14,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  21%|██        | 86/415 [00:57<14:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5236\n",
      "F1-macro: 0.7004\n",
      "F1-pn: 0.6181\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.565  83.604    86.482    616.0\n",
      "                 1     58.654  54.955    56.744    111.0\n",
      "                 2     58.011  78.947    66.879    133.0\n",
      "          accuracy     79.186     NaN       NaN      NaN\n",
      "         macro avg     68.743  72.502    70.035    860.0\n",
      "      weighted avg     80.696  79.186    79.612    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.812      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 170/415 [01:46<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  41%|████      | 171/415 [01:54<10:57,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4857\n",
      "F1-macro: 0.6929\n",
      "F1-pn: 0.6027\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.838  87.825    87.328    616.0\n",
      "                 1     67.105  45.946    54.545    111.0\n",
      "                 2     60.248  72.932    65.986    133.0\n",
      "          accuracy     80.116     NaN       NaN      NaN\n",
      "         macro avg     71.397  68.901    69.287    860.0\n",
      "      weighted avg     80.179  80.116    79.797    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.266      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  50%|█████     | 209/415 [02:16<02:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  61%|██████▏   | 255/415 [03:37<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  62%|██████▏   | 256/415 [03:44<07:08,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4832\n",
      "F1-macro: 0.6792\n",
      "F1-pn: 0.5831\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     85.714  88.636    87.151    616.0\n",
      "                 1     66.667  41.441    51.111    111.0\n",
      "                 2     61.039  70.677    65.505    133.0\n",
      "          accuracy     79.767     NaN       NaN      NaN\n",
      "         macro avg     71.140  66.918    67.922    860.0\n",
      "      weighted avg     79.440  79.767    79.152    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    58.308      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 340/415 [04:34<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches:  82%|████████▏ | 341/415 [04:41<03:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4775\n",
      "F1-macro: 0.6942\n",
      "F1-pn: 0.6045\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     87.725  87.013    87.368    616.0\n",
      "                 1     62.963  45.946    53.125    111.0\n",
      "                 2     60.714  76.692    67.774    133.0\n",
      "          accuracy     80.116     NaN       NaN      NaN\n",
      "         macro avg     70.467  69.884    69.422    860.0\n",
      "      weighted avg     80.352  80.116    79.918    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    60.450      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Batches: 100%|██████████| 415/415 [05:25<00:00,  1.28it/s]\n",
      "INFO:root:Epoch 4, Loss: 0.513326581881707, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.4083\n",
      "F1-macro: 0.7897\n",
      "F1-pn: 0.7294\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.422  90.637    91.028   4774.0\n",
      "                 1     74.825  62.500    68.109    856.0\n",
      "                 2     71.825  84.806    77.778   1007.0\n",
      "          accuracy     86.123     NaN       NaN      NaN\n",
      "         macro avg     79.357  79.314    78.972   6637.0\n",
      "      weighted avg     86.308  86.123    86.061   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    72.944      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4730\n",
      "F1-macro: 0.7093\n",
      "F1-pn: 0.6266\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.796  86.201    87.479    616.0\n",
      "                 1     65.169  52.252    58.000    111.0\n",
      "                 2     59.538  77.444    67.320    133.0\n",
      "          accuracy     80.465     NaN       NaN      NaN\n",
      "         macro avg     71.167  71.966    70.933    860.0\n",
      "      weighted avg     81.222  80.465    80.557    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    62.660      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6680\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4730\n",
      "F1-macro: 0.7093\n",
      "F1-pn: 0.6266\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.3568\n",
      "F1-macro: 0.7497\n",
      "F1-pn: 0.6672\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.995  96.431    91.470   1429.0\n",
      "                 1     72.593  39.044    50.777    251.0\n",
      "                 2     88.722  77.377    82.662    305.0\n",
      "          accuracy     86.247     NaN       NaN      NaN\n",
      "         macro avg     82.770  70.951    74.970   1985.0\n",
      "      weighted avg     85.439  86.247    84.971   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.720      NaN\n",
      "Epoch: 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5017\n",
      "F1-macro: 0.7153\n",
      "F1-pn: 0.6400\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.351  82.305    86.593    616.0\n",
      "                 1     61.818  61.261    61.538    111.0\n",
      "                 2     55.897  81.955    66.463    133.0\n",
      "          accuracy     79.535     NaN       NaN      NaN\n",
      "         macro avg     69.689  75.174    71.532    860.0\n",
      "      weighted avg     82.057  79.535    80.246    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.001      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  21%|██        | 86/415 [01:00<20:21,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6777\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5017\n",
      "F1-macro: 0.7153\n",
      "F1-pn: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 170/415 [01:50<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4597\n",
      "F1-macro: 0.7265\n",
      "F1-pn: 0.6502\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.149  86.688    87.901    616.0\n",
      "                 1     67.347  59.459    63.158    111.0\n",
      "                 2     60.736  74.436    66.892    133.0\n",
      "          accuracy     81.279     NaN       NaN      NaN\n",
      "         macro avg     72.411  73.528    72.650    860.0\n",
      "      weighted avg     81.941  81.279    81.458    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.025      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  41%|████      | 171/415 [02:01<15:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6884\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4597\n",
      "F1-macro: 0.7265\n",
      "F1-pn: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  50%|█████     | 209/415 [02:23<02:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  61%|██████▏   | 255/415 [03:43<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  62%|██████▏   | 256/415 [03:51<07:11,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4583\n",
      "F1-macro: 0.7058\n",
      "F1-pn: 0.6160\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     86.287  90.909    88.538    616.0\n",
      "                 1     67.105  45.946    54.545    111.0\n",
      "                 2     68.148  69.173    68.657    133.0\n",
      "          accuracy     81.744     NaN       NaN      NaN\n",
      "         macro avg     73.847  68.676    70.580    860.0\n",
      "      weighted avg     81.006  81.744    81.076    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    61.601      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 340/415 [04:41<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4565\n",
      "F1-macro: 0.7325\n",
      "F1-pn: 0.6561\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.404  87.662    88.525    616.0\n",
      "                 1     69.149  58.559    63.415    111.0\n",
      "                 2     61.728  75.188    67.797    133.0\n",
      "          accuracy     81.977     NaN       NaN      NaN\n",
      "         macro avg     73.427  73.803    73.245    860.0\n",
      "      weighted avg     82.510  81.977    82.078    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.606      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches:  82%|████████▏ | 341/415 [04:53<05:07,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6943\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4565\n",
      "F1-macro: 0.7325\n",
      "F1-pn: 0.6561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Batches: 100%|██████████| 415/415 [05:37<00:00,  1.23it/s]\n",
      "INFO:root:Epoch 5, Loss: 0.4172841107091272, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.3115\n",
      "F1-macro: 0.8562\n",
      "F1-pn: 0.8165\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.951  92.187    93.549   4774.0\n",
      "                 1     74.231  81.776    77.821    856.0\n",
      "                 2     83.381  87.686    85.479   1007.0\n",
      "          accuracy     90.161     NaN       NaN      NaN\n",
      "         macro avg     84.188  87.216    85.616   6637.0\n",
      "      weighted avg     90.523  90.161    90.296   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    81.650      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4632\n",
      "F1-macro: 0.7339\n",
      "F1-pn: 0.6615\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.966  85.877    87.874    616.0\n",
      "                 1     62.500  67.568    64.935    111.0\n",
      "                 2     63.158  72.180    67.368    133.0\n",
      "          accuracy     81.395     NaN       NaN      NaN\n",
      "         macro avg     71.875  75.208    73.392    860.0\n",
      "      weighted avg     82.275  81.395    81.742    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.152      NaN\n",
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6977\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4632\n",
      "F1-macro: 0.7339\n",
      "F1-pn: 0.6615\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.2482\n",
      "F1-macro: 0.8502\n",
      "F1-pn: 0.8017\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.406  98.251    94.705   1429.0\n",
      "                 1     86.826  57.769    69.378    251.0\n",
      "                 2     94.681  87.541    90.971    305.0\n",
      "          accuracy     91.486     NaN       NaN      NaN\n",
      "         macro avg     90.971  81.187    85.018   1985.0\n",
      "      weighted avg     91.330  91.486    90.929   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    80.175      NaN\n",
      "Epoch: 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4696\n",
      "F1-macro: 0.7349\n",
      "F1-pn: 0.6629\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.115  84.903    87.899    616.0\n",
      "                 1     57.971  72.072    64.257    111.0\n",
      "                 2     64.865  72.180    68.327    133.0\n",
      "          accuracy     81.279     NaN       NaN      NaN\n",
      "         macro avg     71.317  76.385    73.495    860.0\n",
      "      weighted avg     82.777  81.279    81.821    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.292      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  21%|██        | 86/415 [01:00<20:11,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.6989\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4696\n",
      "F1-macro: 0.7349\n",
      "F1-pn: 0.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 170/415 [01:50<02:23,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  41%|████      | 171/415 [01:57<10:56,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4616\n",
      "F1-macro: 0.7254\n",
      "F1-pn: 0.6483\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.119  85.877    87.947    616.0\n",
      "                 1     65.714  62.162    63.889    111.0\n",
      "                 2     58.929  74.436    65.781    133.0\n",
      "          accuracy     81.047     NaN       NaN      NaN\n",
      "         macro avg     71.587  74.158    72.539    860.0\n",
      "      weighted avg     82.146  81.047    81.414    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    64.835      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  50%|█████     | 209/415 [02:19<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  61%|██████▏   | 255/415 [03:40<01:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  62%|██████▏   | 256/415 [03:47<07:08,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4632\n",
      "F1-macro: 0.7331\n",
      "F1-pn: 0.6561\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.780  88.636    88.708    616.0\n",
      "                 1     69.474  59.459    64.078    111.0\n",
      "                 2     63.333  71.429    67.138    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     73.863  73.175    73.308    860.0\n",
      "      weighted avg     82.353  82.209    82.193    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.608      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 340/415 [04:37<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4551\n",
      "F1-macro: 0.7379\n",
      "F1-pn: 0.6632\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.309  88.149    88.725    616.0\n",
      "                 1     70.526  60.360    65.049    111.0\n",
      "                 2     62.420  73.684    67.586    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     74.085  74.065    73.787    860.0\n",
      "      weighted avg     82.727  82.326    82.400    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.317      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches:  82%|████████▏ | 341/415 [04:48<04:31,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7005\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4551\n",
      "F1-macro: 0.7379\n",
      "F1-pn: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Batches: 100%|██████████| 415/415 [05:31<00:00,  1.25it/s]\n",
      "INFO:root:Epoch 6, Loss: 0.31694520773837365, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.2147\n",
      "F1-macro: 0.9093\n",
      "F1-pn: 0.8830\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     96.090  96.271    96.181   4774.0\n",
      "                 1     87.653  83.762    85.663    856.0\n",
      "                 2     89.672  92.254    90.945   1007.0\n",
      "          accuracy     94.049     NaN       NaN      NaN\n",
      "         macro avg     91.138  90.762    90.930   6637.0\n",
      "      weighted avg     94.028  94.049    94.030   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    88.304      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4475\n",
      "F1-macro: 0.7318\n",
      "F1-pn: 0.6548\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.016  88.149    88.581    616.0\n",
      "                 1     68.085  57.658    62.439    111.0\n",
      "                 2     63.462  74.436    68.512    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     73.521  73.414    73.177    860.0\n",
      "      weighted avg     82.363  82.093    82.103    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    65.476      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.1503\n",
      "F1-macro: 0.9225\n",
      "F1-pn: 0.8991\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     94.966  99.020    96.951   1429.0\n",
      "                 1     94.500  75.299    83.814    251.0\n",
      "                 2     97.627  94.426    96.000    305.0\n",
      "          accuracy     95.315     NaN       NaN      NaN\n",
      "         macro avg     95.698  89.582    92.255   1985.0\n",
      "      weighted avg     95.316  95.315    95.144   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    89.907      NaN\n",
      "Epoch: 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4689\n",
      "F1-macro: 0.7558\n",
      "F1-pn: 0.6858\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.547  88.636    89.582    616.0\n",
      "                 1     68.182  67.568    67.873    111.0\n",
      "                 2     65.986  72.932    69.286    133.0\n",
      "          accuracy     83.488     NaN       NaN      NaN\n",
      "         macro avg     74.905  76.379    75.580    860.0\n",
      "      weighted avg     83.862  83.488    83.641    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.580      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  21%|██        | 86/415 [01:00<20:16,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7208\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.4689\n",
      "F1-macro: 0.7558\n",
      "F1-pn: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 170/415 [01:50<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  41%|████      | 171/415 [01:57<10:55,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4751\n",
      "F1-macro: 0.7393\n",
      "F1-pn: 0.6653\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.850  87.662    88.743    616.0\n",
      "                 1     70.526  60.360    65.049    111.0\n",
      "                 2     61.585  75.940    68.013    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     73.987  74.654    73.935    860.0\n",
      "      weighted avg     82.985  82.326    82.479    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.531      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  50%|█████     | 209/415 [02:20<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  61%|██████▏   | 255/415 [03:40<01:34,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  62%|██████▏   | 256/415 [03:48<07:09,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4733\n",
      "F1-macro: 0.7398\n",
      "F1-pn: 0.6657\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.456  88.149    88.798    616.0\n",
      "                 1     65.138  63.964    64.545    111.0\n",
      "                 2     65.972  71.429    68.592    133.0\n",
      "          accuracy     82.442     NaN       NaN      NaN\n",
      "         macro avg     73.522  74.514    73.979    860.0\n",
      "      weighted avg     82.686  82.442    82.543    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.569      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 340/415 [04:37<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches:  82%|████████▏ | 341/415 [04:45<03:20,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4771\n",
      "F1-macro: 0.7417\n",
      "F1-pn: 0.6696\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.236  87.013    88.595    616.0\n",
      "                 1     64.655  67.568    66.079    111.0\n",
      "                 2     64.000  72.180    67.845    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.964  75.587    74.173    860.0\n",
      "      weighted avg     82.877  82.209    82.480    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.962      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Batches: 100%|██████████| 415/415 [05:28<00:00,  1.26it/s]\n",
      "INFO:root:Epoch 7, Loss: 0.21603561976408384, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.1255\n",
      "F1-macro: 0.9560\n",
      "F1-pn: 0.9431\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.299  98.052    98.175   4774.0\n",
      "                 1     92.865  92.757    92.811    856.0\n",
      "                 2     95.196  96.425    95.807   1007.0\n",
      "          accuracy     97.122     NaN       NaN      NaN\n",
      "         macro avg     95.454  95.745    95.598   6637.0\n",
      "      weighted avg     97.127  97.122    97.124   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    94.309      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4768\n",
      "F1-macro: 0.7387\n",
      "F1-pn: 0.6645\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.907  88.474    88.690    616.0\n",
      "                 1     68.224  65.766    66.972    111.0\n",
      "                 2     64.286  67.669    65.934    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     73.806  73.970    73.866    860.0\n",
      "      weighted avg     82.430  82.326    82.368    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.453      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0718\n",
      "F1-macro: 0.9823\n",
      "F1-pn: 0.9766\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     98.824  99.930    99.374   1429.0\n",
      "                 1     99.156  93.625    96.311    251.0\n",
      "                 2     99.340  98.689    99.013    305.0\n",
      "          accuracy     98.942     NaN       NaN      NaN\n",
      "         macro avg     99.107  97.415    98.233   1985.0\n",
      "      weighted avg     98.945  98.942    98.931   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    97.662      NaN\n",
      "Epoch: 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  21%|██        | 86/415 [00:57<14:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.4981\n",
      "F1-macro: 0.7383\n",
      "F1-pn: 0.6640\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.117  87.338    88.706    616.0\n",
      "                 1     63.158  64.865    64.000    111.0\n",
      "                 2     65.101  72.932    68.794    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     72.792  75.045    73.833    860.0\n",
      "      weighted avg     82.769  82.209    82.438    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.397      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 170/415 [01:46<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  41%|████      | 171/415 [01:54<10:56,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5065\n",
      "F1-macro: 0.7461\n",
      "F1-pn: 0.6723\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.431  89.286    89.358    616.0\n",
      "                 1     69.000  62.162    65.403    111.0\n",
      "                 2     66.207  72.180    69.065    133.0\n",
      "          accuracy     83.140     NaN       NaN      NaN\n",
      "         macro avg     74.879  74.543    74.609    860.0\n",
      "      weighted avg     83.202  83.140    83.128    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.234      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  50%|█████     | 209/415 [02:16<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  61%|██████▏   | 255/415 [03:37<01:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  62%|██████▏   | 256/415 [03:44<07:07,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5043\n",
      "F1-macro: 0.7432\n",
      "F1-pn: 0.6671\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.694  90.422    89.550    616.0\n",
      "                 1     72.414  56.757    63.636    111.0\n",
      "                 2     66.897  72.932    69.784    133.0\n",
      "          accuracy     83.372     NaN       NaN      NaN\n",
      "         macro avg     76.002  73.370    74.323    860.0\n",
      "      weighted avg     83.222  83.372    83.148    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.710      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 340/415 [04:33<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5168\n",
      "F1-macro: 0.7565\n",
      "F1-pn: 0.6886\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.349  88.149    89.236    616.0\n",
      "                 1     66.942  72.973    69.828    111.0\n",
      "                 2     66.667  69.173    67.897    133.0\n",
      "          accuracy     83.256     NaN       NaN      NaN\n",
      "         macro avg     74.653  76.765    75.653    860.0\n",
      "      weighted avg     83.666  83.256    83.431    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.862      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches:  82%|████████▏ | 341/415 [04:44<04:33,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Checkpoint] 🎯 Новый лучший средний F1: 0.7226\n",
      "[Checkpoint] 💾 Модель сохранена: ./result_lr_1e-06_ENS_Teg_21_multi_dropout_V2_T_NotToken/best_model.pth\n",
      "Loss: 0.5168\n",
      "F1-macro: 0.7565\n",
      "F1-pn: 0.6886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Batches: 100%|██████████| 415/415 [05:28<00:00,  1.26it/s]\n",
      "INFO:root:Epoch 8, Loss: 0.12099704800779561, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0667\n",
      "F1-macro: 0.9810\n",
      "F1-pn: 0.9753\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.516  98.974    99.244   4774.0\n",
      "                 1     97.427  97.313    97.370    856.0\n",
      "                 2     96.422  99.007    97.697   1007.0\n",
      "          accuracy     98.765     NaN       NaN      NaN\n",
      "         macro avg     97.788  98.431    98.104   6637.0\n",
      "      weighted avg     98.777  98.765    98.768   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    97.534      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5228\n",
      "F1-macro: 0.7429\n",
      "F1-pn: 0.6685\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.199  88.149    89.163    616.0\n",
      "                 1     71.134  62.162    66.346    111.0\n",
      "                 2     61.491  74.436    67.347    133.0\n",
      "          accuracy     82.674     NaN       NaN      NaN\n",
      "         macro avg     74.275  74.916    74.285    860.0\n",
      "      weighted avg     83.299  82.674    82.844    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.847      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0352\n",
      "F1-macro: 0.9942\n",
      "F1-pn: 0.9923\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.651  99.930    99.790   1429.0\n",
      "                 1    100.000  97.610    98.790    251.0\n",
      "                 2     99.349 100.000    99.673    305.0\n",
      "          accuracy     99.647     NaN       NaN      NaN\n",
      "         macro avg     99.667  99.180    99.418   1985.0\n",
      "      weighted avg     99.649  99.647    99.646   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.232      NaN\n",
      "Epoch: 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  21%|██        | 86/415 [00:57<14:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5708\n",
      "F1-macro: 0.7501\n",
      "F1-pn: 0.6813\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.111  86.526    88.759    616.0\n",
      "                 1     62.992  72.072    67.227    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.215  77.177    75.008    860.0\n",
      "      weighted avg     83.527  82.558    82.930    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.133      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 170/415 [01:46<02:24,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  41%|████      | 171/415 [01:54<10:56,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5681\n",
      "F1-macro: 0.7376\n",
      "F1-pn: 0.6644\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     90.339  86.526    88.391    616.0\n",
      "                 1     65.766  65.766    65.766    111.0\n",
      "                 2     61.635  73.684    67.123    133.0\n",
      "          accuracy     81.860     NaN       NaN      NaN\n",
      "         macro avg     72.580  75.325    73.760    860.0\n",
      "      weighted avg     82.728  81.860    82.182    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.445      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  50%|█████     | 209/415 [02:16<02:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  61%|██████▏   | 255/415 [03:37<01:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  62%|██████▏   | 256/415 [03:44<07:07,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5780\n",
      "F1-macro: 0.7389\n",
      "F1-pn: 0.6644\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     88.925  88.636    88.780    616.0\n",
      "                 1     69.149  58.559    63.415    111.0\n",
      "                 2     65.132  74.436    69.474    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     74.402  73.877    73.890    860.0\n",
      "      weighted avg     82.693  82.558    82.521    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.444      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 340/415 [04:33<00:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches:  82%|████████▏ | 341/415 [04:41<03:19,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5655\n",
      "F1-macro: 0.7550\n",
      "F1-pn: 0.6889\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.983  87.500    88.724    616.0\n",
      "                 1     68.142  69.369    68.750    111.0\n",
      "                 2     65.541  72.932    69.039    133.0\n",
      "          accuracy     82.907     NaN       NaN      NaN\n",
      "         macro avg     74.555  76.601    75.504    860.0\n",
      "      weighted avg     83.384  82.907    83.102    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.895      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Batches: 100%|██████████| 415/415 [05:24<00:00,  1.28it/s]\n",
      "INFO:root:Epoch 9, Loss: 0.0596986051749842, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0298\n",
      "F1-macro: 0.9960\n",
      "F1-pn: 0.9949\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.895  99.707    99.801   4774.0\n",
      "                 1     99.302  99.766    99.534    856.0\n",
      "                 2     99.209  99.702    99.455   1007.0\n",
      "          accuracy     99.714     NaN       NaN      NaN\n",
      "         macro avg     99.469  99.725    99.597   6637.0\n",
      "      weighted avg     99.715  99.714    99.714   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.494      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.5639\n",
      "F1-macro: 0.7550\n",
      "F1-pn: 0.6845\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.739  89.448    89.593    616.0\n",
      "                 1     71.717  63.964    67.619    111.0\n",
      "                 2     65.986  72.932    69.286    133.0\n",
      "          accuracy     83.605     NaN       NaN      NaN\n",
      "         macro avg     75.814  75.448    75.499    860.0\n",
      "      weighted avg     83.740  83.605    83.617    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    68.452      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0125\n",
      "F1-macro: 0.9992\n",
      "F1-pn: 0.9990\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.930 100.000    99.965   1429.0\n",
      "                 1    100.000  99.602    99.800    251.0\n",
      "                 2    100.000 100.000   100.000    305.0\n",
      "          accuracy     99.950     NaN       NaN      NaN\n",
      "         macro avg     99.977  99.867    99.922   1985.0\n",
      "      weighted avg     99.950  99.950    99.950   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.900      NaN\n",
      "Epoch: 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  20%|██        | 85/415 [00:49<03:13,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  21%|██        | 86/415 [00:57<14:48,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6261\n",
      "F1-macro: 0.7474\n",
      "F1-pn: 0.6779\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.237  86.201    88.648    616.0\n",
      "                 1     65.000  70.270    67.532    111.0\n",
      "                 2     62.658  74.436    68.041    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     72.965  76.969    74.740    860.0\n",
      "      weighted avg     83.431  82.326    82.736    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.787      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 170/415 [01:46<02:23,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  41%|████      | 171/415 [01:54<10:57,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6341\n",
      "F1-macro: 0.7424\n",
      "F1-pn: 0.6704\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.967  87.338    88.633    616.0\n",
      "                 1     65.766  65.766    65.766    111.0\n",
      "                 2     64.238  72.932    68.310    133.0\n",
      "          accuracy     82.326     NaN       NaN      NaN\n",
      "         macro avg     73.324  75.345    74.236    860.0\n",
      "      weighted avg     82.864  82.326    82.538    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.038      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  50%|█████     | 209/415 [02:16<02:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  61%|██████▏   | 255/415 [03:45<01:49,  1.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  62%|██████▏   | 256/415 [03:54<08:17,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6430\n",
      "F1-macro: 0.7357\n",
      "F1-pn: 0.6603\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.163  88.149    88.653    616.0\n",
      "                 1     70.968  59.459    64.706    111.0\n",
      "                 2     62.025  73.684    67.354    133.0\n",
      "          accuracy     82.209     NaN       NaN      NaN\n",
      "         macro avg     74.052  73.764    73.571    860.0\n",
      "      weighted avg     82.617  82.209    82.268    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.030      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 340/415 [04:51<00:49,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches:  82%|████████▏ | 341/415 [04:59<03:47,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6446\n",
      "F1-macro: 0.7411\n",
      "F1-pn: 0.6675\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     89.198  88.474    88.835    616.0\n",
      "                 1     66.355  63.964    65.138    111.0\n",
      "                 2     66.197  70.677    68.364    133.0\n",
      "          accuracy     82.558     NaN       NaN      NaN\n",
      "         macro avg     73.917  74.372    74.112    860.0\n",
      "      weighted avg     82.693  82.558    82.610    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    66.751      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Batches: 100%|██████████| 415/415 [05:45<00:00,  1.20it/s]\n",
      "INFO:root:Epoch 10, Loss: 0.025798580802539477, Step: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate, backprop: Train\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Train\n",
      "Loss: 0.0141\n",
      "F1-macro: 0.9981\n",
      "F1-pn: 0.9975\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     99.958  99.895    99.927   4774.0\n",
      "                 1     99.650  99.766    99.708    856.0\n",
      "                 2     99.703  99.901    99.802   1007.0\n",
      "          accuracy     99.879     NaN       NaN      NaN\n",
      "         macro avg     99.770  99.854    99.812   6637.0\n",
      "      weighted avg     99.880  99.879    99.879   6637.0\n",
      "avg f1 (class 1&2)        NaN     NaN    99.755      NaN\n",
      "evaluate, backprop: Test\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Test\n",
      "Loss: 0.6726\n",
      "F1-macro: 0.7427\n",
      "F1-pn: 0.6712\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0     91.081  86.201    88.574    616.0\n",
      "                 1     65.789  67.568    66.667    111.0\n",
      "                 2     61.350  75.188    67.568    133.0\n",
      "          accuracy     82.093     NaN       NaN      NaN\n",
      "         macro avg     72.740  76.319    74.269    860.0\n",
      "      weighted avg     83.218  82.093    82.498    860.0\n",
      "avg f1 (class 1&2)        NaN     NaN    67.117      NaN\n",
      "evaluate, backprop: Validation\n",
      "\n",
      "----------------------------------------\n",
      "Result evaluate in Validation\n",
      "Loss: 0.0053\n",
      "F1-macro: 1.0000\n",
      "F1-pn: 1.0000\n",
      "             label  precision  recall  f1-score  support\n",
      "                 0      100.0   100.0     100.0   1429.0\n",
      "                 1      100.0   100.0     100.0    251.0\n",
      "                 2      100.0   100.0     100.0    305.0\n",
      "          accuracy      100.0     NaN       NaN      NaN\n",
      "         macro avg      100.0   100.0     100.0   1985.0\n",
      "      weighted avg      100.0   100.0     100.0   1985.0\n",
      "avg f1 (class 1&2)        NaN     NaN     100.0      NaN\n",
      "Epoch: 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Batches:  18%|█▊        | 76/415 [00:45<03:21,  1.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 202\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.init_checkpoint:\n\u001b[32m    200\u001b[39m     model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    101\u001b[39m optimizer.step()\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(i % batches_per_validation == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i >\u001b[32m50\u001b[39m):\n\u001b[32m    106\u001b[39m     evaluate(epoch, backprop=\u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m, vall_train = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lr_m = 1e-6\n",
    "# lr = 1e-6 началось обучение, уменьшение TrainError\n",
    "# добавить волидацию по шагам в течение эпохи обучения, а не каджые N епох\n",
    "# Добавить сохранение ошибки в файлы для построения графиков\n",
    "# проверить методы передачи сущьности (параетром, +тип, или в тексте выделяя тегами).\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"./ruRoberta-large/\")\n",
    "    #parser.add_argument(\"--model_name\", type=str, default=\"sberbank-ai/ruRoberta-large\", help=\"Имя модели\")\n",
    "    parser.add_argument(\"--max_seq_len\", type=int, default=512) #128\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=16)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=15)\n",
    "    parser.add_argument(\"--lr\", type=float, default=lr_m)\n",
    "    parser.add_argument(\"--init_checkpoint\", type=str, default=None)\n",
    "    parser.add_argument(\"--train_data\", type=str, required=False, default=\"./data/train_data.csv\")\n",
    "    parser.add_argument(\"--validation_data\", type=str, required=False, default=\"./data/validation.csv\")\n",
    "    parser.add_argument(\"--eval_data\", type=str, required=False, default=\"./data/test.csv\")\n",
    "    parser.add_argument(\"--result\", type=str, default=f\"./result_lr_{lr_m}_ENS_Teg_21_multi_dropout_V2_T_NotToken/\")\n",
    "    # Игнорируем аргументы Jupyter\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    os.makedirs(args.result, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    print(args)  # Проверяем аргументы\n",
    "\n",
    "    base_lr = args.lr\n",
    "    min_lr = base_lr * (1/4)\n",
    "    step_size_up = 400 #400\n",
    "\n",
    "    best_avg_f1 = 0.0\n",
    "    best_model_path = os.path.join(args.result, \"best_model.pth\")\n",
    "\n",
    "    SEED = 42\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.model_name)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained(args.model_name, num_labels=3)\n",
    "    model = RobertaWithMultiSampleDropout(model_name='./ruRoberta-large', num_labels=3, use_multi_sample_dropout=True )\n",
    "\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    train_dataset = load_data(args.train_data, tokenizer, args.max_seq_len)\n",
    "    validation_data = load_data(args.validation_data, tokenizer, args.max_seq_len)\n",
    "    eval_dataset = load_data(args.eval_data, tokenizer, args.max_seq_len)\n",
    "    # Извлекаем первые 10 примеров из датасета\n",
    "    for i in range(2):\n",
    "        input_ids, attention_mask, label = train_dataset[i]\n",
    "        decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        print(f\"Text: {decoded_text}\")\n",
    "        print(f\"Label: {label.item()}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    if train_dataset is None or eval_dataset is None or validation_data is None:\n",
    "        sys.exit(f\"Ошибка загрузки данных: убедитесь, что файлы {args.train_data}, {args.validation_data} и {args.eval_data} существуют и содержат нужные колонки.\")\n",
    "\n",
    "    # Получаем метки классов из тренировочного датасета\n",
    "    train_labels = [label.item() for _, _, label in train_dataset]\n",
    "\n",
    "    # Вычисляем веса классов\n",
    "    class_weights = compute_ens_weights(train_labels, beta=0.999)\n",
    "\n",
    "    # Вывод весов классов\n",
    "    print(f\"class_weights = {class_weights}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_data, batch_size=args.batch_size)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=args.batch_size)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    #scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr = base_lr, step_size_up = step_size_up, mode=\"triangular2\",cycle_momentum=False )\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    \n",
    "    def train():\n",
    "        model.train()\n",
    "        batches_per_validation = (len(train_loader) // 2)+2\n",
    "        batches_per_test = (len(train_loader) // 5)+2\n",
    "        \n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"Epoch: {epoch}/{args.epochs}\")\n",
    "            total_loss = 0\n",
    "            for i,batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} - Batches\")):\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                if(i % batches_per_validation == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Validation\", vall_train = True)\n",
    "                if(i % batches_per_test == 0 and i >50):\n",
    "                    evaluate(epoch, backprop=\"Test\", flag_print = True)\n",
    "                \n",
    "            logging.info(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}, Step: {len(train_loader)}\")\n",
    "            # Валидация с обратным распространением ошибки каждые 2 эпохи\n",
    "            evaluate(epoch , backprop=\"Train\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Test\", flag_print = True)\n",
    "            evaluate(epoch , backprop=\"Validation\", flag_print = True, vall_train = True)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def evaluate(epoch = None, backprop = \"None\", flag_print = False, vall_train = False):\n",
    "        global best_avg_f1\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        total_loss = 0\n",
    "        print(f\"evaluate, backprop: {backprop}\")\n",
    "        loader = validation_loader\n",
    "        if backprop == \"Validation\":\n",
    "            loader = validation_loader\n",
    "        elif backprop == \"Test\":\n",
    "            loader = eval_loader\n",
    "        elif backprop == \"Train\":\n",
    "            loader = train_loader\n",
    "        \n",
    "        else: loader = eval_loader\n",
    "        with torch.no_grad() if not backprop == \"Validation\" else torch.enable_grad():  # Включаем градиенты для обучения на валидации\n",
    "            for batch in loader:\n",
    "            #for batch in loader:\n",
    "                input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = loss_fct(outputs.logits, labels)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if backprop == \"Validation\" and vall_train:\n",
    "                    #уменьшая тк обучающие данные удвоились\n",
    "                    loss = loss\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #scheduler.step()\n",
    "                    loss = loss\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "        avg_loss = total_loss / len(loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        f1_pn = f1_score(all_labels, all_preds, labels=[1, 2], average='macro')\n",
    "        avg_f1 = (f1 + f1_pn) / 2\n",
    "\n",
    "        if(flag_print):\n",
    "            print()\n",
    "            print(\"--\"*20)\n",
    "            print(f\"Result evaluate in {backprop}\")\n",
    "            #logging.info(f\"{backprop} Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "            #print(classification_report(all_labels, all_preds))\n",
    "            castom_classification_report(all_labels, all_preds)\n",
    "\n",
    "        # 💾 Сохраняем модель только при улучшении средней метрики\n",
    "        if (avg_f1 > best_avg_f1) and backprop == \"Test\":\n",
    "            best_avg_f1 = avg_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            tokenizer.save_pretrained(os.path.join(args.result, \"tokenizer\"))\n",
    "            \n",
    "            print(f\"[Checkpoint] 🎯 Новый лучший средний F1: {best_avg_f1:.4f}\")\n",
    "            print(f\"[Checkpoint] 💾 Модель сохранена: {best_model_path}\")\n",
    "            # 🔸 Сохраняем значение лучшего F1 в файл\n",
    "            best_score_path = os.path.join(args.result, \"best_score.txt\")\n",
    "            save_metrics_best(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "            save_confusion_matrix(epoch, all_labels, all_preds, args.result, backprop)\n",
    "            with open(best_score_path, \"w\") as f:\n",
    "                f.write(f\"Epoch: {epoch}\\n\")\n",
    "                f.write(f\"Loss: {avg_loss:.4f}\\n\")\n",
    "                f.write(f\"F1-pn0: {f1:.4f}\\n\")\n",
    "                f.write(f\"F1-pn: {f1_pn:.4f}\\n\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"F1-macro: {f1:.4f}\")\n",
    "            print(f\"F1-pn: {f1_pn:.4f}\")\n",
    "\n",
    "\n",
    "        if epoch is not None:\n",
    "            save_metrics(epoch, all_labels, all_preds, args.result, backprop, avg_loss)\n",
    "            \n",
    "        \n",
    "    if args.init_checkpoint:\n",
    "        model.load_state_dict(torch.load(args.init_checkpoint, map_location=device))\n",
    "\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4520d-65bf-4708-99bc-4807f25ea18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805557fd-243e-47ff-b33c-4ce8c82c159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_display_metrics(metrics_file):\n",
    "    # Загружаем CSV-файл\n",
    "    df = pd.read_csv(metrics_file)\n",
    "    df = df[df[\"backprop\"] == \"Test\"]\n",
    "    # Определяем количество эпох\n",
    "    epochs = df[\"epoch\"].unique()\n",
    "    print(epochs)\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        # Фильтруем данные по эпохе\n",
    "        epoch_df = df[df[\"epoch\"] == epoch]\n",
    "        \n",
    "        for idx, row in epoch_df.iterrows():\n",
    "            loss = row[\"loss\"]\n",
    "            backprop_value = row[\"backprop\"]\n",
    "            print(f\"\\nEpoch {epoch} (Backprop: {backprop_value}) (Loss: {loss})\\n\" + \"-\"*30)\n",
    "            # Формируем таблицу в стиле classification_report\n",
    "            table_data = {}\n",
    "            class_labels = sorted(\n",
    "                set(col.split(\"_\")[1] for col in df.columns \n",
    "                    if col.startswith(\"class_\") and \"precision\" in col)\n",
    "            )\n",
    "            \n",
    "            # Фильтруем только числовые метки классов\n",
    "            class_labels = [label for label in class_labels if label.isdigit()]\n",
    "            \n",
    "            for label in class_labels:\n",
    "                table_data[int(label)] = {\n",
    "                    \"precision\": row[f\"class_{label}_precision\"],\n",
    "                    \"recall\": row[f\"class_{label}_recall\"],\n",
    "                    \"f1-score\": row[f\"class_{label}_f1\"],\n",
    "                }\n",
    "            \n",
    "            # Добавляем средние значения\n",
    "            table_data[\"accuracy\"] = {\"precision\": \"\", \"recall\": \"\", \"f1-score\": row[\"accuracy\"] }\n",
    "            table_data[\"macro avg\"] = {\n",
    "                \"precision\": row[\"macro_precision\"],\n",
    "                \"recall\": row[\"macro_recall\"],\n",
    "                \"f1-score\": row[\"macro_f1\"],\n",
    "            }\n",
    "            table_data[\"weighted avg\"] = {\n",
    "                \"precision\": row[\"weighted_precision\"],\n",
    "                \"recall\": row[\"weighted_recall\"],\n",
    "                \"f1-score\": row[\"weighted_f1\"],\n",
    "            }\n",
    "            \n",
    "            # Выводим таблицу\n",
    "            df_table = pd.DataFrame.from_dict(table_data, orient=\"index\")\n",
    "            print(df_table.to_string())\n",
    "\n",
    "# Пример использования\n",
    "metrics_file = \"./result_lr_1e-06_test/metrics_class_weights.csv\"\n",
    "load_and_display_metrics(metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f9444b-5431-4eb6-8ff8-9074d559598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка CSV-файла\n",
    "df = pd.read_csv(\"metrics_class_weights.csv\")  # укажи путь к файлу, если он отличается\n",
    "\n",
    "# Построение графика loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for stage in ['Train', 'Validation', 'Test']:\n",
    "    stage_data = df[df['backprop'] == stage]\n",
    "    plt.plot(stage_data['epoch'], stage_data['loss'], label=stage)\n",
    "\n",
    "plt.title('Значение Loss по эпохам')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ryumin_env",
   "language": "python",
   "name": "ryumin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
